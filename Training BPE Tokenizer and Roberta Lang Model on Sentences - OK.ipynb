{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc356c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://medium.com/analytics-vidhya/create-a-tokenizer-and-train-a-huggingface-roberta-model-from-scratch-f3ed1138180c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b7e036a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1.\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "from tokenizers.processors import BertProcessing\n",
    "import datasets\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "TRAIN_BATCH_SIZE = 16    # input batch size for training (default: 64)\n",
    "VALID_BATCH_SIZE = 8    # input batch size for testing (default: 1000)\n",
    "TRAIN_EPOCHS = 10 #15        # number of epochs to train (default: 10)\n",
    "LEARNING_RATE = 1e-4    # learning rate (default: 0.001)\n",
    "WEIGHT_DECAY = 0.01\n",
    "SEED = 42               # random seed (default: 42)\n",
    "MAX_LEN = 128\n",
    "SUMMARY_LEN = 7\n",
    "\n",
    "paths = [str(x) for x in Path(\"/home/info/MyNotebooks/Datasets/SentencasTRT1/TXT\").glob(\"*.txt\")]\n",
    "tokenizer_folder = \"/home/info/MyNotebooks/RobertaSenTRT/Tokenizer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a81696",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# 2.TREINANDO O TOKENIZADOR e salvando em disco\n",
    "\n",
    "# Initialize a tokenizer\n",
    "tokenizer = ByteLevelBPETokenizer(lowercase=True)\n",
    "\n",
    "tokenizer.train(files=paths, vocab_size=8192, min_frequency=2,\n",
    "                show_progress=True,\n",
    "                special_tokens=[\n",
    "                                \"<s>\",\n",
    "                                \"<pad>\",\n",
    "                                \"</s>\",\n",
    "                                \"<unk>\",\n",
    "                                \"<mask>\",\n",
    "])\n",
    "\n",
    "tokenizer.save_model(tokenizer_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e2ade2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc5d9c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e909791d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d7999ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2. CARREGANDO O TOKENIZADOR\n",
    "# Load the tokenizer using vocab.json and mrege.txt files\n",
    "tokenizer = ByteLevelBPETokenizer(\n",
    "    os.path.abspath(os.path.join(tokenizer_folder,'vocab.json')),\n",
    "    os.path.abspath(os.path.join(tokenizer_folder,'merges.txt'))\n",
    ")\n",
    "\n",
    "# Prepare the tokenizer\n",
    "tokenizer._tokenizer.post_processor = BertProcessing(\n",
    "    (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n",
    "    (\"<s>\", tokenizer.token_to_id(\"<s>\")),\n",
    ")\n",
    "\n",
    "tokenizer.enable_truncation(max_length=512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9240a06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
      "The class this function is called from is 'RobertaTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
      "The class this function is called from is 'RobertaTokenizerFast'.\n"
     ]
    }
   ],
   "source": [
    "# Step 3.\n",
    "from transformers import RobertaTokenizerFast\n",
    "# Create the tokenizer from a trained one\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(tokenizer_folder, max_len=MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a173ffaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1f4c97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b085fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7508fb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e69396",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c0b9c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a5c942",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ecf749",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8891a65b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8034089e",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' - Language Modeling does not use Labeled data! - '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abd12f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1fec585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4. Cria DataFrames e as LISTAS contendo dados das sentenças e as classificacoes.\n",
    "# LOADING DATAFRAMES DATASETDICTS FOR TRAINING \"THE MODEL\"\n",
    "#    Ver notebook WorkflowSolucaoTCC como o Corpus foi criado (pdf->txt->DS) e o dataset dividido (train/test)\n",
    "#\n",
    "import datasets\n",
    "\n",
    "FOLDER_BASE = \"/home/info/MyNotebooks/Datasets/SentencasTRT1/\"\n",
    "DS_FOLDER   = FOLDER_BASE + \"DS/\"\n",
    "\n",
    "DsClassAnot = datasets.load_from_disk(DS_FOLDER+\"DsClassAnot/Train_Test\")\n",
    "DsClassAnot\n",
    "\n",
    "df_train = pd.DataFrame(DsClassAnot['train'])\n",
    "df_test = pd.DataFrame(DsClassAnot['test'])\n",
    "\n",
    "df_train = df_train.drop('disp', 1)\n",
    "df_train = df_train.drop('label', 1)\n",
    "\n",
    "df_test = df_test.drop('disp', 1)\n",
    "df_test = df_test.drop('label', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69864fb",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff3feee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42892501",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06875836",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b282812a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f5935a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RobertaConfig' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b0084d126098>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Step 5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m config = RobertaConfig(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mvocab_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8192\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmax_position_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m514\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'RobertaConfig' is not defined"
     ]
    }
   ],
   "source": [
    "# Step 5\n",
    "\n",
    "config = RobertaConfig(\n",
    "    vocab_size=8192,\n",
    "    max_position_embeddings=514,\n",
    "    num_attention_heads=12,\n",
    "    num_hidden_layers=6,\n",
    "    type_vocab_size=1,\n",
    ")\n",
    "\n",
    "from transformers import RobertaForMaskedLM\n",
    "\n",
    "model = RobertaForMaskedLM(config=config)\n",
    "print('Num parameters: ',model.num_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e5d196",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abebbd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6.\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer):\n",
    "        # or use the RobertaTokenizer from `transformers` directly.\n",
    "\n",
    "        self.examples = []\n",
    "        \n",
    "        for example in df.values:\n",
    "            x=tokenizer.encode_plus(example, max_length = MAX_LEN, truncation=True, padding=True)\n",
    "            self.examples += [x.input_ids]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        # We’ll pad at the batch level.\n",
    "        return torch.tensor(self.examples[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e753b884",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e475aa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e1b889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7.\n",
    "# Create the train and evaluation dataset\n",
    "train_tokenized_ds = CustomDataset(df_train['text'], tokenizer)\n",
    "test_tokenized_ds  = CustomDataset(df_test['text'], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16941025",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ae9d67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e3478c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f326a94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a190eea2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a3b590",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb4f8b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a64a9c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95b69c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96573d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.\n",
    "# CONFIGURING THE MODEL\n",
    "# initialize our model using the configuration file\n",
    "\n",
    "from transformers import RobertaConfig\n",
    "from transformers import RobertaForMaskedLM\n",
    "\n",
    "# Set a configuration for our RoBERTa model\n",
    "config = RobertaConfig(\n",
    "    vocab_size=8192,\n",
    "    max_position_embeddings=514,\n",
    "    num_attention_heads=12,\n",
    "    num_hidden_layers=6,\n",
    "    type_vocab_size=1,\n",
    ")\n",
    "# Initialize the model from a configuration without pretrained weights\n",
    "model = RobertaForMaskedLM(config=config)\n",
    "print('Num parameters: ',model.num_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2e889e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cf0839",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6210b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d96f53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef7ec6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359ffec1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b62def9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98610372",
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b2a1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d666a351",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab7ae0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd20faf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9?\n",
    "\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "# Define the Data Collator\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccdf353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10.\n",
    "\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "\n",
    "model_folder = \"/home/info/MyNotebooks/RobertaSenTRT/Model\"\n",
    "print(model_folder)\n",
    "\n",
    "# Define the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_folder,\n",
    "    overwrite_output_dir=True,\n",
    "    evaluation_strategy = 'epoch',\n",
    "    num_train_epochs=TRAIN_EPOCHS,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    per_device_train_batch_size=TRAIN_BATCH_SIZE,\n",
    "    per_device_eval_batch_size=VALID_BATCH_SIZE,\n",
    "    save_steps=8192,\n",
    "    #eval_steps=4096,\n",
    "    save_total_limit=1,\n",
    ")\n",
    "# Create the trainer for our model\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_tokenized_ds,\n",
    "    eval_dataset=test_tokenized_ds,\n",
    "    #prediction_loss_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4de88a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18e94dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ[\"WANDB_DISABLED\"] = \"True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2068b5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 11.\n",
    "# Train the model\n",
    "import torch\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5611976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12.\n",
    "# Saving the model\n",
    "\n",
    "out_fold = model_folder+\"/outs\"\n",
    "\n",
    "trainer.save_model(out_fold)\n",
    "\n",
    "#trainer.save_model(f'out_fold{i}')\n",
    "#trainer.save_model(model_folder)\n",
    "\n",
    "# trainer.save_model()\n",
    "# trainer.save_model(f'out_fold{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f53a0aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e8340f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d3fc61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72da91d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c1e787",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ce4c13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10df80cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22188fd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e07b2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aaa1b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINE TUNING DAQUI PARA BAIXO. ABRIR EM OUTRO NOTEBOOK!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c946ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ca6852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine tuning a Roberta Classification\n",
    "# https://jesusleal.io/2020/10/20/RoBERTA-Text-Classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109a6843",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datasets\n",
    "from transformers import RobertaTokenizerFast, RobertaForSequenceClassification,Trainer, TrainingArguments\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from tqdm import tqdm\n",
    "#import wandb\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a19b7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nom_Classes = [\"Acordo ou outros\", \"Improcedente\", \"Procedente\",\"Parcialmente procedente\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d987e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 Cria DataFrames e as LISTAS contendo dados das sentenças e as classificacoes.\n",
    "df_train_class = pd.DataFrame(DsClassAnot['train'])\n",
    "df_train_class = df_train_class.drop('text', 1)\n",
    "df_train_class.rename(columns = {'disp':'text'}, inplace = True)\n",
    "Labels_train_class   = df_train_class['label']\n",
    "#df_train_class = df_train_class.drop('label', 1)\n",
    "\n",
    "# 4.2 Cria DataFrames e as LISTAS contendo dados das sentenças e as classificacoes.\n",
    "df_test_class = pd.DataFrame(DsClassAnot['test'])\n",
    "df_test_class = df_test_class.drop('text', 1)\n",
    "df_test_class.rename(columns = {'disp':'text'}, inplace = True)\n",
    "Labels_test   = df_test_class['label']\n",
    "#df_test_class = df_train_class.drop('label', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6d1be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_train['text'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1e9865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train['text'] = df_train['text'][-1000:-1]  # Tomando a ultima parte do Dispositivo melhora a previsão?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a4dcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_train_class['text'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b89ff7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65306dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoder(df):\n",
    "    one_hot_encoding = []\n",
    "    for i in tqdm(range(len(df))):\n",
    "        temp = [0] * n_labels\n",
    "        label_indices = df.iloc[i][\"label\"]\n",
    "        for index in label_indices:\n",
    "            temp[index] = 1\n",
    "        one_hot_encoding.append(temp)\n",
    "        \n",
    "    return pd.DataFrame(one_hot_encoding)\n",
    "\n",
    "train_ohe_labels = one_hot_encoder(train)\n",
    "valid_ohe_labels = one_hot_encoder(valid)\n",
    "test_ohe_labels = one_hot_encoder(test)\n",
    "\n",
    "print(train_ohe_labels.shape)\n",
    "#(43410, 28)\n",
    "\n",
    "train = pd.concat([train, train_ohe_labels], axis=1)\n",
    "valid = pd.concat([valid, valid_ohe_labels], axis=1)\n",
    "test = pd.concat([test, test_ohe_labels], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25cd026",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nom_Classes = [\"Acordo ou outros\", \"Improcedente\", \"Procedente\",\"Parcialmente procedente\"]\n",
    "n_labels = len(Nom_Classes)\n",
    "n_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f45e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoder(df):\n",
    "    one_hot_encoding = []\n",
    "    for i in tqdm(range(len(df))):\n",
    "        temp = [0] * n_labels\n",
    "        label_indices = df.iloc[i][\"label\"]\n",
    "        for index in label_indices:\n",
    "            temp[index] = 1\n",
    "        one_hot_encoding.append(temp)\n",
    "        \n",
    "    df_ohe_labels = pd.DataFrame(one_hot_encoding)    \n",
    "    return pd.concat([df, df_ohe_labels], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd042d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ohe = one_hot_encoder(df_train_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24b837f",
   "metadata": {},
   "outputs": [],
   "source": [
    "OHE_Classes = [torch.Tensor([1,0,0,0]),torch.Tensor([0,1,0,0]),torch.Tensor([0,0,1,0]),torch.Tensor([0,0,0,1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6f0672",
   "metadata": {},
   "outputs": [],
   "source": [
    "teste = OHE_Classes[3]\n",
    "teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d33613",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F \n",
    "\n",
    "F.one_hot(teste, num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ebef71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3fd9bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d5b1fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1818fe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora sim, funcionando!\n",
    "import pandas as pd\n",
    "\n",
    "def label_ohe(df):\n",
    "    Nom_Classes = [\"Acordo ou outros\", \"Improcedente\", \"Procedente\",\"Parcialmente procedente\"]\n",
    "    OHE_Classes = [(1,0,0,0),(0,1,0,0),(0,0,1,0),(0,0,0,1)]\n",
    "       \n",
    "    for i in range(len(df)):\n",
    "        for j in range(len(Nom_Classes)):\n",
    "            if df['label'][i] == Nom_Classes[j]:\n",
    "                df['label'][i] = OHE_Classes[j]\n",
    "    #print(df['label'][100])\n",
    "    return(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91b002e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_class = label_ohe(df_train_class)\n",
    "df_test_class = label_ohe(df_test_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6885cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df_test_class['label'][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f04d694",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_class['label'] = list(df_test_class['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bd1386",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_class['label'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbb8cf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28c66e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b1ea77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3234bbaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb84ccb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd8c642",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8b184b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f8ee29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7d5650",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c076963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nao precisa mais deste trecho!\n",
    "import pandas as pd\n",
    "\n",
    "def label_ids(df):\n",
    "    Nom_Classes = [\"Acordo ou outros\", \"Improcedente\", \"Procedente\",\"Parcialmente procedente\"]\n",
    "       \n",
    "    for i in range(len(df)):\n",
    "        for j in range(len(Nom_Classes)):\n",
    "            if df['label'][i] == Nom_Classes[j]:\n",
    "                df['label'][i] = j                \n",
    "    return(df)\n",
    "\n",
    "# Como ficaria este processamento com list compreension?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d085f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_class = label_ids(df_train_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7f231e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_class = label_ids(df_test_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36c3092",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_class['label'][13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14ea947",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "train_data = Dataset.from_pandas(df_train_class)\n",
    "test_data  = Dataset.from_pandas(df_test_class)\n",
    "\n",
    "#ataset_target = DatasetDict()\n",
    "#ataset_target['train'] = dataset_train\n",
    "#ataset_target['test'] = dataset_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c122b9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c63511",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['label'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea69c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_data['label'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1886d5c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccad4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar o modelo treinado.\n",
    "model_path = \"/home/info/MyNotebooks/RobertaSenTRT/Model/outs\"\n",
    "vocab_path = \"/home/info/MyNotebooks/RobertaSenTRT/Tokenizer\"\n",
    "#'roberta-base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f3d888",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a611ce35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model and tokenizer and define length of the text sequence\n",
    "roberta_model = RobertaForSequenceClassification.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba91f601",
   "metadata": {},
   "outputs": [],
   "source": [
    "#roberta_tokenizer = RobertaTokenizerFast.from_pretrained(vocab_path, max_length = 512)\n",
    "roberta_tokenizer = RobertaTokenizerFast.from_pretrained(tokenizer_folder, max_len=MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefb8b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that will tokenize the model, and will return the relevant inputs for the model\n",
    "def tokenization(batched_text):\n",
    "    return roberta_tokenizer(batched_text['text'], padding = True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac2faa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.map(tokenization, batched = True, batch_size = len(train_data))\n",
    "test_data = test_data.map(tokenization, batched = True, batch_size = len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1064e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e99ea79",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9827772b",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939994c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_data['label'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01aa11b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20df606d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e88c24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0194c32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9094e7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ade54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a5a6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train_data)):\n",
    "    train_data['label'][i] = str(train_data['label'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f7852a",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_data['label'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b36be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['label'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a725a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8d21ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8d7415",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f71b9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86dd366",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee639c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.set_format('torch', columns=['attention_mask','input_ids','label'])\n",
    "#train_data.set_format('torch', columns=['attention_mask','input_ids'])\n",
    "test_data.set_format('torch', columns=['attention_mask','input_ids','label'])\n",
    "#test_data.set_format('torch', columns=['attention_mask','input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c493e50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_data['input_ids'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12600fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8643b516",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['label'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14f9a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9b9d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7582f874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset(features: {'text': Value(dtype='string', id=None), \n",
    "#'label': ClassLabel(num_classes=2, names=['neg', 'pos'], names_file=None, id=None)}, num_rows: 25000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86569efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ClassLabel(num_classes=4, names=[\"Acordo ou outros\", \"Improcedente\", \"Procedente\",\"Parcialmente procedente\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6376628",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2840d4e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83438765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define accuracy metrics\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d862912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = '/home/info/MyNotebooks/RobertaSenTRT/Model/outs_classification',\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size = 4,\n",
    "    gradient_accumulation_steps = 16,    \n",
    "    per_device_eval_batch_size= 8,\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    disable_tqdm = False, \n",
    "    #load_best_model_at_end=True,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps = 8,\n",
    "    fp16 = False, # era True\n",
    "    logging_dir='/home/info/MyNotebooks/RobertaSenTRT/Model/outs_classification/logs',\n",
    "    #dataloader_num_workers = 1, # Era 8\n",
    "    run_name = 'roberta-classification'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b738373e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the trainer class and check for available devices\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_tokenized_ds,\n",
    "    eval_dataset=test_tokenized_ds\n",
    ")\n",
    "#device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = 'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d614676",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokenized_ds[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42074902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a2c5bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb3cb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How about to train a DistilBert (ligthweigth) model from Scratch?\n",
    "# Or a T5 (multitask) model?\n",
    "# Ver também as APIs para acesso a modelos que aceleram a sua utilização na produção (Accelerated Inference API):\n",
    "# https://api-inference.huggingface.co/docs/python/html/index.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
