{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c303da20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb3e4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A helper function that takes a Hugging Face Dataset, the name of the corresponding sentence field on that Dataset,\n",
    "# the name of the label field on Dataset and a Tokenizer to output a tokenized TensorDataset:\n",
    "# Source: DL with Python, sbs - Godoy, Vol2. p√°g.: 1119."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9aba617",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_dataset(hf_dataset, sentence_field, label_field, tokenizer, **kwargs):\n",
    "    \n",
    "    sentences  = hf_dataset[sentence_field]\n",
    "    tokens_ids = tokenizer(sentences, return_tensors='pt', **kwargs)['input_ids']\n",
    "    \n",
    "    labels     = torch.as_tensor(hf_dataset[label_field])\n",
    "    \n",
    "    dataset    = TensorDataset(token_ids, labels)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a677785e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69343522",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071baa14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfce4dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118b435f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1760a29f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e22679",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelo          = 'distilbert-base-uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1076ae2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_tokenizer  = AutoTokenizer.from_pretrained(modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a701024b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tkzr_kwargs     = dict(truncation=True, padding=True, max_length=30, add_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7629f4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39920155",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tensor_ds = tokenize_dataset(train_dataset, 'sentence', 'label', auto_tokenizer, **tkzr_kwargs)\n",
    "test_tensor_ds  = tokenize_dataset(test_dataset, 'sentence', 'label', auto_tokenizer, **tkzr_kwargs)\n",
    "\n",
    "generator       = torch.Generator()\n",
    "\n",
    "train_loader    = DataLoader(train_tensor_ds, batch_size=4, suffle=True, generator=generator)\n",
    "test_loader     = DataLoader(test_tensor_ds, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbe4f5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb29bb78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8cd2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another variation is:\n",
    "# Source: page 1127\n",
    "\n",
    "auto_tokenizer     = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "def tokenize(row):\n",
    "    return auto_tokenizer(row['sentence_field'],truncation=True, padding=max_length, max_length=30)\n",
    "\n",
    "tokenized_train_ds = train_dataset.map(tokenize, batched=True)\n",
    "tokenized_test_ds  = test_dataset.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfa4cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions    = np.argmax(eval_pred.predictions, axis=1)\n",
    "    labels         = eval_pred.label_ids\n",
    "    return {\"Accuracy: \": (predictions == labels).mean()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34487a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "training_args      = TrainingArguments(\n",
    "    output_dir     = 'output',\n",
    "    num_train-epochs = 1,\n",
    "    per_device_train_batch_size = 1,\n",
    "    per_device_eval_batch_size = 8,\n",
    "    evaluation_strategy = 'steps',\n",
    "    eval_steps     = 300,\n",
    "    loggin_steps   = 300,\n",
    "    gradient_accumulation_steps = 8\n",
    ")\n",
    "\n",
    "trainer            = Trainer(model=bert_cls, \n",
    "                             args=training_args\n",
    "                             train_datset=tokenized_train_ds,\n",
    "                             eval_dataset=tokenized_test_ds,\n",
    "                             compute_metrics=compute_metrics)\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a44dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd113e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('MyBert')\n",
    "os.listdir('MyBert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc4ea4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See predictions on 1135 page!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acd9c8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5163cc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.pipelines import SUPPORTED_TASKS\n",
    "SUPPORTED_TASKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e591c3ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d5f687",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7e89c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading a dataset from a CSV file:\n",
    "# Source: page 1145\n",
    "dataset            = load_dataset(path='csv',\n",
    "                      data_files=['path/to/csv.csv'],\n",
    "                      quotechar='\\\\',\n",
    "                      split=Split.TRAIN)\n",
    "\n",
    "shuffled_dataset   = dataset.shuffle(seed=42)\n",
    "\n",
    "split_dataset      = shuffled_dataset.train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "train_dataset      = split_dataset['train']\n",
    "test_dataset       = split_dataset['test']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78843db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fabfe7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cf7119",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
