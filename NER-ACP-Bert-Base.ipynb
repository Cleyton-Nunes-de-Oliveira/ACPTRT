{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76b2984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar o modelo LM pre-treinado nas Sentenças nas Tarefas de NLP especifica (NER) usando Adapters.\n",
    "# https://github.com/piegu/language-models/blob/master/adapters/language-modeling/language_modeling_adapter.ipynb\n",
    "# https://github.com/piegu/language-models/blob/master/adapters/token-classification/token_classification_adapter.ipynb\n",
    "# https://huggingface.co/course/chapter7/2?fw=pt\n",
    "# https://huggingface.co/course/chapter7/3?fw=pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bf8b04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518fc68b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f74fc70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92052277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: 3.8.13 (default, Mar 28 2022, 11:38:47) \n",
      "[GCC 7.5.0]\n",
      "Pytorch: 1.12.0+cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-05 01:41:22.921969: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-05 01:41:22.921982: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/home/info/.conda/envs/acptrt1/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adapter-transformers: 4.17.0\n",
      "tokenizers: 0.12.1\n",
      "datasets: 1.11.0\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from colorama import Fore, Back, Style\n",
    "import random\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "\n",
    "import sys; print('python:',sys.version)\n",
    "import torch; print('Pytorch:',torch.__version__)\n",
    "import transformers; print('adapter-transformers:',transformers.__version__)\n",
    "#import transformers; print('HF transformers:',transformers.__hf_version__)     # <======\n",
    "import tokenizers; print('tokenizers:',tokenizers.__version__)\n",
    "\n",
    "import datasets; print('datasets:',datasets.__version__)\n",
    "from datasets import DatasetDict, Dataset, ClassLabel, Sequence\n",
    "from datasets import load_dataset, load_metric\n",
    "from datasets import Value \n",
    "\n",
    "from transformers.adapters.composition import Stack\n",
    "from transformers.trainer_callback import EarlyStoppingCallback\n",
    "from transformers import AdapterConfig\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "from transformers import AutoModelForTokenClassification, AutoTokenizer, TrainingArguments, Trainer\n",
    "from transformers import AutoTokenizer \n",
    "\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.nn import ModuleDict\n",
    "\n",
    "#!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f05e5d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f818e0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1d6199",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5c688b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#root path ==================================================\n",
    "# root = Path.cwd()\n",
    "model_checkpoint = \"/home/info/MyNotebooks/bert-base-portuguese-cased-finetuned-ACP/checkpoint-1500/\"\n",
    "\n",
    "root = Path(\"/home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP\")\n",
    "root = Path(root)\n",
    "root\n",
    "\n",
    "\n",
    "# DATASET ==================================================\n",
    "#\n",
    "# LeNER-br in Portuguese\n",
    "dataset_name = \"LeNER-Br\"\n",
    "dataset_file = \"/home/info/MyNotebooks/Datasets/LeNER-Br/LeNER-Br/\"\n",
    "\n",
    "\n",
    "# train BERT with 2 sentences consecutive ==================================================\n",
    "next_sentence = True\n",
    "\n",
    "task = \"ner\"\n",
    "\n",
    "\n",
    "# Main hyperparameters\n",
    "# training arguments ==================================================\n",
    "batch_size = 8\n",
    "gradient_accumulation_steps = 1\n",
    "\n",
    "learning_rate = 1e-4\n",
    "num_train_epochs = 3 # 20.\n",
    "early_stopping_patience = 5\n",
    "\n",
    "adam_epsilon = 1e-6\n",
    "\n",
    "fp16 = True\n",
    "ds = False # If True, we use DeepSpeed\n",
    "\n",
    "# best model\n",
    "load_best_model_at_end = True \n",
    "metric_for_best_model = \"f1\"\n",
    "greater_is_better = True\n",
    "\n",
    "# weighted loss\n",
    "weighted_loss = True #False\n",
    "if weighted_loss:\n",
    "    c = 0.3\n",
    "else:\n",
    "    c = 0.0\n",
    "\n",
    "\n",
    "    \n",
    "# train adapter ==================================================\n",
    "train_adapter = True # we want to train an adapter\n",
    "load_adapter = None # we do not upload an existing adapter \n",
    "\n",
    "# lang adapter ==================================================\n",
    "with_adapters_mlm = False #True # if False, we do not upload an existing lang adapter\n",
    "\n",
    "if with_adapters_mlm:\n",
    "    # define values to upload a specific lang adapter\n",
    "    adapter_composition = \"stack\" # we will stack the lang and task adapters\n",
    "else:\n",
    "    adapter_composition = None\n",
    "\n",
    "# if True, do not put adapter in the last transformer layer (Pfeiffer configuration)\n",
    "madx2 = True\n",
    "\n",
    "# if True, do not put adapter in the last transformer layer after the FeedFordarw block (Houlsby configuration)\n",
    "houlsby_MHA_lastlayer = False\n",
    "\n",
    "\n",
    "# Configuration ==================================================\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "torch.cuda.is_available = lambda : False\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device\n",
    "\n",
    "\n",
    "\n",
    "## Adapters config\n",
    "# Task adapter config ==================================================\n",
    "\n",
    "adapter_config_name = \"pfeiffer\" # houlsby is possible, too\n",
    "if adapter_config_name == \"pfeiffer\":\n",
    "    adapter_non_linearity = 'gelu' # relu is possible, too\n",
    "elif adapter_config_name == \"houlsby\":\n",
    "    adapter_non_linearity = 'swish'\n",
    "adapter_reduction_factor = 16\n",
    "language = 'pt' # pt = Portuguese\n",
    "\n",
    "adapter_config_name, adapter_non_linearity, adapter_reduction_factor, language\n",
    "\n",
    "\n",
    "# Lang adapter config  ==================================================\n",
    "if with_adapters_mlm:\n",
    "    # AQUI PODE ESTAR O PROBLEMA! Mas todos hiperparametros referem-se ao _mlm!\n",
    "    #\n",
    "    # hyperparameters used for fine-tuning the MLM with lang adapter\n",
    "    learning_rate_mlm = 1e-4\n",
    "    batch_size_mlm = 16\n",
    "    gradient_accumulation_steps_mlm = 1\n",
    "    adam_epsilon_mlm = 1e-6\n",
    "    num_train_epoch_mlm = 100.\n",
    "    early_stopping_patience_mlm = 10\n",
    "    madx2_mlm = madx2\n",
    "    houlsby_MHA_lastlayer_mlm = houlsby_MHA_lastlayer\n",
    "    ds_mlm = False\n",
    "    fp16_mlm = True\n",
    "    load_best_model_at_end_mlm = True\n",
    "    metric_for_best_model_mlm = \"loss\"\n",
    "    adapter_config_mlm = adapter_config_name+\"+inv\"\n",
    "    \n",
    "    # path to lang adapter\n",
    "    #outputs_mlm = model_checkpoint.replace('/','-') + '_' + dataset_name + '/' + 'mlm' + '/' \\\n",
    "    outputs_mlm = 'NER-ACP-Bert' + '_' + dataset_name + '/' + 'mlm' + '/' \\\n",
    "    + 'lr' + str(learning_rate_mlm) \\\n",
    "    + '_bs' + str(batch_size_mlm) \\\n",
    "    + '_GAS' + str(gradient_accumulation_steps_mlm) \\\n",
    "    + '_eps' + str(adam_epsilon_mlm) \\\n",
    "    + '_epochs' + str(num_train_epoch_mlm) \\\n",
    "    + '_patience' + str(early_stopping_patience_mlm) \\\n",
    "    + '_madx2' + str(madx2_mlm) \\\n",
    "    + '_houlsby_MHA_lastlayer' + str(houlsby_MHA_lastlayer_mlm) \\\n",
    "    + '_ds' + str(ds_mlm) \\\n",
    "    + '_fp16' + str(fp16_mlm) \\\n",
    "    + '_best' + str(load_best_model_at_end_mlm) \\\n",
    "    + '_metric' + str(metric_for_best_model_mlm) \\\n",
    "    + '_adapterconfig' + str(adapter_config_mlm)\n",
    "    \n",
    "    path_to_outputs_mlm = root/'outputs'/outputs_mlm\n",
    "    \n",
    "    # Config of the lang adapter\n",
    "    lang_adapter_path = path_to_outputs_mlm/'adapters-mlm/'\n",
    "    \n",
    "    load_lang_adapter = str(lang_adapter_path)\n",
    "    lang_adapter_config = str(lang_adapter_path) + \"/adapter_config.json\"\n",
    "    if adapter_config_mlm == \"pfeiffer+inv\":\n",
    "        lang_adapter_non_linearity = 'gelu' # relu is possible, too\n",
    "    elif adapter_config_mlm == \"houlsby+inv\":\n",
    "        lang_adapter_non_linearity = 'swish'\n",
    "    lang_adapter_reduction_factor = 2\n",
    "    language_mlm = language\n",
    "\n",
    "\n",
    "    \n",
    "#setup the training argument ==================================================\n",
    "do_train = True \n",
    "do_eval = True \n",
    "\n",
    "# if you want to test the trainer, set up the following variables\n",
    "max_train_samples = 200 # None\n",
    "max_val_samples = 50 # None\n",
    "\n",
    "# epochs, bs, GA\n",
    "evaluation_strategy = \"epoch\" \n",
    "\n",
    "# fp16\n",
    "fp16_opt_level = 'O1'\n",
    "fp16_backend = \"auto\"\n",
    "fp16_full_eval = False\n",
    "\n",
    "# optimizer (AdamW)\n",
    "weight_decay = 0.01 # 0.0\n",
    "adam_beta1 = 0.9\n",
    "adam_beta2 = 0.999\n",
    "\n",
    "# scheduler\n",
    "lr_scheduler_type = 'linear'\n",
    "warmup_ratio = 0.0\n",
    "warmup_steps = 0\n",
    "\n",
    "# logs\n",
    "logging_strategy = \"steps\"\n",
    "logging_first_step = True # False\n",
    "logging_steps = 500     # if strategy = \"steps\"\n",
    "eval_steps = logging_steps # logging_steps\n",
    "\n",
    "# checkpoints\n",
    "save_strategy = \"epoch\" # steps\n",
    "save_steps = 500 # if save_strategy = \"steps\"\n",
    "save_total_limit = 1 # None\n",
    "\n",
    "# no cuda, seed\n",
    "no_cuda = True # False\n",
    "seed = 42\n",
    "\n",
    "# bar\n",
    "disable_tqdm = False # True\n",
    "remove_unused_columns = True\n",
    "\n",
    "\n",
    "\n",
    "# folder for training outputs ==================================================\n",
    "\n",
    "#if model_checkpoint == \"neuralmind/bert-large-portuguese-cased\":\n",
    "if model_checkpoint == \"neuralmind/bert-base-portuguese-cased\":\n",
    "    outputs = model_checkpoint.replace('/','-') + '_' + dataset_name\n",
    "else:\n",
    "    #outputs = model_output\n",
    "    outputs = \"NER-ACP_\"\n",
    "    \n",
    "if with_adapters_mlm:\n",
    "    outputs = outputs + '/' + 'mlm_' + str(task) + '_AdCompo' + str(adapter_composition) + '/'\n",
    "else:\n",
    "    outputs = outputs + '/' + str(task) + '/'\n",
    "\n",
    "outputs = outputs \\\n",
    "+ 'lr' + str(learning_rate) \\\n",
    "+ '_bs' + str(batch_size) \\\n",
    "+ '_epochs' + str(num_train_epochs) \\\n",
    "+ '_patience' + str(early_stopping_patience) \\\n",
    "+ '_wamlm' + str(with_adapters_mlm) \\\n",
    "+ '_madx2' + str(madx2) \\\n",
    "+ '_houlsby_MHA_lastlayer' + str(houlsby_MHA_lastlayer) \\\n",
    "+ '_ds' + str(ds) \\\n",
    "+ '_fp16' + str(fp16) \\\n",
    "+ '_best' + str(load_best_model_at_end) \\\n",
    "+ '_metric' + str(metric_for_best_model) \\\n",
    "+ '_weightedloss' + str(weighted_loss) \\\n",
    "+ '_c' + str(c) \\\n",
    "+ '_ns' + str(next_sentence) \\\n",
    "+ '_adapterconfig' + str(adapter_config_name)  \n",
    "\n",
    "# path to outputs\n",
    "#path_to_outputs = Path(path_to_outputs)\n",
    "path_to_outputs = root/'outputs'/outputs\n",
    "\n",
    "# subfolder for model outputs\n",
    "output_dir = path_to_outputs/'output_dir' \n",
    "overwrite_output_dir = True # False\n",
    "\n",
    "# logs\n",
    "logging_dir = path_to_outputs/'logging_dir'\n",
    "\n",
    "path_to_outputs\n",
    "#output_dir\n",
    "#logging_dir\n",
    "#root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93718f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3098fba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2c221a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a319cf73",
   "metadata": {},
   "source": [
    "Adapters config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99e3f8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7322c8e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ed76ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8352f8ac",
   "metadata": {},
   "source": [
    "Loading the dataset\n",
    "https://huggingface.co/datasets/lener_br"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de157103",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset lener_br (/home/info/.cache/huggingface/datasets/lener_br/lener_br/1.0.0/4a8c97e6813b5c2d85a50faf0a3e6c24ea82f4a9044e6e9e8b24997d27399382)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags'],\n",
       "        num_rows: 7828\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags'],\n",
       "        num_rows: 1177\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags'],\n",
       "        num_rows: 1390\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download dataset from Huggingface Hub\n",
    "dataset_name_hf = \"lener_br\"\n",
    "datasets = load_dataset(dataset_name_hf)\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99ec98ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '0',\n",
       " 'tokens': ['EMENTA',\n",
       "  ':',\n",
       "  'APELAÇÃO',\n",
       "  'CÍVEL',\n",
       "  '-',\n",
       "  'AÇÃO',\n",
       "  'DE',\n",
       "  'INDENIZAÇÃO',\n",
       "  'POR',\n",
       "  'DANOS',\n",
       "  'MORAIS',\n",
       "  '-',\n",
       "  'PRELIMINAR',\n",
       "  '-',\n",
       "  'ARGUIDA',\n",
       "  'PELO',\n",
       "  'MINISTÉRIO',\n",
       "  'PÚBLICO',\n",
       "  'EM',\n",
       "  'GRAU',\n",
       "  'RECURSAL',\n",
       "  '-',\n",
       "  'NULIDADE',\n",
       "  '-',\n",
       "  'AUSÊNCIA',\n",
       "  'DE',\n",
       "  'INTERVENÇÃO',\n",
       "  'DO',\n",
       "  'PARQUET',\n",
       "  'NA',\n",
       "  'INSTÂNCIA',\n",
       "  'A',\n",
       "  'QUO',\n",
       "  '-',\n",
       "  'PRESENÇA',\n",
       "  'DE',\n",
       "  'INCAPAZ',\n",
       "  '-',\n",
       "  'PREJUÍZO',\n",
       "  'EXISTENTE',\n",
       "  '-',\n",
       "  'PRELIMINAR',\n",
       "  'ACOLHIDA',\n",
       "  '-',\n",
       "  'NULIDADE',\n",
       "  'RECONHECIDA',\n",
       "  '.'],\n",
       " 'ner_tags': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a730c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataset to disk\n",
    "datasets.save_to_disk(\"/home/info/MyNotebooks/Datasets/LeNER-Br/From_HuggingFace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e850a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbcf701f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequence(feature=ClassLabel(num_classes=13, names=['O', 'B-ORGANIZACAO', 'I-ORGANIZACAO', 'B-PESSOA', 'I-PESSOA', 'B-TEMPO', 'I-TEMPO', 'B-LOCAL', 'I-LOCAL', 'B-LEGISLACAO', 'I-LEGISLACAO', 'B-JURISPRUDENCIA', 'I-JURISPRUDENCIA'], names_file=None, id=None), length=-1, id=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"train\"].features[f\"ner_tags\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7750f88d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "So for the NER tags, 0 corresponds to 'O', 1 to 'B-ORGANIZACAO' etc... On top of the 'O' (which means no special entity), there are four labels for NER here, each prefixed with 'B-' (for beginning) or 'I-' (for intermediate), that indicate if the token is the first one for the current group with the label or not:\n",
    "\n",
    "    'ORGANIZACAO' for organization\n",
    "    'PESSOA' for person\n",
    "    'TEMPO' for data\n",
    "    'LOCAL' for location\n",
    "    'LEGISLACAO' for legislation\n",
    "    'JURISPRUDENCIA' for jurisprudence\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e5e7bb",
   "metadata": {},
   "source": [
    "Since the labels are lists of ClassLabel, the actual names of the labels are nested in the feature attribute of the object above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2489908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'B-ORGANIZACAO',\n",
       " 'I-ORGANIZACAO',\n",
       " 'B-PESSOA',\n",
       " 'I-PESSOA',\n",
       " 'B-TEMPO',\n",
       " 'I-TEMPO',\n",
       " 'B-LOCAL',\n",
       " 'I-LOCAL',\n",
       " 'B-LEGISLACAO',\n",
       " 'I-LEGISLACAO',\n",
       " 'B-JURISPRUDENCIA',\n",
       " 'I-JURISPRUDENCIA']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label_list = datasets[\"train\"].features[f\"{task}_tags\"].feature.names\n",
    "label_list = ['O',\n",
    " 'B-ORGANIZACAO',\n",
    " 'I-ORGANIZACAO',\n",
    " 'B-PESSOA',\n",
    " 'I-PESSOA',\n",
    " 'B-TEMPO',\n",
    " 'I-TEMPO',\n",
    " 'B-LOCAL',\n",
    " 'I-LOCAL',\n",
    " 'B-LEGISLACAO',\n",
    " 'I-LEGISLACAO',\n",
    " 'B-JURISPRUDENCIA',\n",
    " 'I-JURISPRUDENCIA']\n",
    "label_list\n",
    "\n",
    "# labels = datasets[\"train\"].features[f\"ner_tags\"].feature.names\n",
    "labels  = ['O',\n",
    " 'B-ORGANIZACAO',\n",
    " 'I-ORGANIZACAO',\n",
    " 'B-PESSOA',\n",
    " 'I-PESSOA',\n",
    " 'B-TEMPO',\n",
    " 'I-TEMPO',\n",
    " 'B-LOCAL',\n",
    " 'I-LOCAL',\n",
    " 'B-LEGISLACAO',\n",
    " 'I-LEGISLACAO',\n",
    " 'B-JURISPRUDENCIA',\n",
    " 'I-JURISPRUDENCIA']\n",
    "labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6951be",
   "metadata": {},
   "source": [
    "To get a sense of what the data looks like, the following function will show some examples picked randomly in the dataset (automatically decoding the labels in passing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f69e7543",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_random_elements(dataset, num_examples=10):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "        elif isinstance(typ, Sequence) and isinstance(typ.feature, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda x: [typ.feature.names[i] for i in x])\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1d5d26b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tokens</th>\n",
       "      <th>ner_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7441</td>\n",
       "      <td>[Incidência, da, Súmula, nº, 422, do, TST, .]</td>\n",
       "      <td>[O, O, B-JURISPRUDENCIA, I-JURISPRUDENCIA, I-JURISPRUDENCIA, I-JURISPRUDENCIA, I-JURISPRUDENCIA, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4666</td>\n",
       "      <td>[Reconheceu, ,, ainda, ,, a, Suprema, Corte, ,, no, julgamento, da, Rcl, 12.571-ED, ,, de, relatoria, do, excelentíssimo, Ministro, Dias, Toffoli, ,, que, ``, os, antigos, ferroviários, que, atuavam, perante, a, extinta, FEPASA, estavam, submetidos, ao, regime, jurídico, estatutário, e, não, à, Consolidação, das, Leis, do, Trabalho-CLT, '', .]</td>\n",
       "      <td>[O, O, O, O, O, B-ORGANIZACAO, I-ORGANIZACAO, O, O, O, O, B-JURISPRUDENCIA, I-JURISPRUDENCIA, O, O, O, O, O, O, B-PESSOA, I-PESSOA, O, O, O, O, O, O, O, O, O, O, O, B-ORGANIZACAO, O, O, O, O, O, O, O, O, O, B-LEGISLACAO, I-LEGISLACAO, I-LEGISLACAO, I-LEGISLACAO, I-LEGISLACAO, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>843</td>\n",
       "      <td>[Tome-se, ,, por, exemplo, ,, a, inadimplência, de, particulares, em, operações, de, crédito, regularmente, realizadas, -, ou, seja, ,, de, acordo, com, os, normativos, pertinentes, -, por, bancos, oficiais, .]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>279</td>\n",
       "      <td>[A, conclusão, foi, que, o, atendimento, do, interesse, público, no, âmbito, do, pregão, restou, irremediavelmente, comprometido, .]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>94</td>\n",
       "      <td>[Sobre, o, tema, ,, a, orientação, do, STJ, :, '', RECURSO, ESPECIAL, .]</td>\n",
       "      <td>[O, O, O, O, O, O, O, B-ORGANIZACAO, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6357</td>\n",
       "      <td>[O, que, ,, na, verdade, ,, objetiva, o, recorrente, e, a, rediscussão, de, questões, ,, matéria, que, não, cabe, na, presente, sede, .]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2175</td>\n",
       "      <td>[USURPAÇÃO, DE, COMPETÊNCIA, .]</td>\n",
       "      <td>[O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7143</td>\n",
       "      <td>[LEI, ROUANET, .]</td>\n",
       "      <td>[B-LEGISLACAO, I-LEGISLACAO, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3226</td>\n",
       "      <td>[8, .]</td>\n",
       "      <td>[O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2635</td>\n",
       "      <td>[15, .]</td>\n",
       "      <td>[O, O]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(datasets[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcd6d0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8c6c8a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['id', 'tokens', 'ner_tags'],\n",
       "     num_rows: 7828\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['id', 'tokens', 'ner_tags'],\n",
       "     num_rows: 1390\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['id', 'tokens', 'ner_tags'],\n",
       "     num_rows: 1177\n",
       " }))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"train\"], datasets[\"test\"], datasets[\"validation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055c680e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69505904",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf20890",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef57804b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b1d0cb24",
   "metadata": {},
   "source": [
    "Dataset analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2e094ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8105/2590705613.py:23: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  col.set_xticklabels(labels=list(sorted_ner_tags_dist.keys()),rotation=45)\n",
      "/tmp/ipykernel_8105/2590705613.py:29: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  col.set_xticklabels(labels=list(sorted_ner_tags_dist_without_O.keys()),rotation=45)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8105/2590705613.py:23: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  col.set_xticklabels(labels=list(sorted_ner_tags_dist.keys()),rotation=45)\n",
      "/tmp/ipykernel_8105/2590705613.py:29: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  col.set_xticklabels(labels=list(sorted_ner_tags_dist_without_O.keys()),rotation=45)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8105/2590705613.py:23: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  col.set_xticklabels(labels=list(sorted_ner_tags_dist.keys()),rotation=45)\n",
      "/tmp/ipykernel_8105/2590705613.py:29: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  col.set_xticklabels(labels=list(sorted_ner_tags_dist_without_O.keys()),rotation=45)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dsets = [\"train\",\"validation\",\"test\"]\n",
    "for dset in dsets:\n",
    "    # all tags\n",
    "    ner_tags_list = list()\n",
    "    for i,row in enumerate(datasets[dset]):\n",
    "        ner_tags_list += row['ner_tags']\n",
    "\n",
    "    # unique ner tags\n",
    "    ner_tags_unique = list(set(ner_tags_list))\n",
    "    ner_tags_unique = [labels[i] for i in ner_tags_unique]\n",
    "\n",
    "    # Analyse the Tag distribution\n",
    "    ner_tags_dist = Counter(ner_tags_list)\n",
    "    ner_tags_dist = {labels[k]:v for k,v in ner_tags_dist.items()}\n",
    "    sorted_ner_tags_dist = {k:ner_tags_dist[k] for k in labels}\n",
    "    \n",
    "    fig = plt.figure(figsize=(15,5))\n",
    "    axes = fig.subplots(nrows=1, ncols=2)\n",
    "\n",
    "    for i,col in enumerate(axes):\n",
    "            if i == 0: \n",
    "                col.bar(sorted_ner_tags_dist.keys(), sorted_ner_tags_dist.values(), width=1, color='g')\n",
    "                col.set_xticklabels(labels=list(sorted_ner_tags_dist.keys()),rotation=45)\n",
    "                col.set_title(f'{dset} dataset histogram')\n",
    "            if i == 1:\n",
    "                sorted_ner_tags_dist_without_O = sorted_ner_tags_dist.copy()\n",
    "                del_value = sorted_ner_tags_dist_without_O.pop('O')\n",
    "                col.bar(sorted_ner_tags_dist_without_O.keys(), sorted_ner_tags_dist_without_O.values(), width=1, color='g')\n",
    "                col.set_xticklabels(labels=list(sorted_ner_tags_dist_without_O.keys()),rotation=45)\n",
    "                col.set_title(f'{dset} dataset histogram (without the entity O)')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec25a5b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "There are 2 facts: the labels categories are very imbalanced and the train, validation and test datasets distributions are similar (which is a positive point).\n",
    "\n",
    "As a solution to the first point, we could test a weighted loss function in the trainer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb60a653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['id', 'tokens', 'ner_tags'],\n",
       "     num_rows: 7828\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['id', 'tokens', 'ner_tags'],\n",
       "     num_rows: 1390\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['id', 'tokens', 'ner_tags'],\n",
       "     num_rows: 1177\n",
       " }))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"train\"], datasets[\"test\"], datasets[\"validation\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d887b6e9",
   "metadata": {},
   "source": [
    "Preprocessing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17d8f29",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Before we can feed those texts to our model, we need to preprocess them. This is done by a 🤗 Transformers Tokenizer which will (as the name indicates) tokenize the inputs (including converting the tokens to their corresponding IDs in the pretrained vocabulary) and put it in a format the model expects, as well as generate the other inputs that model requires.\n",
    "\n",
    "To do all of this, we instantiate our tokenizer with the AutoTokenizer.from_pretrained method, which will ensure:\n",
    "\n",
    "    we get a tokenizer that corresponds to the model architecture we want to use,\n",
    "    we download the vocabulary used when pretraining this specific checkpoint.\n",
    "\n",
    "That vocabulary will be cached, so it's not downloaded again the next time we run the cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fe7f7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04518b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOKENIZER\n",
    "#\n",
    "tkzer_checkpoint = \"neuralmind/bert-base-portuguese-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(tkzer_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7ae598",
   "metadata": {},
   "source": [
    "The following assertion ensures that our tokenizer is a fast tokenizers (backed by Rust) from the 🤗 Tokenizers library. Those fast tokenizers are available for almost all models, and we will need some of the special features they have for our preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "924a4111",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(tokenizer, transformers.PreTrainedTokenizerFast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50c020e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 231, 2476, 125, 11798, 11588, 333, 16315, 243, 423, 418, 2245, 488, 119, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"O termo de compromisso deverá ser firmado pelo estagiário.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8461af2c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Depending on the model you selected, you will see different keys in the dictionary returned by the cell above. They don't matter much for what we're doing here (just know they are required by the model we will instantiate later), you can learn more about them in this tutorial if you're interested.\n",
    "\n",
    "If, as is the case here, your inputs have already been split into words, you should pass the list of words to your tokenzier with the argument is_split_into_words=True:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9696587f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 231, 2476, 125, 11798, 11588, 333, 16315, 243, 423, 418, 2245, 488, 119, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer([\"O\", \"termo\", \"de\", \"compromisso\", \"deverá\", \"ser\", \"firmado\", \"pelo\", \"estagiário\", \".\"], is_split_into_words=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5312bf66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe3a596d",
   "metadata": {},
   "source": [
    "Note that transformers are often pretrained with subword tokenizers, meaning that even if your inputs have been split into words already, each of those words could be split again by the tokenizer.\n",
    "\n",
    "For excample, the words \"Zwingmann\" and \"sheepmeat\" have been split in three subtokens.\n",
    "\n",
    "This means that we need to do some processing on our labels as the input ids returned by the tokenizer are longer than the lists of labels our dataset contain, first because some special tokens might be added (we can a [CLS] and a [SEP] above) and then because of those possible splits of words in multiple tokens.\n",
    "\n",
    "Thankfully, the tokenizer returns outputs that have a word_ids method which can help us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63812a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-', 'Preliminar', 'acolhida', 'para', 'reconhecer', 'a', 'nulidade', 'da', 'sentença', '.']\n"
     ]
    }
   ],
   "source": [
    "example = datasets[\"train\"][4]\n",
    "print(example[\"tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "253f2927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '-', 'Pre', '##lim', '##inar', 'acolh', '##ida', 'para', 'reconhecer', 'a', 'nu', '##li', '##dade', 'da', 'sentença', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "tokenized_input = tokenizer(example[\"tokens\"], is_split_into_words=True)\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa5e3df7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 17)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(example[f\"{task}_tags\"]), len(tokenized_input[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555551ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71c9d2b8",
   "metadata": {},
   "source": [
    "As we can see, it returns a list with the same number of elements as our processed input ids, mapping special tokens to None and all other tokens to their respective word. This way, we can align the labels with the processed input ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6b79ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 0, 1, 1, 1, 2, 2, 3, 4, 5, 6, 6, 6, 7, 8, 9, None]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_input.word_ids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6c18141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 17\n"
     ]
    }
   ],
   "source": [
    "word_ids = tokenized_input.word_ids()\n",
    "aligned_labels = [-100 if i is None else example[f\"{task}_tags\"][i] for i in word_ids]\n",
    "print(len(aligned_labels), len(tokenized_input[\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea049ae7",
   "metadata": {},
   "source": [
    "Here we set the labels of all special tokens to -100 (the index that is ignored by PyTorch) and the labels of all other tokens to the label of the word they come from. Another strategy is to set the label only on the first token obtained from a given word, and give a label of -100 to the other subtokens from the same word. We propose the two strategies here, just change the value of the following flag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "433abb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_all_tokens = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b00e36",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "We're now ready to write the function that will preprocess our samples. We feed them to the tokenizer with the argument truncation=True (to truncate texts that are bigger than the maximum size allowed by the model) and is_split_into_words=True (as seen above). Then we align the labels with the token ids using the strategy we picked:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "649cb372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original function: 1 sentence for the validation and test dataset\n",
    "def tokenize_and_align_labels(examples):\n",
    "#     tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True, max_length=512)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[f\"{task}_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n",
    "            # ignored in the loss function.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            # We set the label for the first token of each word.\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
    "            # the label_all_tokens flag.\n",
    "            else:\n",
    "                label_ids.append(label[word_idx] if label_all_tokens else -100)\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9dec7d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new with 2 sentences for the training dataset\n",
    "def tokenize_and_align_labels_next(examples):\n",
    "#     tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "\n",
    "    tokens_sentence = examples[\"tokens_sentence\"]\n",
    "    tokens_second_sentence = examples[\"tokens_second_sentence\"]\n",
    "    tokenized_inputs = tokenizer(tokens_sentence, tokens_second_sentence, truncation=True, is_split_into_words=True, max_length=512)\n",
    "\n",
    "    labels = []\n",
    "    \n",
    "    ner_tags_sentence = examples[\"ner_tags_sentence\"]\n",
    "    ner_tags_second_sentence = examples[\"ner_tags_second_sentence\"]\n",
    "    ner_tags_list = [tags1+tags2 for tags1, tags2 in zip(ner_tags_sentence, ner_tags_second_sentence)]\n",
    "    \n",
    "    for i, label in enumerate(ner_tags_list):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n",
    "            # ignored in the loss function.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            # We set the label for the first token of each word.\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
    "            # the label_all_tokens flag.\n",
    "            else:\n",
    "                label_ids.append(label[word_idx] if label_all_tokens else -100)\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc199fe8",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "This function works with one or several examples. In the case of several examples, the tokenizer will return a list of lists for each key.\n",
    "\n",
    "As you need to pass 2 consecutives sentences, let's create the datasets object new_datasets that contains the 3 datasets train, validation, test with a shifted of one sentence for train. Validation and test stay with just one sentence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d79bd17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 457 ms, sys: 14.2 ms, total: 472 ms\n",
      "Wall time: 514 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if next_sentence:\n",
    "        \n",
    "    # train dataset\n",
    "    folders = ['train']\n",
    "    new_datasets = DatasetDict()\n",
    "\n",
    "    for folder in folders:    \n",
    "\n",
    "        # content creation\n",
    "        new_ids = list()\n",
    "        tokens_sentence = list()\n",
    "        tokens_second_sentence = list()\n",
    "        ner_tags_sentence = list()\n",
    "        ner_tags_second_sentence = list()\n",
    "\n",
    "        df = datasets[folder].to_pandas()\n",
    "\n",
    "        for index, row in df.iterrows():\n",
    "            new_ids.append(index)\n",
    "            if index < len(df) - 1:\n",
    "                tokens_sentence.append(row['tokens'].tolist())\n",
    "                tokens_second_sentence.append(df['tokens'][index+1].tolist())\n",
    "                ner_tags_sentence.append(row['ner_tags'].tolist())\n",
    "                ner_tags_second_sentence.append(df['ner_tags'][index+1].tolist())\n",
    "            else:\n",
    "                tokens_sentence.append(row['tokens'].tolist())\n",
    "                tokens_second_sentence.append(df['tokens'][0].tolist())\n",
    "                ner_tags_sentence.append(row['ner_tags'].tolist())\n",
    "                ner_tags_second_sentence.append(df['ner_tags'][0].tolist())\n",
    "\n",
    "        # new DataFrame\n",
    "        columns = ['id','tokens_sentence','tokens_second_sentence','ner_tags_sentence','ner_tags_second_sentence']\n",
    "        df_new = pd.DataFrame(columns=columns)\n",
    "        df_new['id'] = pd.Series(new_ids)\n",
    "        df_new['tokens_sentence'] = pd.Series(tokens_sentence)\n",
    "        df_new['tokens_second_sentence'] = pd.Series(tokens_second_sentence)\n",
    "        df_new['ner_tags_sentence'] = pd.Series(ner_tags_sentence)\n",
    "        df_new['ner_tags_second_sentence'] = pd.Series(ner_tags_second_sentence)\n",
    "\n",
    "        # new Dataset   \n",
    "        new_datasets[folder] = Dataset.from_pandas(df_new)\n",
    "\n",
    "        # setup features\n",
    "        new_datasets[folder].features['tokens_sentence'] = datasets[folder].features['tokens']\n",
    "        new_datasets[folder].features['tokens_second_sentence'] = datasets[folder].features['tokens']\n",
    "        new_datasets[folder].features['ner_tags_sentence'] = datasets[folder].features['ner_tags']\n",
    "        new_datasets[folder].features['ner_tags_second_sentence'] = datasets[folder].features['ner_tags']\n",
    "        \n",
    "    # validation and test datasets\n",
    "    folders = ['validation', 'test']\n",
    "\n",
    "    for folder in folders:\n",
    "        if len(datasets[folder][0]['tokens']) > 0:\n",
    "            new_datasets[folder] = datasets[folder]\n",
    "        else:\n",
    "            # we do not keep the first row as it has no content\n",
    "            new_datasets[folder] = datasets[folder].select(list(range(1,datasets[folder].num_rows)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b48cad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'tokens_sentence', 'tokens_second_sentence', 'ner_tags_sentence', 'ner_tags_second_sentence'],\n",
      "        num_rows: 7828\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'tokens', 'ner_tags'],\n",
      "        num_rows: 1177\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'tokens', 'ner_tags'],\n",
      "        num_rows: 1390\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "if next_sentence:\n",
    "    print(new_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4f9045c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[101, 192, 7463, 8427, 22301, 131, 12127, 9008, 22301, 22402, 16484, 187, 22360, 22339, 9008, 118, 177, 22402, 16484, 10836, 13760, 7545, 22320, 22323, 22351, 22301, 22402, 16484, 212, 8718, 250, 7665, 6072, 213, 8718, 22301, 6538, 118, 11635, 9008, 13270, 7073, 6765, 118, 11741, 22328, 22341, 6392, 22301, 212, 9008, 22317, 213, 7073, 6538, 22321, 22352, 21748, 22317, 212, 22371, 22318, 22327, 6162, 22317, 192, 22311, 278, 5650, 22341, 257, 5476, 15289, 5903, 22327, 118, 248, 18199, 6392, 11836, 22309, 118, 177, 10409, 22420, 22320, 14298, 22301, 10836, 13760, 16017, 22322, 22339, 12547, 22402, 16484, 15040, 18868, 22322, 22349, 22341, 9208, 248, 22301, 13760, 11846, 22379, 22320, 14298, 22301, 177, 5226, 22341, 22317, 118, 11635, 3341, 12547, 22402, 22301, 10836, 13760, 4529, 5869, 22351, 118, 11635, 22309, 22333, 22341, 22360, 22351, 22317, 192, 22348, 6538, 16017, 8427, 22309, 118, 11635, 9008, 13270, 7073, 6765, 11247, 7918, 22340, 6392, 22301, 118, 248, 18199, 6392, 11836, 22309, 257, 5476, 12234, 22340, 5476, 6392, 22301, 119, 102, 118, 231, 1328, 119, 7048, 117, 1349, 117, 171, 8250, 22304, 543, 1128, 301, 179, 7740, 22279, 320, 3890, 7638, 558, 3718, 529, 8309, 173, 179, 1307, 6399, 125, 22250, 117, 2586, 243, 146, 1328, 119, 2680, 22315, 171, 653, 8178, 179, 146, 1673, 2810, 1444, 326, 625, 146, 3890, 7638, 346, 344, 14353, 201, 221, 12079, 146, 2160, 173, 179, 1981, 558, 3718, 119, 102], [101, 118, 231, 1328, 119, 7048, 117, 1349, 117, 171, 8250, 22304, 543, 1128, 301, 179, 7740, 22279, 320, 3890, 7638, 558, 3718, 529, 8309, 173, 179, 1307, 6399, 125, 22250, 117, 2586, 243, 146, 1328, 119, 2680, 22315, 171, 653, 8178, 179, 146, 1673, 2810, 1444, 326, 625, 146, 3890, 7638, 346, 344, 14353, 201, 221, 12079, 146, 2160, 173, 179, 1981, 558, 3718, 119, 102, 118, 9633, 214, 118, 176, 125, 2973, 18233, 2446, 4977, 1442, 2530, 240, 2760, 12787, 117, 253, 18604, 123, 7418, 171, 3890, 7638, 229, 5061, 125, 13816, 180, 2601, 10629, 119, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 10, 10, 10, 10, 10, 10, -100], [-100, 0, 0, 9, 10, 10, 10, 10, 10, 10, 10, 10, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100, 0, 0, 0, 0, 0, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100]]}\n"
     ]
    }
   ],
   "source": [
    "if next_sentence:\n",
    "    print(tokenize_and_align_labels_next(new_datasets['train'][:2]))\n",
    "else:\n",
    "    print(tokenize_and_align_labels(datasets['train'][:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55475be8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b1b7d6c4ce2442c8c8984076245af81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0467a63756eb4ebb9c00451673b49d74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e03720880c042fda2af5177222dc0f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if next_sentence:\n",
    "    tokenized_datasets = DatasetDict()\n",
    "    folders = ['train', 'validation', 'test']\n",
    "\n",
    "    for folder in folders:\n",
    "        if folder == 'train':\n",
    "            tokenized_datasets[folder] = new_datasets[folder].map(tokenize_and_align_labels_next, batched=True,\n",
    "                                                                   remove_columns=new_datasets[folder].column_names)\n",
    "        else:\n",
    "            tokenized_datasets[folder] = new_datasets[folder].map(tokenize_and_align_labels, batched=True,\n",
    "                                                                  remove_columns=new_datasets[folder].column_names) \n",
    "else:\n",
    "    tokenized_datasets = datasets.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5c8615dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['attention_mask', 'input_ids', 'labels', 'token_type_ids'],\n",
       "        num_rows: 7828\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['attention_mask', 'input_ids', 'labels', 'token_type_ids'],\n",
       "        num_rows: 1177\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['attention_mask', 'input_ids', 'labels', 'token_type_ids'],\n",
       "        num_rows: 1390\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "31596a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SALVA O DATASET TOKENIZADO.\n",
    "tokenized_datasets.save_to_disk(\"/home/info/MyNotebooks/Datasets/LeNER-Br/Tokenized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad0beff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d5d7a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CARREGA O DATASET TOKENIZADO.\n",
    "tokenized_datasets = datasets.load_from_disk(\"/home/info/MyNotebooks/Datasets/LeNER-Br/Tokenized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7f99009b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['attention_mask', 'input_ids', 'labels', 'token_type_ids'],\n",
       "     num_rows: 7828\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['attention_mask', 'input_ids', 'labels', 'token_type_ids'],\n",
       "     num_rows: 1390\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['attention_mask', 'input_ids', 'labels', 'token_type_ids'],\n",
       "     num_rows: 1177\n",
       " }))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets[\"train\"], tokenized_datasets[\"test\"], tokenized_datasets[\"validation\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3e0288",
   "metadata": {},
   "source": [
    "Let's verify that the training dataset has 2 tokonized sentences (token_type_ids = 0 and 1) and validation/test only one (token_type_ids = 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2a697fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "validation [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "test [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "folders = ['train', 'validation', 'test']\n",
    "\n",
    "for folder in folders:\n",
    "    print(folder, tokenized_datasets[folder][0]['token_type_ids'][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2a2fa31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "validation [-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11, 11, 11, 11, 11, 11, 11, 11, 0, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "test [-100, 0, 0, 0, 0, 0, 0, 11, 11, 11, 11, 11, 12, 12, 12, 12, 0, 1, 1, 1, 1, 1, 1, 0, 0, 3, 3, 3, 3, 3, 4, 4, 4, 4, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 0, -100]\n"
     ]
    }
   ],
   "source": [
    "for folder in folders:\n",
    "    print(folder, tokenized_datasets[folder][0]['labels'][:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fccf9f",
   "metadata": {},
   "source": [
    "Let's check the min and max of tokens in our tokenized sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0d6ef81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train min tokens: 7 - max tokens: 512\n",
      "validation min tokens: 2 - max tokens: 505\n",
      "test min tokens: 2 - max tokens: 512\n"
     ]
    }
   ],
   "source": [
    "folders = [\"train\", \"validation\", \"test\"]\n",
    "tokens_length = dict()\n",
    "\n",
    "for folder in folders:\n",
    "    tokens_length[folder] = list()\n",
    "    for i in range(tokenized_datasets[folder].num_rows):\n",
    "        tokens_length[folder].append(len(tokenized_datasets[folder][i]['token_type_ids']))\n",
    "    print(f'{folder} min tokens: {min(tokens_length[folder])} - max tokens: {max(tokens_length[folder])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149cdb75",
   "metadata": {},
   "source": [
    "Let's display the histograms of our tokenized train, validation and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0e5e8880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(15,5))\n",
    "axes = fig.subplots(nrows=1, ncols=3)\n",
    "\n",
    "for i,col in enumerate(axes):\n",
    "    folder = folders[i]\n",
    "    col.hist(tokens_length[folder], color='g')\n",
    "    col.set_title(f'{folder} dataset histogram')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c78eb68",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Even better, the results are automatically cached by the 🤗 Datasets library to avoid spending time on this step the next time you run your notebook. The 🤗 Datasets library is normally smart enough to detect when the function you pass to map has changed (and thus requires to not use the cache data). For instance, it will properly detect if you change the task in the first cell and rerun the notebook. 🤗 Datasets warns you when it uses cached files, you can pass load_from_cache_file=False in the call to map to not use the cached files and force the preprocessing to be applied again.\n",
    "\n",
    "Note that we passed batched=True to encode the texts by batches together. This is to leverage the full benefit of the fast tokenizer we loaded earlier, which will use multi-threading to treat the texts in a batch concurrently.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f7b78080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['attention_mask', 'input_ids', 'labels', 'token_type_ids'],\n",
       "    num_rows: 1177\n",
       "})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NAN on Validation computing\n",
    "# https://datatofish.com/check-nan-pandas-dataframe/\n",
    "# https://sparkbyexamples.com/pandas/pandas-drop-rows-with-nan-values-in-dataframe/\n",
    "tokenized_datasets['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "151e5a06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_set = pd.DataFrame(tokenized_datasets['validation'])\n",
    "val_set.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7bf16951",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = val_set.dropna(how='all').reset_index(drop=True)  # inplace=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "1ee30b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>token_type_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        attention_mask  \\\n",
       "80   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "81             [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
       "82   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "83   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "84   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "85   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "86   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "87   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "88   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "89                   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
       "90       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
       "91                                  [1, 1, 1, 1, 1, 1]   \n",
       "92   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "93   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "94                            [1, 1, 1, 1, 1, 1, 1, 1]   \n",
       "95   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "96   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "97   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "98   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "99   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "100   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
       "\n",
       "                                        token_type_ids  \n",
       "80   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "81             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "82   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "83   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "84   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "85   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "86   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "87   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "88   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "89                   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "90       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "91                                  [0, 0, 0, 0, 0, 0]  \n",
       "92   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "93   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "94                            [0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "95   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "96   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "97   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "98   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "99   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "100   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=80\n",
    "df_val[['attention_mask','token_type_ids']][x:x+21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7da951",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aaf9e50d",
   "metadata": {},
   "source": [
    "Fine-tuning the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d172349",
   "metadata": {},
   "source": [
    "Now that our data is ready, we can download the pretrained model and fine-tune it. Since all our tasks are about token classification, we use the AutoModelForTokenClassification class. Like with the tokenizer, the from_pretrained method will download and cache the model for us. The only thing we have to specify is the number of labels for our problem (which we can get from the features, as seen before):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4f017f2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13,\n",
       " ['O',\n",
       "  'B-ORGANIZACAO',\n",
       "  'I-ORGANIZACAO',\n",
       "  'B-PESSOA',\n",
       "  'I-PESSOA',\n",
       "  'B-TEMPO',\n",
       "  'I-TEMPO',\n",
       "  'B-LOCAL',\n",
       "  'I-LOCAL',\n",
       "  'B-LEGISLACAO',\n",
       "  'I-LEGISLACAO',\n",
       "  'B-JURISPRUDENCIA',\n",
       "  'I-JURISPRUDENCIA'])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_list), label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "17505f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13,\n",
       " ['O',\n",
       "  'B-ORGANIZACAO',\n",
       "  'I-ORGANIZACAO',\n",
       "  'B-PESSOA',\n",
       "  'I-PESSOA',\n",
       "  'B-TEMPO',\n",
       "  'I-TEMPO',\n",
       "  'B-LOCAL',\n",
       "  'I-LOCAL',\n",
       "  'B-LEGISLACAO',\n",
       "  'I-LEGISLACAO',\n",
       "  'B-JURISPRUDENCIA',\n",
       "  'I-JURISPRUDENCIA'])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2e2cac62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: 'O',\n",
       "  1: 'B-ORGANIZACAO',\n",
       "  2: 'I-ORGANIZACAO',\n",
       "  3: 'B-PESSOA',\n",
       "  4: 'I-PESSOA',\n",
       "  5: 'B-TEMPO',\n",
       "  6: 'I-TEMPO',\n",
       "  7: 'B-LOCAL',\n",
       "  8: 'I-LOCAL',\n",
       "  9: 'B-LEGISLACAO',\n",
       "  10: 'I-LEGISLACAO',\n",
       "  11: 'B-JURISPRUDENCIA',\n",
       "  12: 'I-JURISPRUDENCIA'},\n",
       " {'O': 0,\n",
       "  'B-ORGANIZACAO': 1,\n",
       "  'I-ORGANIZACAO': 2,\n",
       "  'B-PESSOA': 3,\n",
       "  'I-PESSOA': 4,\n",
       "  'B-TEMPO': 5,\n",
       "  'I-TEMPO': 6,\n",
       "  'B-LOCAL': 7,\n",
       "  'I-LOCAL': 8,\n",
       "  'B-LEGISLACAO': 9,\n",
       "  'I-LEGISLACAO': 10,\n",
       "  'B-JURISPRUDENCIA': 11,\n",
       "  'I-JURISPRUDENCIA': 12})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label = {id_: label for id_, label in enumerate(labels)}\n",
    "label2id = {label: id_ for id_, label in enumerate(labels)}\n",
    "id2label, label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a8ffd36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /home/info/MyNotebooks/bert-base-portuguese-cased-finetuned-ACP/checkpoint-1500/ were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at /home/info/MyNotebooks/bert-base-portuguese-cased-finetuned-ACP/checkpoint-1500/ and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# MODEL\n",
    "\n",
    "#from transformers import AutoModel\n",
    "\n",
    "#checkpoint = \"/home/info/MyNotebooks/bert-base-portuguese-cased-finetuned-ACP/checkpoint-1500/\"\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=len(label_list), id2label=id2label, label2id=label2id)\n",
    "#model2 = AutoModel.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2ac09d",
   "metadata": {},
   "source": [
    "The warning is telling us we are throwing away some weights (the vocab_transform and vocab_layer_norm layers) and randomly initializing some other (the pre_classifier and classifier layers). This is absolutely normal in this case, because we are removing the head used to pretrain the model on a masked language modeling objective and replacing it with a new head for which we don't have pretrained weights, so the library warns us we should fine-tune this model before using it for inference, which is exactly what we are going to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "270392c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108342541"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of model parameters\n",
    "model_num_param=0\n",
    "for p in model.parameters():\n",
    "    model_num_param+=p.numel()\n",
    "model_num_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "892eb40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model Checkpoint tem  225017600 parametros a mais.\n"
     ]
    }
   ],
   "source": [
    "print(\" Model Checkpoint tem \",333360141 - model_num_param,\"parametros a mais.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd8b64d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c67da1a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"_name_or_path\": \"/home/info/MyNotebooks/bert-base-portuguese-cased-finetuned-ACP/checkpoint-1500/\",\n",
       "  \"adapters\": {\n",
       "    \"adapters\": {},\n",
       "    \"config_map\": {},\n",
       "    \"fusion_config_map\": {},\n",
       "    \"fusions\": {}\n",
       "  },\n",
       "  \"architectures\": [\n",
       "    \"BertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"directionality\": \"bidi\",\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"id2label\": {\n",
       "    \"0\": \"O\",\n",
       "    \"1\": \"B-ORGANIZACAO\",\n",
       "    \"2\": \"I-ORGANIZACAO\",\n",
       "    \"3\": \"B-PESSOA\",\n",
       "    \"4\": \"I-PESSOA\",\n",
       "    \"5\": \"B-TEMPO\",\n",
       "    \"6\": \"I-TEMPO\",\n",
       "    \"7\": \"B-LOCAL\",\n",
       "    \"8\": \"I-LOCAL\",\n",
       "    \"9\": \"B-LEGISLACAO\",\n",
       "    \"10\": \"I-LEGISLACAO\",\n",
       "    \"11\": \"B-JURISPRUDENCIA\",\n",
       "    \"12\": \"I-JURISPRUDENCIA\"\n",
       "  },\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"label2id\": {\n",
       "    \"B-JURISPRUDENCIA\": 11,\n",
       "    \"B-LEGISLACAO\": 9,\n",
       "    \"B-LOCAL\": 7,\n",
       "    \"B-ORGANIZACAO\": 1,\n",
       "    \"B-PESSOA\": 3,\n",
       "    \"B-TEMPO\": 5,\n",
       "    \"I-JURISPRUDENCIA\": 12,\n",
       "    \"I-LEGISLACAO\": 10,\n",
       "    \"I-LOCAL\": 8,\n",
       "    \"I-ORGANIZACAO\": 2,\n",
       "    \"I-PESSOA\": 4,\n",
       "    \"I-TEMPO\": 6,\n",
       "    \"O\": 0\n",
       "  },\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"output_past\": true,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"pooler_fc_size\": 768,\n",
       "  \"pooler_num_attention_heads\": 12,\n",
       "  \"pooler_num_fc_layers\": 3,\n",
       "  \"pooler_size_per_head\": 128,\n",
       "  \"pooler_type\": \"first_token_transform\",\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"torch_dtype\": \"float32\",\n",
       "  \"transformers_version\": \"4.17.0\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 29794\n",
       "}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config\n",
    "# Nao teriamos que configurar previamente o id2label e label2id?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8ca081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.config.adapters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23fc140",
   "metadata": {},
   "source": [
    "9. Adapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6ae5060d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup adapters\n",
    "\n",
    "if train_adapter:\n",
    "        \n",
    "    # new\n",
    "    if madx2:\n",
    "        # do not add adapter in the last transformer layers \n",
    "        leave_out = [len(model.bert.encoder.layer)-1]\n",
    "    else:\n",
    "        leave_out = []\n",
    "        \n",
    "    # new\n",
    "    # task_name = data_args.dataset_name or \"mlm\"\n",
    "    task_name = \"ner\"\n",
    "    \n",
    "    # optionally load another pre-trained language adapter\n",
    "    if with_adapters_mlm:\n",
    "        # resolve the language adapter config\n",
    "        lang_adapter_config = AdapterConfig.load(\n",
    "                lang_adapter_config,\n",
    "                non_linearity=lang_adapter_non_linearity,\n",
    "                reduction_factor=lang_adapter_reduction_factor,\n",
    "                leave_out=leave_out,\n",
    "            )\n",
    "        # load the language adapter from Hub\n",
    "        task_mlm_load_as = 'mlm'\n",
    "        lang_adapter_name = model.load_adapter(\n",
    "                load_lang_adapter,\n",
    "                config=lang_adapter_config,\n",
    "                load_as=task_mlm_load_as,\n",
    "                with_head = False\n",
    "            )\n",
    "    else:\n",
    "        lang_adapter_name = None\n",
    "        \n",
    "    # check if adapter already exists, otherwise add it\n",
    "    if task_name not in model.config.adapters:\n",
    "            \n",
    "#             # resolve the adapter config\n",
    "#             adapter_config = AdapterConfig.load(\n",
    "#                 adapter_args.adapter_config,\n",
    "#                 non_linearity=adapter_args.adapter_non_linearity,\n",
    "#                 reduction_factor=adapter_args.adapter_reduction_factor,\n",
    "#             )\n",
    "\n",
    "        # new\n",
    "        # resolve adapter config with (eventually) the MAD-X 2.0 option\n",
    "        if adapter_config_name == \"pfeiffer\":\n",
    "            from transformers.adapters.configuration import PfeifferConfig\n",
    "            adapter_config = PfeifferConfig(non_linearity=adapter_non_linearity,\n",
    "                                            reduction_factor=adapter_reduction_factor,\n",
    "                                            leave_out=leave_out)           \n",
    "        elif adapter_config_name == \"pfeiffer+inv\":\n",
    "            from transformers.adapters.configuration import PfeifferInvConfig\n",
    "            adapter_config = PfeifferInvConfig(non_linearity=adapter_non_linearity,\n",
    "                                               reduction_factor=adapter_reduction_factor,\n",
    "                                               leave_out=leave_out)          \n",
    "        elif adapter_config_name == \"houlsby\":\n",
    "            from transformers.adapters.configuration import HoulsbyConfig\n",
    "            adapter_config = HoulsbyConfig(non_linearity=adapter_non_linearity,\n",
    "                                           reduction_factor=adapter_reduction_factor,\n",
    "                                           leave_out=leave_out)\n",
    "        elif adapter_config_name == \"houlsby+inv\":\n",
    "            from transformers.adapters.configuration import HoulsbyInvConfig\n",
    "            adapter_config = HoulsbyInvConfig(non_linearity=adapter_non_linearity,\n",
    "                                              reduction_factor=adapter_reduction_factor,\n",
    "                                              leave_out=leave_out)              \n",
    "                \n",
    "        # load a pre-trained from Hub if specified\n",
    "        if load_adapter:\n",
    "            model.load_adapter(\n",
    "                    load_adapter,\n",
    "                    config=adapter_config,\n",
    "                    load_as=task_name,\n",
    "                    with_head = False\n",
    "                )\n",
    "        # otherwise, add a fresh adapter\n",
    "        else:\n",
    "            model.add_adapter(task_name, config=adapter_config)\n",
    "            \n",
    "    # Set the adapters to be used in every forward pass\n",
    "    if lang_adapter_name:\n",
    "        model.active_adapters = Stack(task_mlm_load_as, task_name)\n",
    "    else:\n",
    "        model.set_active_adapters(task_name)\n",
    "\n",
    "    # Freeze all model weights except of those of this adapter\n",
    "    model.train_adapter([task_name])\n",
    "    \n",
    "else:\n",
    "    if load_adapter or load_lang_adapter:\n",
    "        raise ValueError(\n",
    "                \"Adapters can only be loaded in adapters training mode.\"\n",
    "                \"Use --train_adapter to enable adapter training\"\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de5b86c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ee5bae62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put only the adapter after the MHA but not after the FeedForward in the last layer\n",
    "if houlsby_MHA_lastlayer \\\n",
    "and train_adapter \\\n",
    "and not madx2 \\\n",
    "and task_name in model.config.adapters \\\n",
    "and (adapter_config_name == \"houlsby\" or adapter_config_name == \"houlsby+inv\"):\n",
    "    model.bert.encoder.layer[len(model.bert.encoder.layer)-1].output.adapters = ModuleDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "165d1192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109162525"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_adapter_num_param=0\n",
    "for p in model.parameters():\n",
    "    model_adapter_num_param+=p.numel()\n",
    "model_adapter_num_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7e48a9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters of the model with adapter: 109162525\n",
      "Number of parameters of the model without adapter: 108342541\n",
      "Number of parameters of the adapter: 819984\n",
      "Pourcentage of additional parameters through adapter: 0.76 %\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of parameters of the model with adapter: {model_adapter_num_param:.0f}\")\n",
    "print(f\"Number of parameters of the model without adapter: {model_num_param:.0f}\")\n",
    "print(f\"Number of parameters of the adapter: {model_adapter_num_param - model_num_param:.0f}\")\n",
    "print(f\"Pourcentage of additional parameters through adapter:\",round(((model_adapter_num_param - model_num_param)/model_num_param)*100,2),'%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c922f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c8b514",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af4339c3",
   "metadata": {},
   "source": [
    "10. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "85dc9cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if ds:\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        overwrite_output_dir=overwrite_output_dir,\n",
    "        do_train=do_train,\n",
    "        do_eval=do_eval,\n",
    "        evaluation_strategy=evaluation_strategy,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        adam_beta1=adam_beta1,\n",
    "        adam_beta2=adam_beta2,\n",
    "        adam_epsilon=adam_epsilon,\n",
    "        num_train_epochs=num_train_epochs,\n",
    "        lr_scheduler_type=lr_scheduler_type,\n",
    "        warmup_ratio=warmup_ratio,\n",
    "        warmup_steps=warmup_steps,\n",
    "        logging_dir=logging_dir,         # directory for storing logs\n",
    "        logging_strategy=evaluation_strategy,\n",
    "        logging_steps=logging_steps,     # if strategy = \"steps\"\n",
    "        save_strategy=evaluation_strategy,          # model checkpoint saving strategy\n",
    "        save_steps=logging_steps,        # if strategy = \"steps\"\n",
    "        save_total_limit=save_total_limit,\n",
    "        #fp16=fp16,\n",
    "        eval_steps=logging_steps,        # if strategy = \"steps\"\n",
    "        load_best_model_at_end=load_best_model_at_end,\n",
    "        metric_for_best_model=metric_for_best_model,\n",
    "        greater_is_better=greater_is_better,\n",
    "        #local_rank=gpu,\n",
    "        #deepspeed = ds_config\n",
    "        )\n",
    "else:\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        overwrite_output_dir=overwrite_output_dir,\n",
    "        do_train=do_train,\n",
    "        do_eval=do_eval,\n",
    "        evaluation_strategy=evaluation_strategy,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        adam_beta1=adam_beta1,\n",
    "        adam_beta2=adam_beta2,\n",
    "        adam_epsilon=adam_epsilon,\n",
    "        num_train_epochs=num_train_epochs,\n",
    "        lr_scheduler_type=lr_scheduler_type,\n",
    "        warmup_ratio=warmup_ratio,\n",
    "        warmup_steps=warmup_steps,\n",
    "        logging_dir=logging_dir,         # directory for storing logs\n",
    "        logging_strategy=evaluation_strategy,\n",
    "        logging_steps=logging_steps,     # if strategy = \"steps\"\n",
    "        save_strategy=evaluation_strategy,          # model checkpoint saving strategy\n",
    "        save_steps=logging_steps,        # if strategy = \"steps\"\n",
    "        save_total_limit=save_total_limit,\n",
    "        #fp16=fp16,\n",
    "        eval_steps=logging_steps,        # if strategy = \"steps\"\n",
    "        load_best_model_at_end=load_best_model_at_end,\n",
    "        metric_for_best_model=metric_for_best_model,\n",
    "        greater_is_better=greater_is_better,\n",
    "        #local_rank=gpu,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6535004",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "01e52193",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fdff32",
   "metadata": {},
   "source": [
    "The last thing to define for our Trainer is how to compute the metrics from the predictions. Here we will load the seqeval metric (which is commonly used to evaluate results on the CONLL dataset) via the Datasets library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "30a68048",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = load_metric(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c130a6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#example = tokenized_datasets[\"validation\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676802d1",
   "metadata": {},
   "source": [
    "This metric takes list of labels for the predictions and references:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "08eb2fd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'JURISPRUDENCIA': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 3},\n",
       " 'ORGANIZACAO': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 2},\n",
       " 'PESSOA': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 2},\n",
       " 'overall_precision': 1.0,\n",
       " 'overall_recall': 1.0,\n",
       " 'overall_f1': 1.0,\n",
       " 'overall_accuracy': 1.0}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if next_sentence:\n",
    "    example = new_datasets[\"validation\"][0]\n",
    "    #example = tokenized_datasets[\"validation\"][0]\n",
    "else:\n",
    "    example = datasets[\"validation\"][0]\n",
    "    #example = tokenized_datasets[\"validation\"][0]\n",
    "\n",
    "labels = [label_list[i] for i in example[f\"{task}_tags\"]]\n",
    "metric.compute(predictions=[labels], references=[labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653e58f9",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "So we will need to do a bit of post-processing on our predictions:\n",
    "\n",
    "    select the predicted index (with the maximum logit) for each token\n",
    "    convert it to its string label\n",
    "    ignore everywhere we set a label of -100\n",
    "\n",
    "The following function does all this post-processing on the result of Trainer.evaluate (which is a namedtuple containing predictions and labels) before applying the metric:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "37d81549",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6848975e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c9a4c82a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 41807,\n",
       " 'B-ORGANIZACAO': 501,\n",
       " 'I-ORGANIZACAO': 866,\n",
       " 'B-PESSOA': 233,\n",
       " 'I-PESSOA': 502,\n",
       " 'B-TEMPO': 192,\n",
       " 'I-TEMPO': 68,\n",
       " 'B-LOCAL': 47,\n",
       " 'I-LOCAL': 85,\n",
       " 'B-LEGISLACAO': 378,\n",
       " 'I-LEGISLACAO': 2291,\n",
       " 'B-JURISPRUDENCIA': 185,\n",
       " 'I-JURISPRUDENCIA': 475}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_ner_tags_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3df460f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if weighted_loss:\n",
    "\n",
    "    # https://discuss.pytorch.org/t/what-is-the-weight-values-mean-in-torch-nn-crossentropyloss/11455/2\n",
    "    # https://discuss.pytorch.org/t/what-is-the-weight-values-mean-in-torch-nn-crossentropyloss/11455/4\n",
    "    # source: https://medium.com/swlh/approaching-a-named-entity-recognition-ner-end-to-end-steps-685735b4a2f9#5194\n",
    "    class_LabelCounts = [v for v in sorted_ner_tags_dist.values()]\n",
    "\n",
    "    inverse_weights = [1 / lc for lc in class_LabelCounts]\n",
    "    sum_inverse = np.sum(inverse_weights)\n",
    "    normalized_inverse_weights = inverse_weights / sum_inverse\n",
    "\n",
    "    constant = c\n",
    "    class_weights = constant + normalized_inverse_weights\n",
    "    normalized_weights = class_weights / np.sum(class_weights)\n",
    "    \n",
    "    # customized trainer class with weighted loss\n",
    "    # from transformers import Trainer\n",
    "    # import math\n",
    "    # from torch.nn import CrossEntropyLoss\n",
    "\n",
    "    # device = torch.device(f\"cuda:{gpu}\")\n",
    "#     torch.cuda.set_device(gpu)\n",
    "    normalized_class_weights = torch.from_numpy(normalized_weights).float().to(device)\n",
    "    if ds:\n",
    "        normalized_class_weights = normalized_class_weights.half()\n",
    "\n",
    "    class MyTrainer(Trainer):\n",
    "        def __init__(self, *args, **kwargs):\n",
    "            super().__init__(*args, **kwargs)    \n",
    "\n",
    "        # https://huggingface.co/transformers/_modules/transformers/trainer.html#Trainer.compute_loss\n",
    "        # https://github.com/huggingface/transformers/blob/master/src/transformers/models/bert/modeling_bert.py#L1711\n",
    "        def compute_loss(self, model, inputs, return_outputs=False):\n",
    "            \"\"\"\n",
    "            How the loss is computed by Trainer. By default, all models return the loss in the first element.\n",
    "\n",
    "            Subclass and override for custom behavior.\n",
    "            \"\"\"\n",
    "\n",
    "            labels = inputs.pop(\"labels\")\n",
    "            attention_mask = inputs['attention_mask']\n",
    "            \n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            num_labels = logits.shape[2]\n",
    "        \n",
    "            loss = None\n",
    "            \n",
    "            if labels is not None:\n",
    "#                 loss_fct = torch.nn.CrossEntropyLoss()\n",
    "                loss_fct = torch.nn.CrossEntropyLoss(weight=normalized_class_weights, reduction='mean') # mean in order to normalize the loss\n",
    "                \n",
    "                # Only keep active parts of the loss\n",
    "                if attention_mask is not None:\n",
    "                    active_loss = attention_mask.view(-1) == 1\n",
    "                    active_logits = logits.view(-1, num_labels)\n",
    "                    active_labels = torch.where(\n",
    "                        active_loss, labels.view(-1), torch.tensor(loss_fct.ignore_index).type_as(labels)\n",
    "                    )\n",
    "                    loss = loss_fct(active_logits, active_labels)\n",
    "                else:\n",
    "                    loss = loss_fct(logits.view(-1, num_labels), labels.view(-1))\n",
    "                \n",
    "            return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4eb128d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if weighted_loss:\n",
    "    trainer = MyTrainer(\n",
    "        model,\n",
    "        training_args,\n",
    "        train_dataset=tokenized_datasets[\"train\"], #.shard(index=1, num_shards=50), #to be used to reduce train to 1/50\n",
    "        eval_dataset=tokenized_datasets[\"validation\"], #.shard(index=1, num_shards=50), #to be used to reduce validation to 1/50\n",
    "        data_collator=data_collator,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=early_stopping_patience)],\n",
    "    )        \n",
    "else:\n",
    "    trainer = Trainer(\n",
    "        model,\n",
    "        training_args,\n",
    "        train_dataset=tokenized_datasets[\"train\"], #.shard(index=1, num_shards=50), #to be used to reduce train to 1/50\n",
    "        eval_dataset=tokenized_datasets[\"validation\"], #.shard(index=1, num_shards=50), #to be used to reduce validation to 1/50\n",
    "        data_collator=data_collator,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=early_stopping_patience)],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7d907c8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83481b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pixiedust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b18f09a",
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "#%%pixie_debugger\n",
    "# %debug\n",
    "#train_result = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "78e21412",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/info/.local/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 7828\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2937\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2937' max='2937' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2937/2937 1:23:14, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.569500</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.552386</td>\n",
       "      <td>0.612258</td>\n",
       "      <td>0.580783</td>\n",
       "      <td>0.942006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.369900</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.674409</td>\n",
       "      <td>0.677615</td>\n",
       "      <td>0.955278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.338300</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.683316</td>\n",
       "      <td>0.700215</td>\n",
       "      <td>0.691662</td>\n",
       "      <td>0.957578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1177\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer/output_dir/checkpoint-979\n",
      "Configuration saved in /home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer/output_dir/checkpoint-979/config.json\n",
      "Model weights saved in /home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer/output_dir/checkpoint-979/pytorch_model.bin\n",
      "tokenizer config file saved in /home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer/output_dir/checkpoint-979/tokenizer_config.json\n",
      "Special tokens file saved in /home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer/output_dir/checkpoint-979/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer/output_dir/checkpoint-2937] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1177\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer/output_dir/checkpoint-1958\n",
      "Configuration saved in /home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer/output_dir/checkpoint-1958/config.json\n",
      "Model weights saved in /home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer/output_dir/checkpoint-1958/pytorch_model.bin\n",
      "tokenizer config file saved in /home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer/output_dir/checkpoint-1958/tokenizer_config.json\n",
      "Special tokens file saved in /home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer/output_dir/checkpoint-1958/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer/output_dir/checkpoint-979] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1177\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer/output_dir/checkpoint-2937\n",
      "Configuration saved in /home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer/output_dir/checkpoint-2937/config.json\n",
      "Model weights saved in /home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer/output_dir/checkpoint-2937/pytorch_model.bin\n",
      "tokenizer config file saved in /home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer/output_dir/checkpoint-2937/tokenizer_config.json\n",
      "Special tokens file saved in /home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer/output_dir/checkpoint-2937/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer/output_dir/checkpoint-1958] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer/output_dir/checkpoint-2937 (score: 0.6916622411046204).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2937, training_loss=0.42590740386994064, metrics={'train_runtime': 4995.0387, 'train_samples_per_second': 4.701, 'train_steps_per_second': 0.588, 'total_flos': 2547187873126104.0, 'train_loss': 0.42590740386994064, 'epoch': 3.0})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n",
    "# Usar ferramentas de debug."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05c2c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "/home/info/.local/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
    "  warnings.warn(\n",
    "***** Running training *****\n",
    "  Num examples = 7828\n",
    "  Num Epochs = 3\n",
    "  Instantaneous batch size per device = 8\n",
    "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
    "  Gradient Accumulation steps = 1\n",
    "  Total optimization steps = 2937\n",
    "  \n",
    "\n",
    "Epoch \tTraining Loss \tValidation Loss \tPrecision \tRecall \tF1 \tAccuracy\n",
    "1 \t0.586800 \tnan \t0.630430 \t0.646022 \t0.638131 \t0.946699\n",
    "2 \t0.379100 \tnan \t0.723347 \t0.698925 \t0.710926 \t0.956847\n",
    "3 \t0.342000 \tnan \t0.724956 \t0.715914 \t0.720407 \t0.959392\n",
    "\n",
    "\n",
    "***** Running Evaluation *****\n",
    "  Num examples = 1177\n",
    "  Batch size = 8\n",
    "\n",
    "Saving model checkpoint to /home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer/output_dir/checkpoint-2937\n",
    "Configuration saved in /home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer/output_dir/checkpoint-2937/config.json\n",
    "Model weights saved in /home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer/output_dir/checkpoint-2937/pytorch_model.bin\n",
    "tokenizer config file saved in /home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer/output_dir/checkpoint-2937/tokenizer_config.json\n",
    "Special tokens file saved in /home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer/output_dir/checkpoint-2937/special_tokens_map.json\n",
    "Deleting older checkpoint [/home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer/output_dir/checkpoint-1958] due to args.save_total_limit\n",
    "\n",
    "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
    "\n",
    "\n",
    "Loading best model from /home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer/output_dir/checkpoint-2937 (score: 0.7204068383466782).\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "26b99111",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer/adapters-ner/adapter_config.json\n",
      "Module weights saved in /home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer/adapters-ner/pytorch_adapter.bin\n",
      "Configuration saved in /home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer/adapters-ner/head_config.json\n",
      "Module weights saved in /home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer/adapters-ner/pytorch_model_head.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 3,2M\r\n",
      "-rw-rw-r-- 1 info info 1006 Aug  5 03:35 adapter_config.json\r\n",
      "-rw-rw-r-- 1 info info  486 Aug  5 03:35 head_config.json\r\n",
      "-rw-rw-r-- 1 info info 3,2M Aug  5 03:35 pytorch_adapter.bin\r\n",
      "-rw-rw-r-- 1 info info  40K Aug  5 03:35 pytorch_model_head.bin\r\n"
     ]
    }
   ],
   "source": [
    "# save adapter + head\n",
    "adapters_folder = 'adapters-' + task_name\n",
    "path_to_save_adapter = path_to_outputs/adapters_folder\n",
    "trainer.model.save_adapter(str(path_to_save_adapter), adapter_name=task_name, with_head=True)\n",
    "\n",
    "!ls -lh {path_to_save_adapter}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a2be1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Configuration saved in /home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer/adapters-ner/adapter_config.json\n",
    "Module weights saved in /home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer/adapters-ner/pytorch_adapter.bin\n",
    "Configuration saved in /home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer/adapters-ner/head_config.json\n",
    "Module weights saved in /home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer/adapters-ner/pytorch_model_head.bin\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fd538923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer/adapters-ner')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_save_adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050ada07",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "PosixPath('/home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer/adapters-ner')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5009f821",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Creio que a configuração para usar o Adapter seja:\n",
    "\n",
    "model_checkpoint = \"/home/info/MyNotebooks/bert-base-portuguese-cased-finetuned-ACP/checkpoint-1500/\"\n",
    "\n",
    "root = Path(\"/home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP\")\n",
    "root = Path(root)     \n",
    "\n",
    "\n",
    "Adapter Configuration in: /home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer/adapters-ner/\n",
    "\n",
    "\n",
    "\n",
    "OU:\n",
    "\n",
    "BASE ('Saving model checkpoint to' or 'Loading best model from'):\n",
    " /home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer/output_dir/checkpoint-2937\n",
    "\n",
    "ADAPTER (path_to_save_adapter):\n",
    "/home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer/adapters-ner\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99509299",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab48ed51",
   "metadata": {},
   "source": [
    "11. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "276947de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1177\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='644' max='148' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [148/148 07:31]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': nan,\n",
       " 'eval_precision': 0.6833158447009444,\n",
       " 'eval_recall': 0.7002150537634408,\n",
       " 'eval_f1': 0.6916622411046204,\n",
       " 'eval_accuracy': 0.9575784357048166,\n",
       " 'eval_runtime': 79.6729,\n",
       " 'eval_samples_per_second': 14.773,\n",
       " 'eval_steps_per_second': 1.858,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497fed6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "{'eval_loss': nan,\n",
    " 'eval_precision': 0.7249564459930313,\n",
    " 'eval_recall': 0.7159139784946237,\n",
    " 'eval_f1': 0.7204068383466782,\n",
    " 'eval_accuracy': 0.959391713776342,\n",
    " 'eval_runtime': 71.6175,\n",
    " 'eval_samples_per_second': 16.435,\n",
    " 'eval_steps_per_second': 2.067,\n",
    " 'epoch': 3.0}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7141945f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1177\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'JURISPRUDENCIA': {'precision': 0.3779264214046823,\n",
       "  'recall': 0.3439878234398782,\n",
       "  'f1': 0.3601593625498008,\n",
       "  'number': 657},\n",
       " 'LEGISLACAO': {'precision': 0.6900175131348512,\n",
       "  'recall': 0.6900175131348512,\n",
       "  'f1': 0.6900175131348512,\n",
       "  'number': 571},\n",
       " 'LOCAL': {'precision': 0.2830188679245283,\n",
       "  'recall': 0.3865979381443299,\n",
       "  'f1': 0.32679738562091504,\n",
       "  'number': 194},\n",
       " 'ORGANIZACAO': {'precision': 0.6068702290076335,\n",
       "  'recall': 0.5932835820895522,\n",
       "  'f1': 0.6000000000000001,\n",
       "  'number': 1340},\n",
       " 'PESSOA': {'precision': 0.9539040451552211,\n",
       "  'recall': 0.9458955223880597,\n",
       "  'f1': 0.9498829039812647,\n",
       "  'number': 1072},\n",
       " 'TEMPO': {'precision': 0.7849686847599165,\n",
       "  'recall': 0.9215686274509803,\n",
       "  'f1': 0.8478015783540023,\n",
       "  'number': 816},\n",
       " 'overall_precision': 0.6833158447009444,\n",
       " 'overall_recall': 0.7002150537634408,\n",
       " 'overall_f1': 0.6916622411046204,\n",
       " 'overall_accuracy': 0.9575784357048166}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions, labels, _ = trainer.predict(tokenized_datasets[\"validation\"])\n",
    "predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "# Remove ignored index (special tokens)\n",
    "true_predictions = [\n",
    "    [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]\n",
    "true_labels = [\n",
    "    [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]\n",
    "\n",
    "results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7987d520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JURISPRUDENCIA</th>\n",
       "      <th>LEGISLACAO</th>\n",
       "      <th>LOCAL</th>\n",
       "      <th>ORGANIZACAO</th>\n",
       "      <th>PESSOA</th>\n",
       "      <th>TEMPO</th>\n",
       "      <th>overall_precision</th>\n",
       "      <th>overall_recall</th>\n",
       "      <th>overall_f1</th>\n",
       "      <th>overall_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.377926</td>\n",
       "      <td>0.690018</td>\n",
       "      <td>0.283019</td>\n",
       "      <td>0.606870</td>\n",
       "      <td>0.953904</td>\n",
       "      <td>0.784969</td>\n",
       "      <td>0.683316</td>\n",
       "      <td>0.700215</td>\n",
       "      <td>0.691662</td>\n",
       "      <td>0.957578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.343988</td>\n",
       "      <td>0.690018</td>\n",
       "      <td>0.386598</td>\n",
       "      <td>0.593284</td>\n",
       "      <td>0.945896</td>\n",
       "      <td>0.921569</td>\n",
       "      <td>0.683316</td>\n",
       "      <td>0.700215</td>\n",
       "      <td>0.691662</td>\n",
       "      <td>0.957578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.360159</td>\n",
       "      <td>0.690018</td>\n",
       "      <td>0.326797</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.949883</td>\n",
       "      <td>0.847802</td>\n",
       "      <td>0.683316</td>\n",
       "      <td>0.700215</td>\n",
       "      <td>0.691662</td>\n",
       "      <td>0.957578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number</th>\n",
       "      <td>657.000000</td>\n",
       "      <td>571.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>1340.000000</td>\n",
       "      <td>1072.000000</td>\n",
       "      <td>816.000000</td>\n",
       "      <td>0.683316</td>\n",
       "      <td>0.700215</td>\n",
       "      <td>0.691662</td>\n",
       "      <td>0.957578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           JURISPRUDENCIA  LEGISLACAO       LOCAL  ORGANIZACAO       PESSOA  \\\n",
       "precision        0.377926    0.690018    0.283019     0.606870     0.953904   \n",
       "recall           0.343988    0.690018    0.386598     0.593284     0.945896   \n",
       "f1               0.360159    0.690018    0.326797     0.600000     0.949883   \n",
       "number         657.000000  571.000000  194.000000  1340.000000  1072.000000   \n",
       "\n",
       "                TEMPO  overall_precision  overall_recall  overall_f1  \\\n",
       "precision    0.784969           0.683316        0.700215    0.691662   \n",
       "recall       0.921569           0.683316        0.700215    0.691662   \n",
       "f1           0.847802           0.683316        0.700215    0.691662   \n",
       "number     816.000000           0.683316        0.700215    0.691662   \n",
       "\n",
       "           overall_accuracy  \n",
       "precision          0.957578  \n",
       "recall             0.957578  \n",
       "f1                 0.957578  \n",
       "number             0.957578  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8877ff50",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "***** Running Prediction *****\n",
    "  Num examples = 1177\n",
    "  Batch size = 8\n",
    "\n",
    "{'JURISPRUDENCIA': {'precision': 0.3576388888888889,\n",
    "  'recall': 0.3135464231354642,\n",
    "  'f1': 0.3341443633414436,\n",
    "  'number': 657},\n",
    " 'LEGISLACAO': {'precision': 0.7201492537313433,\n",
    "  'recall': 0.6760070052539404,\n",
    "  'f1': 0.6973803071364046,\n",
    "  'number': 571},\n",
    " 'LOCAL': {'precision': 0.34701492537313433,\n",
    "  'recall': 0.4793814432989691,\n",
    "  'f1': 0.4025974025974026,\n",
    "  'number': 194},\n",
    " 'ORGANIZACAO': {'precision': 0.6523101018010963,\n",
    "  'recall': 0.6216417910447761,\n",
    "  'f1': 0.6366068016813144,\n",
    "  'number': 1340},\n",
    " 'PESSOA': {'precision': 0.9705882352941176,\n",
    "  'recall': 0.9542910447761194,\n",
    "  'f1': 0.962370649106303,\n",
    "  'number': 1072},\n",
    " 'TEMPO': {'precision': 0.8944381384790011,\n",
    "  'recall': 0.9656862745098039,\n",
    "  'f1': 0.928697701826753,\n",
    "  'number': 816},\n",
    " 'overall_precision': 0.7249564459930313,\n",
    " 'overall_recall': 0.7159139784946237,\n",
    " 'overall_f1': 0.7204068383466782,\n",
    " 'overall_accuracy': 0.959391713776342}\n",
    " \n",
    "\n",
    "JURISPRUDENCIA \tLEGISLACAO \tLOCAL \tORGANIZACAO \tPESSOA \tTEMPO \toverall_precision \toverall_recall \toverall_f1 \toverall_accuracy\n",
    "precision \t0.357639 \t0.720149 \t0.347015 \t0.652310 \t0.970588 \t0.894438 \t0.724956 \t0.715914 \t0.720407 \t0.959392\n",
    "recall \t0.313546 \t0.676007 \t0.479381 \t0.621642 \t0.954291 \t0.965686 \t0.724956 \t0.715914 \t0.720407 \t0.959392\n",
    "f1 \t0.334144 \t0.697380 \t0.402597 \t0.636607 \t0.962371 \t0.928698 \t0.724956 \t0.715914 \t0.720407 \t0.959392\n",
    "number \t657.000000 \t571.000000 \t194.000000 \t1340.000000 \t1072.000000 \t816.000000 \t0.724956 \t0.715914 \t0.720407 \t0.959392\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d6edda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7aa0cb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64f75c9a",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "69363748",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1390\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.10147732496261597,\n",
       " 'eval_precision': 0.6979727995894278,\n",
       " 'eval_recall': 0.7003089598352215,\n",
       " 'eval_f1': 0.6991389281583344,\n",
       " 'eval_accuracy': 0.9674445277692002,\n",
       " 'eval_runtime': 82.7041,\n",
       " 'eval_samples_per_second': 16.807,\n",
       " 'eval_steps_per_second': 2.104,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(tokenized_datasets[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d6ead7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "{'eval_loss': 0.10461320728063583,\n",
    " 'eval_precision': 0.7238785925329035,\n",
    " 'eval_recall': 0.6938722966014418,\n",
    " 'eval_f1': 0.7085579071907453,\n",
    " 'eval_accuracy': 0.9672533709765171,\n",
    " 'eval_runtime': 76.2975,\n",
    " 'eval_samples_per_second': 18.218,\n",
    " 'eval_steps_per_second': 2.281,\n",
    " 'epoch': 3.0}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f5dedb89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1390\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'JURISPRUDENCIA': {'precision': 0.6589673913043478,\n",
       "  'recall': 0.4507434944237918,\n",
       "  'f1': 0.5353200883002207,\n",
       "  'number': 1076},\n",
       " 'LEGISLACAO': {'precision': 0.7354709418837675,\n",
       "  'recall': 0.6577060931899642,\n",
       "  'f1': 0.6944181646168402,\n",
       "  'number': 558},\n",
       " 'LOCAL': {'precision': 0.3504273504273504,\n",
       "  'recall': 0.6029411764705882,\n",
       "  'f1': 0.4432432432432432,\n",
       "  'number': 68},\n",
       " 'ORGANIZACAO': {'precision': 0.5806188925081434,\n",
       "  'recall': 0.7465968586387435,\n",
       "  'f1': 0.6532295006871279,\n",
       "  'number': 955},\n",
       " 'PESSOA': {'precision': 0.8450244698205547,\n",
       "  'recall': 0.9522058823529411,\n",
       "  'f1': 0.8954191875540191,\n",
       "  'number': 544},\n",
       " 'TEMPO': {'precision': 0.8465909090909091,\n",
       "  'recall': 0.8726207906295754,\n",
       "  'f1': 0.8594087959625091,\n",
       "  'number': 683},\n",
       " 'overall_precision': 0.6979727995894278,\n",
       " 'overall_recall': 0.7003089598352215,\n",
       " 'overall_f1': 0.6991389281583344,\n",
       " 'overall_accuracy': 0.9674445277692002}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions, labels, _ = trainer.predict(tokenized_datasets[\"test\"])\n",
    "predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "# Remove ignored index (special tokens)\n",
    "true_predictions = [\n",
    "    [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]\n",
    "true_labels = [\n",
    "    [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]\n",
    "\n",
    "results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "08d772e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JURISPRUDENCIA</th>\n",
       "      <th>LEGISLACAO</th>\n",
       "      <th>LOCAL</th>\n",
       "      <th>ORGANIZACAO</th>\n",
       "      <th>PESSOA</th>\n",
       "      <th>TEMPO</th>\n",
       "      <th>overall_precision</th>\n",
       "      <th>overall_recall</th>\n",
       "      <th>overall_f1</th>\n",
       "      <th>overall_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.658967</td>\n",
       "      <td>0.735471</td>\n",
       "      <td>0.350427</td>\n",
       "      <td>0.580619</td>\n",
       "      <td>0.845024</td>\n",
       "      <td>0.846591</td>\n",
       "      <td>0.697973</td>\n",
       "      <td>0.700309</td>\n",
       "      <td>0.699139</td>\n",
       "      <td>0.967445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.450743</td>\n",
       "      <td>0.657706</td>\n",
       "      <td>0.602941</td>\n",
       "      <td>0.746597</td>\n",
       "      <td>0.952206</td>\n",
       "      <td>0.872621</td>\n",
       "      <td>0.697973</td>\n",
       "      <td>0.700309</td>\n",
       "      <td>0.699139</td>\n",
       "      <td>0.967445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.535320</td>\n",
       "      <td>0.694418</td>\n",
       "      <td>0.443243</td>\n",
       "      <td>0.653230</td>\n",
       "      <td>0.895419</td>\n",
       "      <td>0.859409</td>\n",
       "      <td>0.697973</td>\n",
       "      <td>0.700309</td>\n",
       "      <td>0.699139</td>\n",
       "      <td>0.967445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number</th>\n",
       "      <td>1076.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>955.000000</td>\n",
       "      <td>544.000000</td>\n",
       "      <td>683.000000</td>\n",
       "      <td>0.697973</td>\n",
       "      <td>0.700309</td>\n",
       "      <td>0.699139</td>\n",
       "      <td>0.967445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           JURISPRUDENCIA  LEGISLACAO      LOCAL  ORGANIZACAO      PESSOA  \\\n",
       "precision        0.658967    0.735471   0.350427     0.580619    0.845024   \n",
       "recall           0.450743    0.657706   0.602941     0.746597    0.952206   \n",
       "f1               0.535320    0.694418   0.443243     0.653230    0.895419   \n",
       "number        1076.000000  558.000000  68.000000   955.000000  544.000000   \n",
       "\n",
       "                TEMPO  overall_precision  overall_recall  overall_f1  \\\n",
       "precision    0.846591           0.697973        0.700309    0.699139   \n",
       "recall       0.872621           0.697973        0.700309    0.699139   \n",
       "f1           0.859409           0.697973        0.700309    0.699139   \n",
       "number     683.000000           0.697973        0.700309    0.699139   \n",
       "\n",
       "           overall_accuracy  \n",
       "precision          0.967445  \n",
       "recall             0.967445  \n",
       "f1                 0.967445  \n",
       "number             0.967445  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0de32bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "***** Running Prediction *****\n",
    "  Num examples = 1390\n",
    "  Batch size = 8\n",
    "\n",
    "{'JURISPRUDENCIA': {'precision': 0.651925820256776,\n",
    "  'recall': 0.4247211895910781,\n",
    "  'f1': 0.5143500281373101,\n",
    "  'number': 1076},\n",
    " 'LEGISLACAO': {'precision': 0.7194388777555111,\n",
    "  'recall': 0.6433691756272402,\n",
    "  'f1': 0.6792809839167454,\n",
    "  'number': 558},\n",
    " 'LOCAL': {'precision': 0.3761467889908257,\n",
    "  'recall': 0.6029411764705882,\n",
    "  'f1': 0.4632768361581921,\n",
    "  'number': 68},\n",
    " 'ORGANIZACAO': {'precision': 0.6302447552447552,\n",
    "  'recall': 0.7549738219895288,\n",
    "  'f1': 0.6869938065745592,\n",
    "  'number': 955},\n",
    " 'PESSOA': {'precision': 0.8519134775374376,\n",
    "  'recall': 0.9411764705882353,\n",
    "  'f1': 0.8943231441048035,\n",
    "  'number': 544},\n",
    " 'TEMPO': {'precision': 0.9043348281016442,\n",
    "  'recall': 0.8857979502196194,\n",
    "  'f1': 0.8949704142011834,\n",
    "  'number': 683},\n",
    " 'overall_precision': 0.7238785925329035,\n",
    " 'overall_recall': 0.6938722966014418,\n",
    " 'overall_f1': 0.7085579071907453,\n",
    " 'overall_accuracy': 0.9672533709765171}\n",
    "\n",
    "\n",
    "JURISPRUDENCIA \tLEGISLACAO \tLOCAL \tORGANIZACAO \tPESSOA \tTEMPO \toverall_precision \toverall_recall \toverall_f1 \toverall_accuracy\n",
    "precision \t0.651926 \t0.719439 \t0.376147 \t0.630245 \t0.851913 \t0.904335 \t0.723879 \t0.693872 \t0.708558 \t0.967253\n",
    "recall \t0.424721 \t0.643369 \t0.602941 \t0.754974 \t0.941176 \t0.885798 \t0.723879 \t0.693872 \t0.708558 \t0.967253\n",
    "f1 \t0.514350 \t0.679281 \t0.463277 \t0.686994 \t0.894323 \t0.894970 \t0.723879 \t0.693872 \t0.708558 \t0.967253\n",
    "number \t1076.000000 \t558.000000 \t68.000000 \t955.000000 \t544.000000 \t683.000000 \t0.723879 \t0.693872 \t0.708558 \t0.967253\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bba6954",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96e36ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29db949b",
   "metadata": {},
   "source": [
    "12. TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2d46f790",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cdcc685e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PATH=/mnt/home/xxxx/anaconda3/envs/yyyy/bin:/home/info/.conda/envs/acptrt1/bin:/home/info/anaconda3/condabin:/home/info/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin\n"
     ]
    }
   ],
   "source": [
    "PATH = os.getenv('PATH')\n",
    "# replace xxxx by your username on your server (ex: paulo)\n",
    "# replace yyyy by the name of the virtual environment of this notebook (ex: adapter-transformers)\n",
    "%env PATH=/mnt/home/xxxx/anaconda3/envs/yyyy/bin:$PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1d7b98a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1c80317fa3b1799d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1c80317fa3b1799d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pip install --upgrade tensorflow\n",
    "#%load_ext tensorboard\n",
    "%reload_ext tensorboard\n",
    "# %reload_ext tensorboard\n",
    "%tensorboard --logdir {logging_dir} --bind_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15de5f3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832774f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec08148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "35f65844",
   "metadata": {},
   "source": [
    "13. Application NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "1b4a403d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### import transformers\n",
    "# !pip install colorama\n",
    "# # or\n",
    "#!conda install -c anaconda colorama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "04d42704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel_checkpoint = \"/home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer/adapters-ner\"\\n\\nroot = Path(\"/home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/\")\\nroot = Path(root)\\nroot\\n'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model_checkpoint = \"neuralmind/bert-large-portuguese-cased\"\n",
    "\n",
    "#BASE ('Saving model checkpoint to' or 'Loading best model from'):\n",
    "\n",
    "model_checkpoint = \"/home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer/output_dir/checkpoint-2937\"\n",
    "\n",
    "#ADAPTER (path_to_save_adapter):\n",
    "model_output = \"/home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer/adapters-ner\"\n",
    "\n",
    "\n",
    "'''\n",
    "model_checkpoint = \"/home/info/MyNotebooks/bert-base-portuguese-cased-finetuned-ACP/checkpoint-1500/\"\n",
    "\n",
    "root = Path(\"/home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP\")\n",
    "root = Path(root)\n",
    "root \n",
    "'''\n",
    "# Ou:\n",
    "'''\n",
    "BASE:\n",
    "/home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer/output_dir/checkpoint-979\n",
    "ADAPTER:\n",
    "/home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer/adapters-ner\n",
    "'''\n",
    "\n",
    "\n",
    "# Ou:\n",
    "'''\n",
    "model_checkpoint = \"/home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer/output_dir/checkpoint-2937\"\n",
    "\n",
    "root = Path(\"/home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/\")\n",
    "root = Path(root)\n",
    "root\n",
    "'''\n",
    "\n",
    "# Ou:\n",
    "'''\n",
    "model_checkpoint = \"/home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer/adapters-ner\"\n",
    "\n",
    "root = Path(\"/home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/\")\n",
    "root = Path(root)\n",
    "root\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1cee0f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_name == \"lenerbr\":\n",
    "    label_list = ['O',\n",
    " 'B-ORGANIZACAO',\n",
    " 'I-ORGANIZACAO',\n",
    " 'B-PESSOA',\n",
    " 'I-PESSOA',\n",
    " 'B-TEMPO',\n",
    " 'I-TEMPO',\n",
    " 'B-LOCAL',\n",
    " 'I-LOCAL',\n",
    " 'B-LEGISLACAO',\n",
    " 'I-LEGISLACAO',\n",
    " 'B-JURISPRUDENCIA',\n",
    " 'I-JURISPRUDENCIA'\n",
    "                 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "17fff229",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if dataset_name == \"LeNER-Br\":\n",
    "    \n",
    "    # sentence from the dataset\n",
    "    texts_dataset = [\n",
    "        'Acrescento que o Juiz Pedro DA SILVA do tribunal STF em Brasília (Brasil) reconheceu a limitação do pedido único e, com base no artigo 487, inciso II, do Código de Processo Civil, encerrou o processo no dia 3 de janeiro de 2014, com resolução do mérito, condenando o autor às custas judiciais e advocatícias, que são fixadas em 10% (dez por cento) do valor da causa.',\n",
    "        'Insurge-se no apelo extremo contra acórdão proferido pelo Superior Tribunal Militar no Agravo Regimental n° 222-73.2010.7.05.0005/PR, assim do: DESERÇÃO.'\n",
    "    ]\n",
    "    \n",
    "    texts_labels = [\n",
    "        \"\",\n",
    "        \"'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORGANIZACAO', 'I-ORGANIZACAO', 'I-ORGANIZACAO', 'O', 'B-JURISPRUDENCIA', 'I-JURISPRUDENCIA', 'I-JURISPRUDENCIA', 'I-JURISPRUDENCIA', 'I-JURISPRUDENCIA', 'O', 'O', 'O', 'O', 'O', 'O'\"\n",
    "    ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8bbd335c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Acrescento que o Juiz Pedro DA SILVA do tribunal STF em Brasília (Brasil) reconheceu a limitação do pedido único e, com base no artigo 487, inciso II, do Código de Processo Civil, encerrou o processo no dia 3 de janeiro de 2014, com resolução do mérito, condenando o autor às custas judiciais e advocatícias, que são fixadas em 10% (dez por cento) do valor da causa.',\n",
       " 'Insurge-se no apelo extremo contra acórdão proferido pelo Superior Tribunal Militar no Agravo Regimental n° 222-73.2010.7.05.0005/PR, assim do: DESERÇÃO.']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a18cc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb785396",
   "metadata": {},
   "source": [
    "Model with adapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3125585c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer/output_dir/checkpoint-2937/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"/home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer/output_dir/checkpoint-2937\",\n",
      "  \"adapters\": {\n",
      "    \"adapters\": {\n",
      "      \"ner\": \"55afc146b84997d9\"\n",
      "    },\n",
      "    \"config_map\": {\n",
      "      \"55afc146b84997d9\": {\n",
      "        \"adapter_residual_before_ln\": false,\n",
      "        \"cross_adapter\": false,\n",
      "        \"factorized_phm_W\": true,\n",
      "        \"factorized_phm_rule\": false,\n",
      "        \"hypercomplex_nonlinearity\": \"glorot-uniform\",\n",
      "        \"init_weights\": \"bert\",\n",
      "        \"inv_adapter\": null,\n",
      "        \"inv_adapter_reduction_factor\": null,\n",
      "        \"is_parallel\": false,\n",
      "        \"learn_phm\": true,\n",
      "        \"leave_out\": [\n",
      "          11\n",
      "        ],\n",
      "        \"ln_after\": false,\n",
      "        \"ln_before\": false,\n",
      "        \"mh_adapter\": false,\n",
      "        \"non_linearity\": \"gelu\",\n",
      "        \"original_ln_after\": true,\n",
      "        \"original_ln_before\": true,\n",
      "        \"output_adapter\": true,\n",
      "        \"phm_bias\": true,\n",
      "        \"phm_c_init\": \"normal\",\n",
      "        \"phm_dim\": 4,\n",
      "        \"phm_init_range\": 0.0001,\n",
      "        \"phm_layer\": false,\n",
      "        \"phm_rank\": 1,\n",
      "        \"reduction_factor\": 16,\n",
      "        \"residual_before_ln\": true,\n",
      "        \"scaling\": 1.0,\n",
      "        \"shared_W_phm\": false,\n",
      "        \"shared_phm_rule\": true\n",
      "      }\n",
      "    },\n",
      "    \"fusion_config_map\": {},\n",
      "    \"fusions\": {}\n",
      "  },\n",
      "  \"architectures\": [\n",
      "    \"BertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"O\",\n",
      "    \"1\": \"B-ORGANIZACAO\",\n",
      "    \"2\": \"I-ORGANIZACAO\",\n",
      "    \"3\": \"B-PESSOA\",\n",
      "    \"4\": \"I-PESSOA\",\n",
      "    \"5\": \"B-TEMPO\",\n",
      "    \"6\": \"I-TEMPO\",\n",
      "    \"7\": \"B-LOCAL\",\n",
      "    \"8\": \"I-LOCAL\",\n",
      "    \"9\": \"B-LEGISLACAO\",\n",
      "    \"10\": \"I-LEGISLACAO\",\n",
      "    \"11\": \"B-JURISPRUDENCIA\",\n",
      "    \"12\": \"I-JURISPRUDENCIA\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"B-JURISPRUDENCIA\": 11,\n",
      "    \"B-LEGISLACAO\": 9,\n",
      "    \"B-LOCAL\": 7,\n",
      "    \"B-ORGANIZACAO\": 1,\n",
      "    \"B-PESSOA\": 3,\n",
      "    \"B-TEMPO\": 5,\n",
      "    \"I-JURISPRUDENCIA\": 12,\n",
      "    \"I-LEGISLACAO\": 10,\n",
      "    \"I-LOCAL\": 8,\n",
      "    \"I-ORGANIZACAO\": 2,\n",
      "    \"I-PESSOA\": 4,\n",
      "    \"I-TEMPO\": 6,\n",
      "    \"O\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 29794\n",
      "}\n",
      "\n",
      "loading weights file /home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer/output_dir/checkpoint-2937/pytorch_model.bin\n",
      "Some weights of the model checkpoint at /home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer/output_dir/checkpoint-2937 were not used when initializing BertForTokenClassification: ['bert.encoder.layer.0.output.adapters.ner.adapter_up.bias', 'bert.encoder.layer.1.output.adapters.ner.adapter_up.weight', 'bert.encoder.layer.5.output.adapters.ner.adapter_up.weight', 'bert.encoder.layer.7.output.adapters.ner.adapter_down.0.weight', 'bert.encoder.layer.4.output.adapters.ner.adapter_up.bias', 'bert.encoder.layer.2.output.adapters.ner.adapter_down.0.weight', 'bert.encoder.layer.6.output.adapters.ner.adapter_up.weight', 'bert.encoder.layer.10.output.adapters.ner.adapter_up.weight', 'bert.encoder.layer.5.output.adapters.ner.adapter_down.0.bias', 'bert.encoder.layer.9.output.adapters.ner.adapter_down.0.weight', 'bert.encoder.layer.9.output.adapters.ner.adapter_up.bias', 'bert.encoder.layer.8.output.adapters.ner.adapter_up.weight', 'bert.encoder.layer.10.output.adapters.ner.adapter_down.0.weight', 'bert.encoder.layer.8.output.adapters.ner.adapter_down.0.weight', 'bert.encoder.layer.1.output.adapters.ner.adapter_down.0.weight', 'bert.encoder.layer.9.output.adapters.ner.adapter_up.weight', 'bert.encoder.layer.10.output.adapters.ner.adapter_up.bias', 'bert.encoder.layer.3.output.adapters.ner.adapter_up.weight', 'bert.encoder.layer.5.output.adapters.ner.adapter_up.bias', 'bert.encoder.layer.0.output.adapters.ner.adapter_down.0.bias', 'bert.encoder.layer.4.output.adapters.ner.adapter_up.weight', 'bert.encoder.layer.7.output.adapters.ner.adapter_up.weight', 'bert.encoder.layer.1.output.adapters.ner.adapter_up.bias', 'bert.encoder.layer.0.output.adapters.ner.adapter_up.weight', 'bert.encoder.layer.3.output.adapters.ner.adapter_down.0.weight', 'bert.encoder.layer.8.output.adapters.ner.adapter_up.bias', 'bert.encoder.layer.3.output.adapters.ner.adapter_up.bias', 'bert.encoder.layer.3.output.adapters.ner.adapter_down.0.bias', 'bert.encoder.layer.8.output.adapters.ner.adapter_down.0.bias', 'bert.encoder.layer.10.output.adapters.ner.adapter_down.0.bias', 'bert.encoder.layer.2.output.adapters.ner.adapter_down.0.bias', 'bert.encoder.layer.7.output.adapters.ner.adapter_up.bias', 'bert.encoder.layer.7.output.adapters.ner.adapter_down.0.bias', 'bert.encoder.layer.2.output.adapters.ner.adapter_up.weight', 'bert.encoder.layer.6.output.adapters.ner.adapter_down.0.bias', 'bert.encoder.layer.4.output.adapters.ner.adapter_down.0.bias', 'bert.encoder.layer.1.output.adapters.ner.adapter_down.0.bias', 'bert.encoder.layer.2.output.adapters.ner.adapter_up.bias', 'bert.encoder.layer.9.output.adapters.ner.adapter_down.0.bias', 'bert.encoder.layer.6.output.adapters.ner.adapter_up.bias', 'bert.encoder.layer.5.output.adapters.ner.adapter_down.0.weight', 'bert.encoder.layer.6.output.adapters.ner.adapter_down.0.weight', 'bert.encoder.layer.0.output.adapters.ner.adapter_down.0.weight', 'bert.encoder.layer.4.output.adapters.ner.adapter_down.0.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertForTokenClassification were initialized from the model checkpoint at /home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer/output_dir/checkpoint-2937.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTokenClassification for predictions without further training.\n",
      "Didn't find file /home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer/output_dir/checkpoint-2937/added_tokens.json. We won't load it.\n",
      "loading file /home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer/output_dir/checkpoint-2937/vocab.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file /home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer/output_dir/checkpoint-2937/tokenizer.json\n",
      "loading file None\n",
      "loading file /home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer/output_dir/checkpoint-2937/special_tokens_map.json\n",
      "loading file /home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer/output_dir/checkpoint-2937/tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "model_ner = AutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=len(label_list), id2label=id2label, label2id=label2id)\n",
    "tokenizer_ner = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c30bfa",
   "metadata": {},
   "source": [
    "Lang adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "72d08fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if with_adapters_mlm:\n",
    "    \n",
    "    # hyperparameters used for fine-tuning the MLM with lang adapter\n",
    "    learning_rate_mlm = 1e-4\n",
    "    batch_size_mlm = 16\n",
    "    gradient_accumulation_steps_mlm = 1\n",
    "    adam_epsilon_mlm = 1e-6\n",
    "    num_train_epoch_mlm = 100.\n",
    "    early_stopping_patience_mlm = 10\n",
    "    madx2_mlm = True\n",
    "    houlsby_MHA_lastlayer_mlm = False\n",
    "    ds_mlm = False\n",
    "    fp16_mlm = True\n",
    "    load_best_model_at_end_mlm = True\n",
    "    metric_for_best_model_mlm = \"loss\"\n",
    "    adapter_config_mlm = 'pfeiffer+inv'\n",
    "\n",
    "    # path to lang adapter\n",
    "    outputs_mlm = model_checkpoint.replace('/','-') + '_' + dataset_name + '/' + 'mlm' + '/' \\\n",
    "    + 'lr' + str(learning_rate_mlm) \\\n",
    "    + '_bs' + str(batch_size_mlm) \\\n",
    "    + '_GAS' + str(gradient_accumulation_steps_mlm) \\\n",
    "    + '_eps' + str(adam_epsilon_mlm) \\\n",
    "    + '_epochs' + str(num_train_epoch_mlm) \\\n",
    "    + '_patience' + str(early_stopping_patience_mlm) \\\n",
    "    + '_madx2' + str(madx2_mlm) \\\n",
    "    + '_houlsby_MHA_lastlayer' + str(houlsby_MHA_lastlayer_mlm) \\\n",
    "    + '_ds' + str(ds_mlm) \\\n",
    "    + '_fp16' + str(fp16_mlm) \\\n",
    "    + '_best' + str(load_best_model_at_end_mlm) \\\n",
    "    + '_metric' + str(metric_for_best_model_mlm) \\\n",
    "    + '_adapterconfig' + str(adapter_config_mlm)\n",
    "\n",
    "    path_to_outputs_mlm = root/'outputs'/outputs_mlm\n",
    "\n",
    "    # Config of the lang adapter\n",
    "    lang_adapter_path = path_to_outputs_mlm/'adapters-mlm/'\n",
    "\n",
    "    #load_lang_adapter = str(lang_adapter_path)\n",
    "    load_lang_adapter = \"/home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer/adapters-ner\"\n",
    "    #'/home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP-Bert_LeNER-Br/mlm/lr0.0001_bs16_GAS1_eps1e-06_epochs100.0_patience10_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricloss_adapterconfigpfeiffer+inv/adapters-mlm'\n",
    "    lang_adapter_config = str(lang_adapter_path) + \"/adapter_config.json\"\n",
    "\n",
    "if with_adapters_mlm:\n",
    "    # load the language adapter without head\n",
    "    task_mlm_load_as = 'mlm'\n",
    "    lang_adapter_name = model_ner.load_adapter(\n",
    "        load_lang_adapter,\n",
    "        config=lang_adapter_config,\n",
    "        load_as=task_mlm_load_as,\n",
    "        with_head=False\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d3e3d2",
   "metadata": {},
   "source": [
    "NER adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c18ea571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder for training outputs\n",
    "\n",
    "if model_checkpoint == \"neuralmind/bert-large-portuguese-cased\":\n",
    "    outputs = model_checkpoint.replace('/','-') + '_' + dataset_name_hf\n",
    "else:\n",
    "    outputs = model_output\n",
    "    \n",
    "if with_adapters_mlm:\n",
    "    outputs = outputs + '/' + 'mlm_' + str(task) + '_AdCompo' + str(adapter_composition) + '/'\n",
    "else:\n",
    "    outputs = outputs + '/' + str(task) + '/'\n",
    "\n",
    "outputs = outputs \\\n",
    "+ 'lr' + str(learning_rate) \\\n",
    "+ '_bs' + str(batch_size) \\\n",
    "+ '_GAS' + str(gradient_accumulation_steps) \\\n",
    "+ '_eps' + str(adam_epsilon) \\\n",
    "+ '_epochs' + str(num_train_epochs) \\\n",
    "+ '_patience' + str(early_stopping_patience) \\\n",
    "+ '_wamlm' + str(with_adapters_mlm) \\\n",
    "+ '_madx2' + str(madx2) \\\n",
    "+ '_houlsby_MHA_lastlayer' + str(houlsby_MHA_lastlayer) \\\n",
    "+ '_ds' + str(ds) \\\n",
    "+ '_fp16' + str(fp16) \\\n",
    "+ '_best' + str(load_best_model_at_end) \\\n",
    "+ '_metric' + str(metric_for_best_model) \\\n",
    "+ '_weightedloss' + str(weighted_loss) \\\n",
    "+ '_c' + str(c) \\\n",
    "+ '_ns' + str(next_sentence) \\\n",
    "+ '_adapterconfig' + str(adapter_config_name)\n",
    "\n",
    "\n",
    "# path to outputs\n",
    "path_to_outputs = root/'outputs'/outputs\n",
    "\n",
    "# path to adapter\n",
    "adapters_folder = 'adapters-' + task\n",
    "#path_to_save_adapter = path_to_outputs/adapters_folder\n",
    "path_to_save_adapter = '/home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer/adapters-ner'\n",
    "                             \n",
    "# Config of the task adapter\n",
    "load_adapter = str(path_to_save_adapter)\n",
    "adapter_config = str(path_to_save_adapter) + \"/adapter_config.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "78e9b439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer/adapters-ner/adapter_config.json\n"
     ]
    }
   ],
   "source": [
    "print(adapter_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "646b5d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading module configuration from /home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer/adapters-ner/adapter_config.json\n",
      "Overwriting existing adapter 'ner'.\n",
      "Loading module weights from /home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer/adapters-ner/pytorch_adapter.bin\n",
      "Some weights of the state_dict could not be loaded into model: bert.encoder.layer.0.output.adapters.ner.adapter_down.0.weight, bert.encoder.layer.0.output.adapters.ner.adapter_down.0.bias, bert.encoder.layer.0.output.adapters.ner.adapter_up.weight, bert.encoder.layer.0.output.adapters.ner.adapter_up.bias, bert.encoder.layer.1.output.adapters.ner.adapter_down.0.weight, bert.encoder.layer.1.output.adapters.ner.adapter_down.0.bias, bert.encoder.layer.1.output.adapters.ner.adapter_up.weight, bert.encoder.layer.1.output.adapters.ner.adapter_up.bias, bert.encoder.layer.2.output.adapters.ner.adapter_down.0.weight, bert.encoder.layer.2.output.adapters.ner.adapter_down.0.bias, bert.encoder.layer.2.output.adapters.ner.adapter_up.weight, bert.encoder.layer.2.output.adapters.ner.adapter_up.bias, bert.encoder.layer.3.output.adapters.ner.adapter_down.0.weight, bert.encoder.layer.3.output.adapters.ner.adapter_down.0.bias, bert.encoder.layer.3.output.adapters.ner.adapter_up.weight, bert.encoder.layer.3.output.adapters.ner.adapter_up.bias, bert.encoder.layer.4.output.adapters.ner.adapter_down.0.weight, bert.encoder.layer.4.output.adapters.ner.adapter_down.0.bias, bert.encoder.layer.4.output.adapters.ner.adapter_up.weight, bert.encoder.layer.4.output.adapters.ner.adapter_up.bias, bert.encoder.layer.5.output.adapters.ner.adapter_down.0.weight, bert.encoder.layer.5.output.adapters.ner.adapter_down.0.bias, bert.encoder.layer.5.output.adapters.ner.adapter_up.weight, bert.encoder.layer.5.output.adapters.ner.adapter_up.bias, bert.encoder.layer.6.output.adapters.ner.adapter_down.0.weight, bert.encoder.layer.6.output.adapters.ner.adapter_down.0.bias, bert.encoder.layer.6.output.adapters.ner.adapter_up.weight, bert.encoder.layer.6.output.adapters.ner.adapter_up.bias, bert.encoder.layer.7.output.adapters.ner.adapter_down.0.weight, bert.encoder.layer.7.output.adapters.ner.adapter_down.0.bias, bert.encoder.layer.7.output.adapters.ner.adapter_up.weight, bert.encoder.layer.7.output.adapters.ner.adapter_up.bias, bert.encoder.layer.8.output.adapters.ner.adapter_down.0.weight, bert.encoder.layer.8.output.adapters.ner.adapter_down.0.bias, bert.encoder.layer.8.output.adapters.ner.adapter_up.weight, bert.encoder.layer.8.output.adapters.ner.adapter_up.bias, bert.encoder.layer.9.output.adapters.ner.adapter_down.0.weight, bert.encoder.layer.9.output.adapters.ner.adapter_down.0.bias, bert.encoder.layer.9.output.adapters.ner.adapter_up.weight, bert.encoder.layer.9.output.adapters.ner.adapter_up.bias, bert.encoder.layer.10.output.adapters.ner.adapter_down.0.weight, bert.encoder.layer.10.output.adapters.ner.adapter_down.0.bias, bert.encoder.layer.10.output.adapters.ner.adapter_up.weight, bert.encoder.layer.10.output.adapters.ner.adapter_up.bias\n",
      "Loading module configuration from /home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer/adapters-ner/head_config.json\n",
      "Loading module weights from /home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer/adapters-ner/pytorch_model_head.bin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ner'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the task adapter with head\n",
    "task_name = task\n",
    "model_ner.load_adapter(\n",
    "    load_adapter,\n",
    "    config=adapter_config,\n",
    "    load_as=task_name,\n",
    "    with_head = True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1a703d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/huggingface/transformers/issues/20\n",
    "# https://github.com/huggingface/transformers/issues/7881\n",
    "'''\n",
    "thomwolf commented on Nov 14, 2018\n",
    "\n",
    "Ok, I think I found the issue, your BertConfig is not build from the configuration file for some reason and thus use the default value of type_vocab_size in BertConfig which is 16.\n",
    "\n",
    "This error happen on my system when I use config = BertConfig('bert_config.json') instead of config = BertConfig.from_json_file('bert_config.json').\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6b9b0530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.state_dict of BertForTokenClassification(\n",
       "  (shared_parameters): ModuleDict()\n",
       "  (bert): BertModel(\n",
       "    (shared_parameters): ModuleDict()\n",
       "    (invertible_adapters): ModuleDict()\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(29794, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (adapters): ModuleDict()\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (adapters): ModuleDict()\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (adapters): ModuleDict()\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (adapters): ModuleDict()\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (adapters): ModuleDict()\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (adapters): ModuleDict()\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (adapters): ModuleDict()\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (adapters): ModuleDict()\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (adapters): ModuleDict()\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (adapters): ModuleDict()\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (adapters): ModuleDict()\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (adapters): ModuleDict()\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (prefix_tuning): PrefixTuningPool(\n",
       "      (prefix_tunings): ModuleDict()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=13, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ner.state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cab97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "(dropout): Dropout(p=0.1, inplace=False)\n",
    "  (classifier): Linear(in_features=1024, out_features=13, bias=True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "136ed4fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for BertModel:\n\tMissing key(s) in state_dict: \"embeddings.position_ids\", \"embeddings.word_embeddings.weight\", \"embeddings.position_embeddings.weight\", \"embeddings.token_type_embeddings.weight\", \"embeddings.LayerNorm.weight\", \"embeddings.LayerNorm.bias\", \"encoder.layer.0.attention.self.query.weight\", \"encoder.layer.0.attention.self.query.bias\", \"encoder.layer.0.attention.self.key.weight\", \"encoder.layer.0.attention.self.key.bias\", \"encoder.layer.0.attention.self.value.weight\", \"encoder.layer.0.attention.self.value.bias\", \"encoder.layer.0.attention.output.dense.weight\", \"encoder.layer.0.attention.output.dense.bias\", \"encoder.layer.0.attention.output.LayerNorm.weight\", \"encoder.layer.0.attention.output.LayerNorm.bias\", \"encoder.layer.0.intermediate.dense.weight\", \"encoder.layer.0.intermediate.dense.bias\", \"encoder.layer.0.output.dense.weight\", \"encoder.layer.0.output.dense.bias\", \"encoder.layer.0.output.LayerNorm.weight\", \"encoder.layer.0.output.LayerNorm.bias\", \"encoder.layer.1.attention.self.query.weight\", \"encoder.layer.1.attention.self.query.bias\", \"encoder.layer.1.attention.self.key.weight\", \"encoder.layer.1.attention.self.key.bias\", \"encoder.layer.1.attention.self.value.weight\", \"encoder.layer.1.attention.self.value.bias\", \"encoder.layer.1.attention.output.dense.weight\", \"encoder.layer.1.attention.output.dense.bias\", \"encoder.layer.1.attention.output.LayerNorm.weight\", \"encoder.layer.1.attention.output.LayerNorm.bias\", \"encoder.layer.1.intermediate.dense.weight\", \"encoder.layer.1.intermediate.dense.bias\", \"encoder.layer.1.output.dense.weight\", \"encoder.layer.1.output.dense.bias\", \"encoder.layer.1.output.LayerNorm.weight\", \"encoder.layer.1.output.LayerNorm.bias\", \"encoder.layer.2.attention.self.query.weight\", \"encoder.layer.2.attention.self.query.bias\", \"encoder.layer.2.attention.self.key.weight\", \"encoder.layer.2.attention.self.key.bias\", \"encoder.layer.2.attention.self.value.weight\", \"encoder.layer.2.attention.self.value.bias\", \"encoder.layer.2.attention.output.dense.weight\", \"encoder.layer.2.attention.output.dense.bias\", \"encoder.layer.2.attention.output.LayerNorm.weight\", \"encoder.layer.2.attention.output.LayerNorm.bias\", \"encoder.layer.2.intermediate.dense.weight\", \"encoder.layer.2.intermediate.dense.bias\", \"encoder.layer.2.output.dense.weight\", \"encoder.layer.2.output.dense.bias\", \"encoder.layer.2.output.LayerNorm.weight\", \"encoder.layer.2.output.LayerNorm.bias\", \"encoder.layer.3.attention.self.query.weight\", \"encoder.layer.3.attention.self.query.bias\", \"encoder.layer.3.attention.self.key.weight\", \"encoder.layer.3.attention.self.key.bias\", \"encoder.layer.3.attention.self.value.weight\", \"encoder.layer.3.attention.self.value.bias\", \"encoder.layer.3.attention.output.dense.weight\", \"encoder.layer.3.attention.output.dense.bias\", \"encoder.layer.3.attention.output.LayerNorm.weight\", \"encoder.layer.3.attention.output.LayerNorm.bias\", \"encoder.layer.3.intermediate.dense.weight\", \"encoder.layer.3.intermediate.dense.bias\", \"encoder.layer.3.output.dense.weight\", \"encoder.layer.3.output.dense.bias\", \"encoder.layer.3.output.LayerNorm.weight\", \"encoder.layer.3.output.LayerNorm.bias\", \"encoder.layer.4.attention.self.query.weight\", \"encoder.layer.4.attention.self.query.bias\", \"encoder.layer.4.attention.self.key.weight\", \"encoder.layer.4.attention.self.key.bias\", \"encoder.layer.4.attention.self.value.weight\", \"encoder.layer.4.attention.self.value.bias\", \"encoder.layer.4.attention.output.dense.weight\", \"encoder.layer.4.attention.output.dense.bias\", \"encoder.layer.4.attention.output.LayerNorm.weight\", \"encoder.layer.4.attention.output.LayerNorm.bias\", \"encoder.layer.4.intermediate.dense.weight\", \"encoder.layer.4.intermediate.dense.bias\", \"encoder.layer.4.output.dense.weight\", \"encoder.layer.4.output.dense.bias\", \"encoder.layer.4.output.LayerNorm.weight\", \"encoder.layer.4.output.LayerNorm.bias\", \"encoder.layer.5.attention.self.query.weight\", \"encoder.layer.5.attention.self.query.bias\", \"encoder.layer.5.attention.self.key.weight\", \"encoder.layer.5.attention.self.key.bias\", \"encoder.layer.5.attention.self.value.weight\", \"encoder.layer.5.attention.self.value.bias\", \"encoder.layer.5.attention.output.dense.weight\", \"encoder.layer.5.attention.output.dense.bias\", \"encoder.layer.5.attention.output.LayerNorm.weight\", \"encoder.layer.5.attention.output.LayerNorm.bias\", \"encoder.layer.5.intermediate.dense.weight\", \"encoder.layer.5.intermediate.dense.bias\", \"encoder.layer.5.output.dense.weight\", \"encoder.layer.5.output.dense.bias\", \"encoder.layer.5.output.LayerNorm.weight\", \"encoder.layer.5.output.LayerNorm.bias\", \"encoder.layer.6.attention.self.query.weight\", \"encoder.layer.6.attention.self.query.bias\", \"encoder.layer.6.attention.self.key.weight\", \"encoder.layer.6.attention.self.key.bias\", \"encoder.layer.6.attention.self.value.weight\", \"encoder.layer.6.attention.self.value.bias\", \"encoder.layer.6.attention.output.dense.weight\", \"encoder.layer.6.attention.output.dense.bias\", \"encoder.layer.6.attention.output.LayerNorm.weight\", \"encoder.layer.6.attention.output.LayerNorm.bias\", \"encoder.layer.6.intermediate.dense.weight\", \"encoder.layer.6.intermediate.dense.bias\", \"encoder.layer.6.output.dense.weight\", \"encoder.layer.6.output.dense.bias\", \"encoder.layer.6.output.LayerNorm.weight\", \"encoder.layer.6.output.LayerNorm.bias\", \"encoder.layer.7.attention.self.query.weight\", \"encoder.layer.7.attention.self.query.bias\", \"encoder.layer.7.attention.self.key.weight\", \"encoder.layer.7.attention.self.key.bias\", \"encoder.layer.7.attention.self.value.weight\", \"encoder.layer.7.attention.self.value.bias\", \"encoder.layer.7.attention.output.dense.weight\", \"encoder.layer.7.attention.output.dense.bias\", \"encoder.layer.7.attention.output.LayerNorm.weight\", \"encoder.layer.7.attention.output.LayerNorm.bias\", \"encoder.layer.7.intermediate.dense.weight\", \"encoder.layer.7.intermediate.dense.bias\", \"encoder.layer.7.output.dense.weight\", \"encoder.layer.7.output.dense.bias\", \"encoder.layer.7.output.LayerNorm.weight\", \"encoder.layer.7.output.LayerNorm.bias\", \"encoder.layer.8.attention.self.query.weight\", \"encoder.layer.8.attention.self.query.bias\", \"encoder.layer.8.attention.self.key.weight\", \"encoder.layer.8.attention.self.key.bias\", \"encoder.layer.8.attention.self.value.weight\", \"encoder.layer.8.attention.self.value.bias\", \"encoder.layer.8.attention.output.dense.weight\", \"encoder.layer.8.attention.output.dense.bias\", \"encoder.layer.8.attention.output.LayerNorm.weight\", \"encoder.layer.8.attention.output.LayerNorm.bias\", \"encoder.layer.8.intermediate.dense.weight\", \"encoder.layer.8.intermediate.dense.bias\", \"encoder.layer.8.output.dense.weight\", \"encoder.layer.8.output.dense.bias\", \"encoder.layer.8.output.LayerNorm.weight\", \"encoder.layer.8.output.LayerNorm.bias\", \"encoder.layer.9.attention.self.query.weight\", \"encoder.layer.9.attention.self.query.bias\", \"encoder.layer.9.attention.self.key.weight\", \"encoder.layer.9.attention.self.key.bias\", \"encoder.layer.9.attention.self.value.weight\", \"encoder.layer.9.attention.self.value.bias\", \"encoder.layer.9.attention.output.dense.weight\", \"encoder.layer.9.attention.output.dense.bias\", \"encoder.layer.9.attention.output.LayerNorm.weight\", \"encoder.layer.9.attention.output.LayerNorm.bias\", \"encoder.layer.9.intermediate.dense.weight\", \"encoder.layer.9.intermediate.dense.bias\", \"encoder.layer.9.output.dense.weight\", \"encoder.layer.9.output.dense.bias\", \"encoder.layer.9.output.LayerNorm.weight\", \"encoder.layer.9.output.LayerNorm.bias\", \"encoder.layer.10.attention.self.query.weight\", \"encoder.layer.10.attention.self.query.bias\", \"encoder.layer.10.attention.self.key.weight\", \"encoder.layer.10.attention.self.key.bias\", \"encoder.layer.10.attention.self.value.weight\", \"encoder.layer.10.attention.self.value.bias\", \"encoder.layer.10.attention.output.dense.weight\", \"encoder.layer.10.attention.output.dense.bias\", \"encoder.layer.10.attention.output.LayerNorm.weight\", \"encoder.layer.10.attention.output.LayerNorm.bias\", \"encoder.layer.10.intermediate.dense.weight\", \"encoder.layer.10.intermediate.dense.bias\", \"encoder.layer.10.output.dense.weight\", \"encoder.layer.10.output.dense.bias\", \"encoder.layer.10.output.LayerNorm.weight\", \"encoder.layer.10.output.LayerNorm.bias\", \"encoder.layer.11.attention.self.query.weight\", \"encoder.layer.11.attention.self.query.bias\", \"encoder.layer.11.attention.self.key.weight\", \"encoder.layer.11.attention.self.key.bias\", \"encoder.layer.11.attention.self.value.weight\", \"encoder.layer.11.attention.self.value.bias\", \"encoder.layer.11.attention.output.dense.weight\", \"encoder.layer.11.attention.output.dense.bias\", \"encoder.layer.11.attention.output.LayerNorm.weight\", \"encoder.layer.11.attention.output.LayerNorm.bias\", \"encoder.layer.11.intermediate.dense.weight\", \"encoder.layer.11.intermediate.dense.bias\", \"encoder.layer.11.output.dense.weight\", \"encoder.layer.11.output.dense.bias\", \"encoder.layer.11.output.LayerNorm.weight\", \"encoder.layer.11.output.LayerNorm.bias\", \"pooler.dense.weight\", \"pooler.dense.bias\". \n\tUnexpected key(s) in state_dict: \"bert.embeddings.position_ids\", \"bert.embeddings.word_embeddings.weight\", \"bert.embeddings.position_embeddings.weight\", \"bert.embeddings.token_type_embeddings.weight\", \"bert.embeddings.LayerNorm.weight\", \"bert.embeddings.LayerNorm.bias\", \"bert.encoder.layer.0.attention.self.query.weight\", \"bert.encoder.layer.0.attention.self.query.bias\", \"bert.encoder.layer.0.attention.self.key.weight\", \"bert.encoder.layer.0.attention.self.key.bias\", \"bert.encoder.layer.0.attention.self.value.weight\", \"bert.encoder.layer.0.attention.self.value.bias\", \"bert.encoder.layer.0.attention.output.dense.weight\", \"bert.encoder.layer.0.attention.output.dense.bias\", \"bert.encoder.layer.0.attention.output.LayerNorm.weight\", \"bert.encoder.layer.0.attention.output.LayerNorm.bias\", \"bert.encoder.layer.0.intermediate.dense.weight\", \"bert.encoder.layer.0.intermediate.dense.bias\", \"bert.encoder.layer.0.output.dense.weight\", \"bert.encoder.layer.0.output.dense.bias\", \"bert.encoder.layer.0.output.LayerNorm.weight\", \"bert.encoder.layer.0.output.LayerNorm.bias\", \"bert.encoder.layer.0.output.adapters.ner.adapter_down.0.weight\", \"bert.encoder.layer.0.output.adapters.ner.adapter_down.0.bias\", \"bert.encoder.layer.0.output.adapters.ner.adapter_up.weight\", \"bert.encoder.layer.0.output.adapters.ner.adapter_up.bias\", \"bert.encoder.layer.1.attention.self.query.weight\", \"bert.encoder.layer.1.attention.self.query.bias\", \"bert.encoder.layer.1.attention.self.key.weight\", \"bert.encoder.layer.1.attention.self.key.bias\", \"bert.encoder.layer.1.attention.self.value.weight\", \"bert.encoder.layer.1.attention.self.value.bias\", \"bert.encoder.layer.1.attention.output.dense.weight\", \"bert.encoder.layer.1.attention.output.dense.bias\", \"bert.encoder.layer.1.attention.output.LayerNorm.weight\", \"bert.encoder.layer.1.attention.output.LayerNorm.bias\", \"bert.encoder.layer.1.intermediate.dense.weight\", \"bert.encoder.layer.1.intermediate.dense.bias\", \"bert.encoder.layer.1.output.dense.weight\", \"bert.encoder.layer.1.output.dense.bias\", \"bert.encoder.layer.1.output.LayerNorm.weight\", \"bert.encoder.layer.1.output.LayerNorm.bias\", \"bert.encoder.layer.1.output.adapters.ner.adapter_down.0.weight\", \"bert.encoder.layer.1.output.adapters.ner.adapter_down.0.bias\", \"bert.encoder.layer.1.output.adapters.ner.adapter_up.weight\", \"bert.encoder.layer.1.output.adapters.ner.adapter_up.bias\", \"bert.encoder.layer.2.attention.self.query.weight\", \"bert.encoder.layer.2.attention.self.query.bias\", \"bert.encoder.layer.2.attention.self.key.weight\", \"bert.encoder.layer.2.attention.self.key.bias\", \"bert.encoder.layer.2.attention.self.value.weight\", \"bert.encoder.layer.2.attention.self.value.bias\", \"bert.encoder.layer.2.attention.output.dense.weight\", \"bert.encoder.layer.2.attention.output.dense.bias\", \"bert.encoder.layer.2.attention.output.LayerNorm.weight\", \"bert.encoder.layer.2.attention.output.LayerNorm.bias\", \"bert.encoder.layer.2.intermediate.dense.weight\", \"bert.encoder.layer.2.intermediate.dense.bias\", \"bert.encoder.layer.2.output.dense.weight\", \"bert.encoder.layer.2.output.dense.bias\", \"bert.encoder.layer.2.output.LayerNorm.weight\", \"bert.encoder.layer.2.output.LayerNorm.bias\", \"bert.encoder.layer.2.output.adapters.ner.adapter_down.0.weight\", \"bert.encoder.layer.2.output.adapters.ner.adapter_down.0.bias\", \"bert.encoder.layer.2.output.adapters.ner.adapter_up.weight\", \"bert.encoder.layer.2.output.adapters.ner.adapter_up.bias\", \"bert.encoder.layer.3.attention.self.query.weight\", \"bert.encoder.layer.3.attention.self.query.bias\", \"bert.encoder.layer.3.attention.self.key.weight\", \"bert.encoder.layer.3.attention.self.key.bias\", \"bert.encoder.layer.3.attention.self.value.weight\", \"bert.encoder.layer.3.attention.self.value.bias\", \"bert.encoder.layer.3.attention.output.dense.weight\", \"bert.encoder.layer.3.attention.output.dense.bias\", \"bert.encoder.layer.3.attention.output.LayerNorm.weight\", \"bert.encoder.layer.3.attention.output.LayerNorm.bias\", \"bert.encoder.layer.3.intermediate.dense.weight\", \"bert.encoder.layer.3.intermediate.dense.bias\", \"bert.encoder.layer.3.output.dense.weight\", \"bert.encoder.layer.3.output.dense.bias\", \"bert.encoder.layer.3.output.LayerNorm.weight\", \"bert.encoder.layer.3.output.LayerNorm.bias\", \"bert.encoder.layer.3.output.adapters.ner.adapter_down.0.weight\", \"bert.encoder.layer.3.output.adapters.ner.adapter_down.0.bias\", \"bert.encoder.layer.3.output.adapters.ner.adapter_up.weight\", \"bert.encoder.layer.3.output.adapters.ner.adapter_up.bias\", \"bert.encoder.layer.4.attention.self.query.weight\", \"bert.encoder.layer.4.attention.self.query.bias\", \"bert.encoder.layer.4.attention.self.key.weight\", \"bert.encoder.layer.4.attention.self.key.bias\", \"bert.encoder.layer.4.attention.self.value.weight\", \"bert.encoder.layer.4.attention.self.value.bias\", \"bert.encoder.layer.4.attention.output.dense.weight\", \"bert.encoder.layer.4.attention.output.dense.bias\", \"bert.encoder.layer.4.attention.output.LayerNorm.weight\", \"bert.encoder.layer.4.attention.output.LayerNorm.bias\", \"bert.encoder.layer.4.intermediate.dense.weight\", \"bert.encoder.layer.4.intermediate.dense.bias\", \"bert.encoder.layer.4.output.dense.weight\", \"bert.encoder.layer.4.output.dense.bias\", \"bert.encoder.layer.4.output.LayerNorm.weight\", \"bert.encoder.layer.4.output.LayerNorm.bias\", \"bert.encoder.layer.4.output.adapters.ner.adapter_down.0.weight\", \"bert.encoder.layer.4.output.adapters.ner.adapter_down.0.bias\", \"bert.encoder.layer.4.output.adapters.ner.adapter_up.weight\", \"bert.encoder.layer.4.output.adapters.ner.adapter_up.bias\", \"bert.encoder.layer.5.attention.self.query.weight\", \"bert.encoder.layer.5.attention.self.query.bias\", \"bert.encoder.layer.5.attention.self.key.weight\", \"bert.encoder.layer.5.attention.self.key.bias\", \"bert.encoder.layer.5.attention.self.value.weight\", \"bert.encoder.layer.5.attention.self.value.bias\", \"bert.encoder.layer.5.attention.output.dense.weight\", \"bert.encoder.layer.5.attention.output.dense.bias\", \"bert.encoder.layer.5.attention.output.LayerNorm.weight\", \"bert.encoder.layer.5.attention.output.LayerNorm.bias\", \"bert.encoder.layer.5.intermediate.dense.weight\", \"bert.encoder.layer.5.intermediate.dense.bias\", \"bert.encoder.layer.5.output.dense.weight\", \"bert.encoder.layer.5.output.dense.bias\", \"bert.encoder.layer.5.output.LayerNorm.weight\", \"bert.encoder.layer.5.output.LayerNorm.bias\", \"bert.encoder.layer.5.output.adapters.ner.adapter_down.0.weight\", \"bert.encoder.layer.5.output.adapters.ner.adapter_down.0.bias\", \"bert.encoder.layer.5.output.adapters.ner.adapter_up.weight\", \"bert.encoder.layer.5.output.adapters.ner.adapter_up.bias\", \"bert.encoder.layer.6.attention.self.query.weight\", \"bert.encoder.layer.6.attention.self.query.bias\", \"bert.encoder.layer.6.attention.self.key.weight\", \"bert.encoder.layer.6.attention.self.key.bias\", \"bert.encoder.layer.6.attention.self.value.weight\", \"bert.encoder.layer.6.attention.self.value.bias\", \"bert.encoder.layer.6.attention.output.dense.weight\", \"bert.encoder.layer.6.attention.output.dense.bias\", \"bert.encoder.layer.6.attention.output.LayerNorm.weight\", \"bert.encoder.layer.6.attention.output.LayerNorm.bias\", \"bert.encoder.layer.6.intermediate.dense.weight\", \"bert.encoder.layer.6.intermediate.dense.bias\", \"bert.encoder.layer.6.output.dense.weight\", \"bert.encoder.layer.6.output.dense.bias\", \"bert.encoder.layer.6.output.LayerNorm.weight\", \"bert.encoder.layer.6.output.LayerNorm.bias\", \"bert.encoder.layer.6.output.adapters.ner.adapter_down.0.weight\", \"bert.encoder.layer.6.output.adapters.ner.adapter_down.0.bias\", \"bert.encoder.layer.6.output.adapters.ner.adapter_up.weight\", \"bert.encoder.layer.6.output.adapters.ner.adapter_up.bias\", \"bert.encoder.layer.7.attention.self.query.weight\", \"bert.encoder.layer.7.attention.self.query.bias\", \"bert.encoder.layer.7.attention.self.key.weight\", \"bert.encoder.layer.7.attention.self.key.bias\", \"bert.encoder.layer.7.attention.self.value.weight\", \"bert.encoder.layer.7.attention.self.value.bias\", \"bert.encoder.layer.7.attention.output.dense.weight\", \"bert.encoder.layer.7.attention.output.dense.bias\", \"bert.encoder.layer.7.attention.output.LayerNorm.weight\", \"bert.encoder.layer.7.attention.output.LayerNorm.bias\", \"bert.encoder.layer.7.intermediate.dense.weight\", \"bert.encoder.layer.7.intermediate.dense.bias\", \"bert.encoder.layer.7.output.dense.weight\", \"bert.encoder.layer.7.output.dense.bias\", \"bert.encoder.layer.7.output.LayerNorm.weight\", \"bert.encoder.layer.7.output.LayerNorm.bias\", \"bert.encoder.layer.7.output.adapters.ner.adapter_down.0.weight\", \"bert.encoder.layer.7.output.adapters.ner.adapter_down.0.bias\", \"bert.encoder.layer.7.output.adapters.ner.adapter_up.weight\", \"bert.encoder.layer.7.output.adapters.ner.adapter_up.bias\", \"bert.encoder.layer.8.attention.self.query.weight\", \"bert.encoder.layer.8.attention.self.query.bias\", \"bert.encoder.layer.8.attention.self.key.weight\", \"bert.encoder.layer.8.attention.self.key.bias\", \"bert.encoder.layer.8.attention.self.value.weight\", \"bert.encoder.layer.8.attention.self.value.bias\", \"bert.encoder.layer.8.attention.output.dense.weight\", \"bert.encoder.layer.8.attention.output.dense.bias\", \"bert.encoder.layer.8.attention.output.LayerNorm.weight\", \"bert.encoder.layer.8.attention.output.LayerNorm.bias\", \"bert.encoder.layer.8.intermediate.dense.weight\", \"bert.encoder.layer.8.intermediate.dense.bias\", \"bert.encoder.layer.8.output.dense.weight\", \"bert.encoder.layer.8.output.dense.bias\", \"bert.encoder.layer.8.output.LayerNorm.weight\", \"bert.encoder.layer.8.output.LayerNorm.bias\", \"bert.encoder.layer.8.output.adapters.ner.adapter_down.0.weight\", \"bert.encoder.layer.8.output.adapters.ner.adapter_down.0.bias\", \"bert.encoder.layer.8.output.adapters.ner.adapter_up.weight\", \"bert.encoder.layer.8.output.adapters.ner.adapter_up.bias\", \"bert.encoder.layer.9.attention.self.query.weight\", \"bert.encoder.layer.9.attention.self.query.bias\", \"bert.encoder.layer.9.attention.self.key.weight\", \"bert.encoder.layer.9.attention.self.key.bias\", \"bert.encoder.layer.9.attention.self.value.weight\", \"bert.encoder.layer.9.attention.self.value.bias\", \"bert.encoder.layer.9.attention.output.dense.weight\", \"bert.encoder.layer.9.attention.output.dense.bias\", \"bert.encoder.layer.9.attention.output.LayerNorm.weight\", \"bert.encoder.layer.9.attention.output.LayerNorm.bias\", \"bert.encoder.layer.9.intermediate.dense.weight\", \"bert.encoder.layer.9.intermediate.dense.bias\", \"bert.encoder.layer.9.output.dense.weight\", \"bert.encoder.layer.9.output.dense.bias\", \"bert.encoder.layer.9.output.LayerNorm.weight\", \"bert.encoder.layer.9.output.LayerNorm.bias\", \"bert.encoder.layer.9.output.adapters.ner.adapter_down.0.weight\", \"bert.encoder.layer.9.output.adapters.ner.adapter_down.0.bias\", \"bert.encoder.layer.9.output.adapters.ner.adapter_up.weight\", \"bert.encoder.layer.9.output.adapters.ner.adapter_up.bias\", \"bert.encoder.layer.10.attention.self.query.weight\", \"bert.encoder.layer.10.attention.self.query.bias\", \"bert.encoder.layer.10.attention.self.key.weight\", \"bert.encoder.layer.10.attention.self.key.bias\", \"bert.encoder.layer.10.attention.self.value.weight\", \"bert.encoder.layer.10.attention.self.value.bias\", \"bert.encoder.layer.10.attention.output.dense.weight\", \"bert.encoder.layer.10.attention.output.dense.bias\", \"bert.encoder.layer.10.attention.output.LayerNorm.weight\", \"bert.encoder.layer.10.attention.output.LayerNorm.bias\", \"bert.encoder.layer.10.intermediate.dense.weight\", \"bert.encoder.layer.10.intermediate.dense.bias\", \"bert.encoder.layer.10.output.dense.weight\", \"bert.encoder.layer.10.output.dense.bias\", \"bert.encoder.layer.10.output.LayerNorm.weight\", \"bert.encoder.layer.10.output.LayerNorm.bias\", \"bert.encoder.layer.10.output.adapters.ner.adapter_down.0.weight\", \"bert.encoder.layer.10.output.adapters.ner.adapter_down.0.bias\", \"bert.encoder.layer.10.output.adapters.ner.adapter_up.weight\", \"bert.encoder.layer.10.output.adapters.ner.adapter_up.bias\", \"bert.encoder.layer.11.attention.self.query.weight\", \"bert.encoder.layer.11.attention.self.query.bias\", \"bert.encoder.layer.11.attention.self.key.weight\", \"bert.encoder.layer.11.attention.self.key.bias\", \"bert.encoder.layer.11.attention.self.value.weight\", \"bert.encoder.layer.11.attention.self.value.bias\", \"bert.encoder.layer.11.attention.output.dense.weight\", \"bert.encoder.layer.11.attention.output.dense.bias\", \"bert.encoder.layer.11.attention.output.LayerNorm.weight\", \"bert.encoder.layer.11.attention.output.LayerNorm.bias\", \"bert.encoder.layer.11.intermediate.dense.weight\", \"bert.encoder.layer.11.intermediate.dense.bias\", \"bert.encoder.layer.11.output.dense.weight\", \"bert.encoder.layer.11.output.dense.bias\", \"bert.encoder.layer.11.output.LayerNorm.weight\", \"bert.encoder.layer.11.output.LayerNorm.bias\", \"classifier.weight\", \"classifier.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [189]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m bert_config \u001b[38;5;241m=\u001b[39m BertConfig\u001b[38;5;241m.\u001b[39mfrom_json_file(BertFolder\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig.json\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m model\u001b[38;5;241m=\u001b[39mBertModel(bert_config)\n\u001b[0;32m----> 8\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBertFolder\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpytorch_model.bin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1604\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1599\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   1600\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1601\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   1603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1604\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1605\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   1606\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for BertModel:\n\tMissing key(s) in state_dict: \"embeddings.position_ids\", \"embeddings.word_embeddings.weight\", \"embeddings.position_embeddings.weight\", \"embeddings.token_type_embeddings.weight\", \"embeddings.LayerNorm.weight\", \"embeddings.LayerNorm.bias\", \"encoder.layer.0.attention.self.query.weight\", \"encoder.layer.0.attention.self.query.bias\", \"encoder.layer.0.attention.self.key.weight\", \"encoder.layer.0.attention.self.key.bias\", \"encoder.layer.0.attention.self.value.weight\", \"encoder.layer.0.attention.self.value.bias\", \"encoder.layer.0.attention.output.dense.weight\", \"encoder.layer.0.attention.output.dense.bias\", \"encoder.layer.0.attention.output.LayerNorm.weight\", \"encoder.layer.0.attention.output.LayerNorm.bias\", \"encoder.layer.0.intermediate.dense.weight\", \"encoder.layer.0.intermediate.dense.bias\", \"encoder.layer.0.output.dense.weight\", \"encoder.layer.0.output.dense.bias\", \"encoder.layer.0.output.LayerNorm.weight\", \"encoder.layer.0.output.LayerNorm.bias\", \"encoder.layer.1.attention.self.query.weight\", \"encoder.layer.1.attention.self.query.bias\", \"encoder.layer.1.attention.self.key.weight\", \"encoder.layer.1.attention.self.key.bias\", \"encoder.layer.1.attention.self.value.weight\", \"encoder.layer.1.attention.self.value.bias\", \"encoder.layer.1.attention.output.dense.weight\", \"encoder.layer.1.attention.output.dense.bias\", \"encoder.layer.1.attention.output.LayerNorm.weight\", \"encoder.layer.1.attention.output.LayerNorm.bias\", \"encoder.layer.1.intermediate.dense.weight\", \"encoder.layer.1.intermediate.dense.bias\", \"encoder.layer.1.output.dense.weight\", \"encoder.layer.1.output.dense.bias\", \"encoder.layer.1.output.LayerNorm.weight\", \"encoder.layer.1.output.LayerNorm.bias\", \"encoder.layer.2.attention.self.query.weight\", \"encoder.layer.2.attention.self.query.bias\", \"encoder.layer.2.attention.self.key.weight\", \"encoder.layer.2.attention.self.key.bias\", \"encoder.layer.2.attention.self.value.weight\", \"encoder.layer.2.attention.self.value.bias\", \"encoder.layer.2.attention.output.dense.weight\", \"encoder.layer.2.attention.output.dense.bias\", \"encoder.layer.2.attention.output.LayerNorm.weight\", \"encoder.layer.2.attention.output.LayerNorm.bias\", \"encoder.layer.2.intermediate.dense.weight\", \"encoder.layer.2.intermediate.dense.bias\", \"encoder.layer.2.output.dense.weight\", \"encoder.layer.2.output.dense.bias\", \"encoder.layer.2.output.LayerNorm.weight\", \"encoder.layer.2.output.LayerNorm.bias\", \"encoder.layer.3.attention.self.query.weight\", \"encoder.layer.3.attention.self.query.bias\", \"encoder.layer.3.attention.self.key.weight\", \"encoder.layer.3.attention.self.key.bias\", \"encoder.layer.3.attention.self.value.weight\", \"encoder.layer.3.attention.self.value.bias\", \"encoder.layer.3.attention.output.dense.weight\", \"encoder.layer.3.attention.output.dense.bias\", \"encoder.layer.3.attention.output.LayerNorm.weight\", \"encoder.layer.3.attention.output.LayerNorm.bias\", \"encoder.layer.3.intermediate.dense.weight\", \"encoder.layer.3.intermediate.dense.bias\", \"encoder.layer.3.output.dense.weight\", \"encoder.layer.3.output.dense.bias\", \"encoder.layer.3.output.LayerNorm.weight\", \"encoder.layer.3.output.LayerNorm.bias\", \"encoder.layer.4.attention.self.query.weight\", \"encoder.layer.4.attention.self.query.bias\", \"encoder.layer.4.attention.self.key.weight\", \"encoder.layer.4.attention.self.key.bias\", \"encoder.layer.4.attention.self.value.weight\", \"encoder.layer.4.attention.self.value.bias\", \"encoder.layer.4.attention.output.dense.weight\", \"encoder.layer.4.attention.output.dense.bias\", \"encoder.layer.4.attention.output.LayerNorm.weight\", \"encoder.layer.4.attention.output.LayerNorm.bias\", \"encoder.layer.4.intermediate.dense.weight\", \"encoder.layer.4.intermediate.dense.bias\", \"encoder.layer.4.output.dense.weight\", \"encoder.layer.4.output.dense.bias\", \"encoder.layer.4.output.LayerNorm.weight\", \"encoder.layer.4.output.LayerNorm.bias\", \"encoder.layer.5.attention.self.query.weight\", \"encoder.layer.5.attention.self.query.bias\", \"encoder.layer.5.attention.self.key.weight\", \"encoder.layer.5.attention.self.key.bias\", \"encoder.layer.5.attention.self.value.weight\", \"encoder.layer.5.attention.self.value.bias\", \"encoder.layer.5.attention.output.dense.weight\", \"encoder.layer.5.attention.output.dense.bias\", \"encoder.layer.5.attention.output.LayerNorm.weight\", \"encoder.layer.5.attention.output.LayerNorm.bias\", \"encoder.layer.5.intermediate.dense.weight\", \"encoder.layer.5.intermediate.dense.bias\", \"encoder.layer.5.output.dense.weight\", \"encoder.layer.5.output.dense.bias\", \"encoder.layer.5.output.LayerNorm.weight\", \"encoder.layer.5.output.LayerNorm.bias\", \"encoder.layer.6.attention.self.query.weight\", \"encoder.layer.6.attention.self.query.bias\", \"encoder.layer.6.attention.self.key.weight\", \"encoder.layer.6.attention.self.key.bias\", \"encoder.layer.6.attention.self.value.weight\", \"encoder.layer.6.attention.self.value.bias\", \"encoder.layer.6.attention.output.dense.weight\", \"encoder.layer.6.attention.output.dense.bias\", \"encoder.layer.6.attention.output.LayerNorm.weight\", \"encoder.layer.6.attention.output.LayerNorm.bias\", \"encoder.layer.6.intermediate.dense.weight\", \"encoder.layer.6.intermediate.dense.bias\", \"encoder.layer.6.output.dense.weight\", \"encoder.layer.6.output.dense.bias\", \"encoder.layer.6.output.LayerNorm.weight\", \"encoder.layer.6.output.LayerNorm.bias\", \"encoder.layer.7.attention.self.query.weight\", \"encoder.layer.7.attention.self.query.bias\", \"encoder.layer.7.attention.self.key.weight\", \"encoder.layer.7.attention.self.key.bias\", \"encoder.layer.7.attention.self.value.weight\", \"encoder.layer.7.attention.self.value.bias\", \"encoder.layer.7.attention.output.dense.weight\", \"encoder.layer.7.attention.output.dense.bias\", \"encoder.layer.7.attention.output.LayerNorm.weight\", \"encoder.layer.7.attention.output.LayerNorm.bias\", \"encoder.layer.7.intermediate.dense.weight\", \"encoder.layer.7.intermediate.dense.bias\", \"encoder.layer.7.output.dense.weight\", \"encoder.layer.7.output.dense.bias\", \"encoder.layer.7.output.LayerNorm.weight\", \"encoder.layer.7.output.LayerNorm.bias\", \"encoder.layer.8.attention.self.query.weight\", \"encoder.layer.8.attention.self.query.bias\", \"encoder.layer.8.attention.self.key.weight\", \"encoder.layer.8.attention.self.key.bias\", \"encoder.layer.8.attention.self.value.weight\", \"encoder.layer.8.attention.self.value.bias\", \"encoder.layer.8.attention.output.dense.weight\", \"encoder.layer.8.attention.output.dense.bias\", \"encoder.layer.8.attention.output.LayerNorm.weight\", \"encoder.layer.8.attention.output.LayerNorm.bias\", \"encoder.layer.8.intermediate.dense.weight\", \"encoder.layer.8.intermediate.dense.bias\", \"encoder.layer.8.output.dense.weight\", \"encoder.layer.8.output.dense.bias\", \"encoder.layer.8.output.LayerNorm.weight\", \"encoder.layer.8.output.LayerNorm.bias\", \"encoder.layer.9.attention.self.query.weight\", \"encoder.layer.9.attention.self.query.bias\", \"encoder.layer.9.attention.self.key.weight\", \"encoder.layer.9.attention.self.key.bias\", \"encoder.layer.9.attention.self.value.weight\", \"encoder.layer.9.attention.self.value.bias\", \"encoder.layer.9.attention.output.dense.weight\", \"encoder.layer.9.attention.output.dense.bias\", \"encoder.layer.9.attention.output.LayerNorm.weight\", \"encoder.layer.9.attention.output.LayerNorm.bias\", \"encoder.layer.9.intermediate.dense.weight\", \"encoder.layer.9.intermediate.dense.bias\", \"encoder.layer.9.output.dense.weight\", \"encoder.layer.9.output.dense.bias\", \"encoder.layer.9.output.LayerNorm.weight\", \"encoder.layer.9.output.LayerNorm.bias\", \"encoder.layer.10.attention.self.query.weight\", \"encoder.layer.10.attention.self.query.bias\", \"encoder.layer.10.attention.self.key.weight\", \"encoder.layer.10.attention.self.key.bias\", \"encoder.layer.10.attention.self.value.weight\", \"encoder.layer.10.attention.self.value.bias\", \"encoder.layer.10.attention.output.dense.weight\", \"encoder.layer.10.attention.output.dense.bias\", \"encoder.layer.10.attention.output.LayerNorm.weight\", \"encoder.layer.10.attention.output.LayerNorm.bias\", \"encoder.layer.10.intermediate.dense.weight\", \"encoder.layer.10.intermediate.dense.bias\", \"encoder.layer.10.output.dense.weight\", \"encoder.layer.10.output.dense.bias\", \"encoder.layer.10.output.LayerNorm.weight\", \"encoder.layer.10.output.LayerNorm.bias\", \"encoder.layer.11.attention.self.query.weight\", \"encoder.layer.11.attention.self.query.bias\", \"encoder.layer.11.attention.self.key.weight\", \"encoder.layer.11.attention.self.key.bias\", \"encoder.layer.11.attention.self.value.weight\", \"encoder.layer.11.attention.self.value.bias\", \"encoder.layer.11.attention.output.dense.weight\", \"encoder.layer.11.attention.output.dense.bias\", \"encoder.layer.11.attention.output.LayerNorm.weight\", \"encoder.layer.11.attention.output.LayerNorm.bias\", \"encoder.layer.11.intermediate.dense.weight\", \"encoder.layer.11.intermediate.dense.bias\", \"encoder.layer.11.output.dense.weight\", \"encoder.layer.11.output.dense.bias\", \"encoder.layer.11.output.LayerNorm.weight\", \"encoder.layer.11.output.LayerNorm.bias\", \"pooler.dense.weight\", \"pooler.dense.bias\". \n\tUnexpected key(s) in state_dict: \"bert.embeddings.position_ids\", \"bert.embeddings.word_embeddings.weight\", \"bert.embeddings.position_embeddings.weight\", \"bert.embeddings.token_type_embeddings.weight\", \"bert.embeddings.LayerNorm.weight\", \"bert.embeddings.LayerNorm.bias\", \"bert.encoder.layer.0.attention.self.query.weight\", \"bert.encoder.layer.0.attention.self.query.bias\", \"bert.encoder.layer.0.attention.self.key.weight\", \"bert.encoder.layer.0.attention.self.key.bias\", \"bert.encoder.layer.0.attention.self.value.weight\", \"bert.encoder.layer.0.attention.self.value.bias\", \"bert.encoder.layer.0.attention.output.dense.weight\", \"bert.encoder.layer.0.attention.output.dense.bias\", \"bert.encoder.layer.0.attention.output.LayerNorm.weight\", \"bert.encoder.layer.0.attention.output.LayerNorm.bias\", \"bert.encoder.layer.0.intermediate.dense.weight\", \"bert.encoder.layer.0.intermediate.dense.bias\", \"bert.encoder.layer.0.output.dense.weight\", \"bert.encoder.layer.0.output.dense.bias\", \"bert.encoder.layer.0.output.LayerNorm.weight\", \"bert.encoder.layer.0.output.LayerNorm.bias\", \"bert.encoder.layer.0.output.adapters.ner.adapter_down.0.weight\", \"bert.encoder.layer.0.output.adapters.ner.adapter_down.0.bias\", \"bert.encoder.layer.0.output.adapters.ner.adapter_up.weight\", \"bert.encoder.layer.0.output.adapters.ner.adapter_up.bias\", \"bert.encoder.layer.1.attention.self.query.weight\", \"bert.encoder.layer.1.attention.self.query.bias\", \"bert.encoder.layer.1.attention.self.key.weight\", \"bert.encoder.layer.1.attention.self.key.bias\", \"bert.encoder.layer.1.attention.self.value.weight\", \"bert.encoder.layer.1.attention.self.value.bias\", \"bert.encoder.layer.1.attention.output.dense.weight\", \"bert.encoder.layer.1.attention.output.dense.bias\", \"bert.encoder.layer.1.attention.output.LayerNorm.weight\", \"bert.encoder.layer.1.attention.output.LayerNorm.bias\", \"bert.encoder.layer.1.intermediate.dense.weight\", \"bert.encoder.layer.1.intermediate.dense.bias\", \"bert.encoder.layer.1.output.dense.weight\", \"bert.encoder.layer.1.output.dense.bias\", \"bert.encoder.layer.1.output.LayerNorm.weight\", \"bert.encoder.layer.1.output.LayerNorm.bias\", \"bert.encoder.layer.1.output.adapters.ner.adapter_down.0.weight\", \"bert.encoder.layer.1.output.adapters.ner.adapter_down.0.bias\", \"bert.encoder.layer.1.output.adapters.ner.adapter_up.weight\", \"bert.encoder.layer.1.output.adapters.ner.adapter_up.bias\", \"bert.encoder.layer.2.attention.self.query.weight\", \"bert.encoder.layer.2.attention.self.query.bias\", \"bert.encoder.layer.2.attention.self.key.weight\", \"bert.encoder.layer.2.attention.self.key.bias\", \"bert.encoder.layer.2.attention.self.value.weight\", \"bert.encoder.layer.2.attention.self.value.bias\", \"bert.encoder.layer.2.attention.output.dense.weight\", \"bert.encoder.layer.2.attention.output.dense.bias\", \"bert.encoder.layer.2.attention.output.LayerNorm.weight\", \"bert.encoder.layer.2.attention.output.LayerNorm.bias\", \"bert.encoder.layer.2.intermediate.dense.weight\", \"bert.encoder.layer.2.intermediate.dense.bias\", \"bert.encoder.layer.2.output.dense.weight\", \"bert.encoder.layer.2.output.dense.bias\", \"bert.encoder.layer.2.output.LayerNorm.weight\", \"bert.encoder.layer.2.output.LayerNorm.bias\", \"bert.encoder.layer.2.output.adapters.ner.adapter_down.0.weight\", \"bert.encoder.layer.2.output.adapters.ner.adapter_down.0.bias\", \"bert.encoder.layer.2.output.adapters.ner.adapter_up.weight\", \"bert.encoder.layer.2.output.adapters.ner.adapter_up.bias\", \"bert.encoder.layer.3.attention.self.query.weight\", \"bert.encoder.layer.3.attention.self.query.bias\", \"bert.encoder.layer.3.attention.self.key.weight\", \"bert.encoder.layer.3.attention.self.key.bias\", \"bert.encoder.layer.3.attention.self.value.weight\", \"bert.encoder.layer.3.attention.self.value.bias\", \"bert.encoder.layer.3.attention.output.dense.weight\", \"bert.encoder.layer.3.attention.output.dense.bias\", \"bert.encoder.layer.3.attention.output.LayerNorm.weight\", \"bert.encoder.layer.3.attention.output.LayerNorm.bias\", \"bert.encoder.layer.3.intermediate.dense.weight\", \"bert.encoder.layer.3.intermediate.dense.bias\", \"bert.encoder.layer.3.output.dense.weight\", \"bert.encoder.layer.3.output.dense.bias\", \"bert.encoder.layer.3.output.LayerNorm.weight\", \"bert.encoder.layer.3.output.LayerNorm.bias\", \"bert.encoder.layer.3.output.adapters.ner.adapter_down.0.weight\", \"bert.encoder.layer.3.output.adapters.ner.adapter_down.0.bias\", \"bert.encoder.layer.3.output.adapters.ner.adapter_up.weight\", \"bert.encoder.layer.3.output.adapters.ner.adapter_up.bias\", \"bert.encoder.layer.4.attention.self.query.weight\", \"bert.encoder.layer.4.attention.self.query.bias\", \"bert.encoder.layer.4.attention.self.key.weight\", \"bert.encoder.layer.4.attention.self.key.bias\", \"bert.encoder.layer.4.attention.self.value.weight\", \"bert.encoder.layer.4.attention.self.value.bias\", \"bert.encoder.layer.4.attention.output.dense.weight\", \"bert.encoder.layer.4.attention.output.dense.bias\", \"bert.encoder.layer.4.attention.output.LayerNorm.weight\", \"bert.encoder.layer.4.attention.output.LayerNorm.bias\", \"bert.encoder.layer.4.intermediate.dense.weight\", \"bert.encoder.layer.4.intermediate.dense.bias\", \"bert.encoder.layer.4.output.dense.weight\", \"bert.encoder.layer.4.output.dense.bias\", \"bert.encoder.layer.4.output.LayerNorm.weight\", \"bert.encoder.layer.4.output.LayerNorm.bias\", \"bert.encoder.layer.4.output.adapters.ner.adapter_down.0.weight\", \"bert.encoder.layer.4.output.adapters.ner.adapter_down.0.bias\", \"bert.encoder.layer.4.output.adapters.ner.adapter_up.weight\", \"bert.encoder.layer.4.output.adapters.ner.adapter_up.bias\", \"bert.encoder.layer.5.attention.self.query.weight\", \"bert.encoder.layer.5.attention.self.query.bias\", \"bert.encoder.layer.5.attention.self.key.weight\", \"bert.encoder.layer.5.attention.self.key.bias\", \"bert.encoder.layer.5.attention.self.value.weight\", \"bert.encoder.layer.5.attention.self.value.bias\", \"bert.encoder.layer.5.attention.output.dense.weight\", \"bert.encoder.layer.5.attention.output.dense.bias\", \"bert.encoder.layer.5.attention.output.LayerNorm.weight\", \"bert.encoder.layer.5.attention.output.LayerNorm.bias\", \"bert.encoder.layer.5.intermediate.dense.weight\", \"bert.encoder.layer.5.intermediate.dense.bias\", \"bert.encoder.layer.5.output.dense.weight\", \"bert.encoder.layer.5.output.dense.bias\", \"bert.encoder.layer.5.output.LayerNorm.weight\", \"bert.encoder.layer.5.output.LayerNorm.bias\", \"bert.encoder.layer.5.output.adapters.ner.adapter_down.0.weight\", \"bert.encoder.layer.5.output.adapters.ner.adapter_down.0.bias\", \"bert.encoder.layer.5.output.adapters.ner.adapter_up.weight\", \"bert.encoder.layer.5.output.adapters.ner.adapter_up.bias\", \"bert.encoder.layer.6.attention.self.query.weight\", \"bert.encoder.layer.6.attention.self.query.bias\", \"bert.encoder.layer.6.attention.self.key.weight\", \"bert.encoder.layer.6.attention.self.key.bias\", \"bert.encoder.layer.6.attention.self.value.weight\", \"bert.encoder.layer.6.attention.self.value.bias\", \"bert.encoder.layer.6.attention.output.dense.weight\", \"bert.encoder.layer.6.attention.output.dense.bias\", \"bert.encoder.layer.6.attention.output.LayerNorm.weight\", \"bert.encoder.layer.6.attention.output.LayerNorm.bias\", \"bert.encoder.layer.6.intermediate.dense.weight\", \"bert.encoder.layer.6.intermediate.dense.bias\", \"bert.encoder.layer.6.output.dense.weight\", \"bert.encoder.layer.6.output.dense.bias\", \"bert.encoder.layer.6.output.LayerNorm.weight\", \"bert.encoder.layer.6.output.LayerNorm.bias\", \"bert.encoder.layer.6.output.adapters.ner.adapter_down.0.weight\", \"bert.encoder.layer.6.output.adapters.ner.adapter_down.0.bias\", \"bert.encoder.layer.6.output.adapters.ner.adapter_up.weight\", \"bert.encoder.layer.6.output.adapters.ner.adapter_up.bias\", \"bert.encoder.layer.7.attention.self.query.weight\", \"bert.encoder.layer.7.attention.self.query.bias\", \"bert.encoder.layer.7.attention.self.key.weight\", \"bert.encoder.layer.7.attention.self.key.bias\", \"bert.encoder.layer.7.attention.self.value.weight\", \"bert.encoder.layer.7.attention.self.value.bias\", \"bert.encoder.layer.7.attention.output.dense.weight\", \"bert.encoder.layer.7.attention.output.dense.bias\", \"bert.encoder.layer.7.attention.output.LayerNorm.weight\", \"bert.encoder.layer.7.attention.output.LayerNorm.bias\", \"bert.encoder.layer.7.intermediate.dense.weight\", \"bert.encoder.layer.7.intermediate.dense.bias\", \"bert.encoder.layer.7.output.dense.weight\", \"bert.encoder.layer.7.output.dense.bias\", \"bert.encoder.layer.7.output.LayerNorm.weight\", \"bert.encoder.layer.7.output.LayerNorm.bias\", \"bert.encoder.layer.7.output.adapters.ner.adapter_down.0.weight\", \"bert.encoder.layer.7.output.adapters.ner.adapter_down.0.bias\", \"bert.encoder.layer.7.output.adapters.ner.adapter_up.weight\", \"bert.encoder.layer.7.output.adapters.ner.adapter_up.bias\", \"bert.encoder.layer.8.attention.self.query.weight\", \"bert.encoder.layer.8.attention.self.query.bias\", \"bert.encoder.layer.8.attention.self.key.weight\", \"bert.encoder.layer.8.attention.self.key.bias\", \"bert.encoder.layer.8.attention.self.value.weight\", \"bert.encoder.layer.8.attention.self.value.bias\", \"bert.encoder.layer.8.attention.output.dense.weight\", \"bert.encoder.layer.8.attention.output.dense.bias\", \"bert.encoder.layer.8.attention.output.LayerNorm.weight\", \"bert.encoder.layer.8.attention.output.LayerNorm.bias\", \"bert.encoder.layer.8.intermediate.dense.weight\", \"bert.encoder.layer.8.intermediate.dense.bias\", \"bert.encoder.layer.8.output.dense.weight\", \"bert.encoder.layer.8.output.dense.bias\", \"bert.encoder.layer.8.output.LayerNorm.weight\", \"bert.encoder.layer.8.output.LayerNorm.bias\", \"bert.encoder.layer.8.output.adapters.ner.adapter_down.0.weight\", \"bert.encoder.layer.8.output.adapters.ner.adapter_down.0.bias\", \"bert.encoder.layer.8.output.adapters.ner.adapter_up.weight\", \"bert.encoder.layer.8.output.adapters.ner.adapter_up.bias\", \"bert.encoder.layer.9.attention.self.query.weight\", \"bert.encoder.layer.9.attention.self.query.bias\", \"bert.encoder.layer.9.attention.self.key.weight\", \"bert.encoder.layer.9.attention.self.key.bias\", \"bert.encoder.layer.9.attention.self.value.weight\", \"bert.encoder.layer.9.attention.self.value.bias\", \"bert.encoder.layer.9.attention.output.dense.weight\", \"bert.encoder.layer.9.attention.output.dense.bias\", \"bert.encoder.layer.9.attention.output.LayerNorm.weight\", \"bert.encoder.layer.9.attention.output.LayerNorm.bias\", \"bert.encoder.layer.9.intermediate.dense.weight\", \"bert.encoder.layer.9.intermediate.dense.bias\", \"bert.encoder.layer.9.output.dense.weight\", \"bert.encoder.layer.9.output.dense.bias\", \"bert.encoder.layer.9.output.LayerNorm.weight\", \"bert.encoder.layer.9.output.LayerNorm.bias\", \"bert.encoder.layer.9.output.adapters.ner.adapter_down.0.weight\", \"bert.encoder.layer.9.output.adapters.ner.adapter_down.0.bias\", \"bert.encoder.layer.9.output.adapters.ner.adapter_up.weight\", \"bert.encoder.layer.9.output.adapters.ner.adapter_up.bias\", \"bert.encoder.layer.10.attention.self.query.weight\", \"bert.encoder.layer.10.attention.self.query.bias\", \"bert.encoder.layer.10.attention.self.key.weight\", \"bert.encoder.layer.10.attention.self.key.bias\", \"bert.encoder.layer.10.attention.self.value.weight\", \"bert.encoder.layer.10.attention.self.value.bias\", \"bert.encoder.layer.10.attention.output.dense.weight\", \"bert.encoder.layer.10.attention.output.dense.bias\", \"bert.encoder.layer.10.attention.output.LayerNorm.weight\", \"bert.encoder.layer.10.attention.output.LayerNorm.bias\", \"bert.encoder.layer.10.intermediate.dense.weight\", \"bert.encoder.layer.10.intermediate.dense.bias\", \"bert.encoder.layer.10.output.dense.weight\", \"bert.encoder.layer.10.output.dense.bias\", \"bert.encoder.layer.10.output.LayerNorm.weight\", \"bert.encoder.layer.10.output.LayerNorm.bias\", \"bert.encoder.layer.10.output.adapters.ner.adapter_down.0.weight\", \"bert.encoder.layer.10.output.adapters.ner.adapter_down.0.bias\", \"bert.encoder.layer.10.output.adapters.ner.adapter_up.weight\", \"bert.encoder.layer.10.output.adapters.ner.adapter_up.bias\", \"bert.encoder.layer.11.attention.self.query.weight\", \"bert.encoder.layer.11.attention.self.query.bias\", \"bert.encoder.layer.11.attention.self.key.weight\", \"bert.encoder.layer.11.attention.self.key.bias\", \"bert.encoder.layer.11.attention.self.value.weight\", \"bert.encoder.layer.11.attention.self.value.bias\", \"bert.encoder.layer.11.attention.output.dense.weight\", \"bert.encoder.layer.11.attention.output.dense.bias\", \"bert.encoder.layer.11.attention.output.LayerNorm.weight\", \"bert.encoder.layer.11.attention.output.LayerNorm.bias\", \"bert.encoder.layer.11.intermediate.dense.weight\", \"bert.encoder.layer.11.intermediate.dense.bias\", \"bert.encoder.layer.11.output.dense.weight\", \"bert.encoder.layer.11.output.dense.bias\", \"bert.encoder.layer.11.output.LayerNorm.weight\", \"bert.encoder.layer.11.output.LayerNorm.bias\", \"classifier.weight\", \"classifier.bias\". "
     ]
    }
   ],
   "source": [
    "from transformers import BertModel, BertConfig\n",
    "\n",
    "BertFolder = '/home/info/MyNotebooks/Datasets/SentencasTRT1/ACP-Bert-LM/NER-ACP/outputs/NER-ACP_/ner/lr0.0001_bs8_epochs3_patience5_wamlmFalse_madx2True_houlsby_MHA_lastlayerFalse_dsFalse_fp16True_bestTrue_metricf1_weightedlossTrue_c0.3_nsTrue_adapterconfigpfeiffer/output_dir/checkpoint-2937/'\n",
    "\n",
    "bert_config = BertConfig.from_json_file(BertFolder+'config.json')\n",
    "model=BertModel(bert_config)\n",
    "\n",
    "model.load_state_dict(torch.load(BertFolder+'pytorch_model.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61da8858",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "RuntimeError                              Traceback (most recent call last)\n",
    "Input In [189], in <cell line: 8>()\n",
    "      5 bert_config = BertConfig.from_json_file(BertFolder+'config.json')\n",
    "      6 model=BertModel(bert_config)\n",
    "----> 8 model.load_state_dict(torch.load(BertFolder+'pytorch_model.bin'))\n",
    "\n",
    "1606 return _IncompatibleKeys(missing_keys, unexpected_keys)\n",
    "\n",
    "RuntimeError: Error(s) in loading state_dict for BertModel:\n",
    "\tMissing key(s) in state_dict: \"embeddings.position_ids\", \"embeddings.word_embeddings.weight\", \"embeddings.position_embeddings.weight\", \"embeddings.token_type_embeddings.weight\", \"embeddings.LayerNorm.weight\", \"embeddings.LayerNorm.bias\", \"encoder.layer.0.attention.self.query.weight\"\n",
    "    \n",
    "    \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96da6a8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f73ffb43",
   "metadata": {},
   "source": [
    "Active adapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0becd486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the adapters to be used in every forward pass\n",
    "\n",
    "if lang_adapter_name:\n",
    "    model_ner.active_adapters = Stack(task_mlm_load_as, task_name)\n",
    "else:\n",
    "    model_ner.set_active_adapters(task_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f84e0ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (shared_parameters): ModuleDict()\n",
       "  (bert): BertModel(\n",
       "    (shared_parameters): ModuleDict()\n",
       "    (invertible_adapters): ModuleDict()\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(29794, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (adapters): ModuleDict()\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (adapters): ModuleDict()\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (adapters): ModuleDict()\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (adapters): ModuleDict()\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (adapters): ModuleDict()\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (adapters): ModuleDict()\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (adapters): ModuleDict()\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (adapters): ModuleDict()\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (adapters): ModuleDict()\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (adapters): ModuleDict()\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (adapters): ModuleDict()\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (adapters): ModuleDict()\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (prefix_tuning): PrefixTuningPool(\n",
       "      (prefix_tunings): ModuleDict()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=13, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a510496b",
   "metadata": {},
   "source": [
    "Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6ce53a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(lang_adapter_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4c0e3b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fore: BLACK, RED, GREEN, YELLOW, BLUE, MAGENTA, CYAN, WHITE, RESET.\n",
    "# Back: BLACK, RED, GREEN, YELLOW, BLUE, MAGENTA, CYAN, WHITE, RESET.\n",
    "# Style: DIM, NORMAL, BRIGHT, RESET_ALL\n",
    "if dataset_name == \"LeNER-Br\":\n",
    "    color_map = {\n",
    "    0: 'WHITE',\n",
    "    1: 'CYAN',\n",
    "    2: 'CYAN',\n",
    "    3: 'BLUE',\n",
    "    4: 'BLUE',\n",
    "    5: 'YELLOW',\n",
    "    6: 'YELLOW',\n",
    "    7: 'MAGENTA',\n",
    "    8: 'MAGENTA',\n",
    "    9: 'RED',\n",
    "    10: 'RED',\n",
    "    11: 'GREEN',\n",
    "    12: 'GREEN'\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd373eb3",
   "metadata": {},
   "source": [
    "Get list of subwords by word in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6bb431cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "subwords_list = list()\n",
    "\n",
    "for text_dataset in texts_dataset:\n",
    "    tokens = tokenizer_ner.tokenize(text_dataset,return_tensors=\"pt\",add_special_tokens=False)\n",
    "\n",
    "    indices = list()\n",
    "    for i,token in enumerate(tokens):\n",
    "        if not token.startswith('##'):\n",
    "            indices.append(i)\n",
    "\n",
    "    subwords = list()\n",
    "    for i in range(len(indices)):\n",
    "        start = indices[i]\n",
    "\n",
    "        if i < len(indices) - 1:\n",
    "            end = indices[i+1]\n",
    "            subwords.append(list(range(start,end)))\n",
    "        else:\n",
    "            subwords.append([start])\n",
    "            \n",
    "    subwords_list.append(subwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbada02",
   "metadata": {},
   "source": [
    "Get NER label for each subword."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c02d41c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_list = list()\n",
    "preds_list = list()\n",
    "\n",
    "for text_dataset in texts_dataset:\n",
    "    tokens = tokenizer_ner.encode(text_dataset,return_tensors=\"pt\",add_special_tokens=False)\n",
    "    model_ner.eval()\n",
    "\n",
    "    #preds = model_ner(tokens, adapter_names=['ner'])[0]\n",
    "    preds = model_ner(tokens)[0]\n",
    "    preds = preds.detach().numpy()\n",
    "    preds = np.argmax(preds, axis=2)\n",
    "\n",
    "    tokens, preds = tokenizer_ner.tokenize(text_dataset), preds[0].tolist()\n",
    "    tokens_list.append(tokens)\n",
    "    preds_list.append(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7204611",
   "metadata": {},
   "source": [
    "Get NER label for each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c4a3959c",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_label_list = list()\n",
    "for i,subwords in enumerate(subwords_list):\n",
    "    words_label = list()\n",
    "    for subword in subwords:\n",
    "        words_label.append((tokenizer_ner.convert_tokens_to_string([tokens_list[i][idx] for idx in subword]), preds_list[i][subword[0]]))\n",
    "    words_label_list.append(words_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "dd8e5c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_pred_list = list()\n",
    "\n",
    "for words_label in words_label_list:\n",
    "    groups_pred = dict()\n",
    "    group = ''\n",
    "    group_label = ''\n",
    "    pred_prec = ''\n",
    "\n",
    "    i = 0\n",
    "    for word, pred in words_label:\n",
    "        if pred == 0: \n",
    "            if len(group) > 0:\n",
    "                groups_pred[group] = group_label\n",
    "                group = ''\n",
    "                group_label = ''\n",
    "\n",
    "            groups_pred[word] = pred  \n",
    "\n",
    "        elif pred in [1,3,5,7,9,11,13,15]:\n",
    "            if pred_prec in [0,1,3,5,7,9,11,13,15] and len(group) > 0:\n",
    "                groups_pred[group] = group_label\n",
    "                group = ''\n",
    "                group_label = ''  \n",
    "            group = word\n",
    "            group_label = pred\n",
    "            pred_prec = pred\n",
    "\n",
    "        elif pred in [2,4,6,8,10,12,14,16]:\n",
    "\n",
    "            if len(group) > 0:\n",
    "                group += ' ' + word\n",
    "            else:\n",
    "                group = word\n",
    "                group_label = pred\n",
    "\n",
    "        if i == len(words_label) - 1 and len(group) > 0:\n",
    "            groups_pred[group] = group_label\n",
    "            group = ''\n",
    "            group_label = ''\n",
    "\n",
    "        i += 1\n",
    "    groups_pred_list.append(groups_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097b100d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ba5510b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def predict(sentence):\n",
    "    tokens = tokenizer_ner.encode(\n",
    "        sentence,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    model_ner.eval()\n",
    "    preds = model_ner(tokens, adapter_names=['ner'])[0]\n",
    "    preds = preds.detach().numpy()\n",
    "    preds = np.argmax(preds, axis=2)\n",
    "    return tokenizer_ner.tokenize(sentence), preds.squeeze()[1:-1]\n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "25216a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntokens, preds = predict(text_dataset)\\nfor token, pred in zip(tokens, preds):\\n    print(f\"{token}({label_map[pred]}) \", end=\"\")\\n'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the mapping of ids to labels\n",
    "label_map = model_ner.get_labels_dict()\n",
    "#label_map = {i:label for i,label in enumerate(labels)}\n",
    "'''\n",
    "tokens, preds = predict(text_dataset)\n",
    "for token, pred in zip(tokens, preds):\n",
    "    print(f\"{token}({label_map[pred]}) \", end=\"\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cad1075",
   "metadata": {},
   "source": [
    "Get NER label for each group of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "24bbc5c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-100,    0,    0, ..., -100, -100, -100],\n",
       "       [-100,    0,    0, ..., -100, -100, -100],\n",
       "       [-100,    0,    0, ..., -100, -100, -100],\n",
       "       ...,\n",
       "       [-100,    0,    0, ..., -100, -100, -100],\n",
       "       [-100,    0,   11, ..., -100, -100, -100],\n",
       "       [-100, -100, -100, ..., -100, -100, -100]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a92104b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********** EXEMPLO 1 **********\n",
      "\n",
      "\u001b[30m\u001b[42mAcrescento\u001b[37m\u001b[40m (JURISPRUDENCIA)\u001b[0m que o \u001b[30m\u001b[42mJuiz\u001b[37m\u001b[40m (JURISPRUDENCIA)\u001b[0m \u001b[30m\u001b[44mPedro DA SILVA do\u001b[37m\u001b[40m (PESSOA)\u001b[0m \u001b[30m\u001b[46mtribunal\u001b[37m\u001b[40m (ORGANIZACAO)\u001b[0m \u001b[30m\u001b[46mSTF\u001b[37m\u001b[40m (ORGANIZACAO)\u001b[0m em Brasília ( Brasil ) reconheceu a limitação do pedido \u001b[30m\u001b[42múnico\u001b[37m\u001b[40m (JURISPRUDENCIA)\u001b[0m e , com base no \u001b[30m\u001b[41martigo 487\u001b[37m\u001b[40m (LEGISLACAO)\u001b[0m \u001b[30m\u001b[41minciso II\u001b[37m\u001b[40m (LEGISLACAO)\u001b[0m \u001b[30m\u001b[41mCódigo de Processo Civil\u001b[37m\u001b[40m (LEGISLACAO)\u001b[0m encerrou processo dia 3 \u001b[30m\u001b[43mde janeiro de 2014\u001b[37m\u001b[40m (TEMPO)\u001b[0m \u001b[30m\u001b[42mresolução\u001b[37m\u001b[40m (JURISPRUDENCIA)\u001b[0m \u001b[30m\u001b[42mmérito\u001b[37m\u001b[40m (JURISPRUDENCIA)\u001b[0m condenando autor às custas \u001b[30m\u001b[42mjudiciais\u001b[37m\u001b[40m (JURISPRUDENCIA)\u001b[0m advocatícias são \u001b[30m\u001b[42mfixadas\u001b[37m\u001b[40m (JURISPRUDENCIA)\u001b[0m 10 \u001b[30m\u001b[41m%\u001b[37m\u001b[40m (LEGISLACAO)\u001b[0m dez por cento valor da causa . \n",
      "\n",
      "Text without Named Entities:\n",
      " Acrescento que o Juiz Pedro DA SILVA do tribunal STF em Brasília (Brasil) reconheceu a limitação do pedido único e, com base no artigo 487, inciso II, do Código de Processo Civil, encerrou o processo no dia 3 de janeiro de 2014, com resolução do mérito, condenando o autor às custas judiciais e advocatícias, que são fixadas em 10% (dez por cento) do valor da causa.\n",
      "\n",
      "********** EXEMPLO 2 **********\n",
      "\n",
      "\u001b[30m\u001b[42mInsurge\u001b[37m\u001b[40m (JURISPRUDENCIA)\u001b[0m - se no \u001b[30m\u001b[42mapelo\u001b[37m\u001b[40m (JURISPRUDENCIA)\u001b[0m extremo contra acórdão proferido pelo \u001b[30m\u001b[46mSuperior\u001b[37m\u001b[40m (ORGANIZACAO)\u001b[0m \u001b[30m\u001b[46mTribunal Militar\u001b[37m\u001b[40m (ORGANIZACAO)\u001b[0m \u001b[30m\u001b[42mAgravo\u001b[37m\u001b[40m (JURISPRUDENCIA)\u001b[0m \u001b[30m\u001b[42mRegimental n° 222 -\u001b[37m\u001b[40m (JURISPRUDENCIA)\u001b[0m 73 \u001b[30m\u001b[42m. 2010 .\u001b[37m\u001b[40m (JURISPRUDENCIA)\u001b[0m 7 \u001b[30m\u001b[42m. 05 . 0005 / PR , assim do :\u001b[37m\u001b[40m (JURISPRUDENCIA)\u001b[0m \u001b[30m\u001b[42mDESERÇÃO .\u001b[37m\u001b[40m (JURISPRUDENCIA)\u001b[0m \n",
      "\n",
      "Text without Named Entities:\n",
      " Insurge-se no apelo extremo contra acórdão proferido pelo Superior Tribunal Militar no Agravo Regimental n° 222-73.2010.7.05.0005/PR, assim do: DESERÇÃO.\n",
      "\n",
      "Named Entities of the text:\n",
      " 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORGANIZACAO', 'I-ORGANIZACAO', 'I-ORGANIZACAO', 'O', 'B-JURISPRUDENCIA', 'I-JURISPRUDENCIA', 'I-JURISPRUDENCIA', 'I-JURISPRUDENCIA', 'I-JURISPRUDENCIA', 'O', 'O', 'O', 'O', 'O', 'O'\n"
     ]
    }
   ],
   "source": [
    "for i,groups_pred in enumerate(groups_pred_list):\n",
    "    print(f'\\n********** EXEMPLO {i+1} **********\\n')\n",
    "    sentence_color = ''\n",
    "\n",
    "    count = 0\n",
    "    for word, pred in groups_pred.items():\n",
    "        COLORNAME = color_map[pred]\n",
    "        color_back = getattr(Back, COLORNAME)  \n",
    "\n",
    "        if pred == 0:\n",
    "            sentence_color += word + ' '\n",
    "        else:\n",
    "            sentence_color += Fore.BLACK + color_back +  word + Fore.WHITE + Back.BLACK + ' (' + label_map[pred].replace('B-','').replace('I-','') + ')' + Style.RESET_ALL + ' '\n",
    "    print(sentence_color)\n",
    "    print()\n",
    "    print('Text without Named Entities:\\n',texts_dataset[i])\n",
    "    if len(texts_labels[i]) > 0:\n",
    "        print('\\nNamed Entities of the text:\\n',texts_labels[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d8622f",
   "metadata": {},
   "source": [
    "We display an image of the precedent results in order to be visible in github.\n",
    "\n",
    "END."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3a1e4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029d20c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e788521",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a699e23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051b7903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_adapter(\"sciie_pfieffer_lang/\", \"tapt-pfeiffer\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
